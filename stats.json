{
    "UC8tgRQ7DOzAbn9L7zDL8mLg": {
        "channel_statistics": {
            "viewCount": "7904217",
            "subscriberCount": "89500",
            "hiddenSubscriberCount": false,
            "videoCount": "293"
        },
        "video_data": {
            "4Q3EUXjPOnc": {
                "snippet": {
                    "publishedAt": "2024-10-27T12:17:08Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Stop Using Selenium or Playwright for Web Scraping",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/4Q3EUXjPOnc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/4Q3EUXjPOnc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/4Q3EUXjPOnc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/4Q3EUXjPOnc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/4Q3EUXjPOnc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Stop Using Selenium or Playwright for Web Scraping",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "7150",
                    "likeCount": "349",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT10M46S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "SKCW_i3lGKU": {
                "snippet": {
                    "publishedAt": "2024-10-21T10:47:36Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Sitemap Scraping is for GOOD bots",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/SKCW_i3lGKU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/SKCW_i3lGKU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/SKCW_i3lGKU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/SKCW_i3lGKU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/SKCW_i3lGKU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Sitemap Scraping is for GOOD bots",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "2199",
                    "likeCount": "97",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT13M11S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "EB2gn9G9sV8": {
                "snippet": {
                    "publishedAt": "2024-10-13T14:47:30Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "They know you're using Browser Automation, so try this.",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/EB2gn9G9sV8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/EB2gn9G9sV8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/EB2gn9G9sV8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/EB2gn9G9sV8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/EB2gn9G9sV8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "They know you're using Browser Automation, so try this.",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "7343",
                    "likeCount": "320",
                    "favoriteCount": "0",
                    "commentCount": "22"
                },
                "contentDetails": {
                    "duration": "PT11M",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "L0gxQsCJ1hY": {
                "snippet": {
                    "publishedAt": "2024-09-22T12:35:21Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This Simple String Blocks Your Web Scrapers",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/L0gxQsCJ1hY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/L0gxQsCJ1hY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/L0gxQsCJ1hY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/L0gxQsCJ1hY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/L0gxQsCJ1hY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This Simple String Blocks Your Web Scrapers",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "31778",
                    "likeCount": "1123",
                    "favoriteCount": "0",
                    "commentCount": "53"
                },
                "contentDetails": {
                    "duration": "PT10M29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ji8F8ppY8bs": {
                "snippet": {
                    "publishedAt": "2024-09-15T11:00:50Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This is How I Scrape 99% of Sites",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ji8F8ppY8bs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ji8F8ppY8bs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ji8F8ppY8bs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ji8F8ppY8bs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ji8F8ppY8bs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This is How I Scrape 99% of Sites",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "142642",
                    "likeCount": "5940",
                    "favoriteCount": "0",
                    "commentCount": "212"
                },
                "contentDetails": {
                    "duration": "PT18M27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_wzFc_gPtV4": {
                "snippet": {
                    "publishedAt": "2024-09-08T13:17:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Learning Scraping is MUCH harder now.",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_wzFc_gPtV4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_wzFc_gPtV4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_wzFc_gPtV4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_wzFc_gPtV4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_wzFc_gPtV4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Learning Scraping is MUCH harder now.",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 JOIN MY MAILING LIST\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "7292",
                    "likeCount": "424",
                    "favoriteCount": "0",
                    "commentCount": "54"
                },
                "contentDetails": {
                    "duration": "PT10M55S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Jz1ky02bIvM": {
                "snippet": {
                    "publishedAt": "2024-09-01T12:06:23Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Use Proxies with Python (requests + playwright)",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Jz1ky02bIvM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Jz1ky02bIvM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Jz1ky02bIvM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Jz1ky02bIvM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Jz1ky02bIvM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Use Proxies with Python (requests + playwright)",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "3154",
                    "likeCount": "160",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT10M51S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "skT4gSdiP9Q": {
                "snippet": {
                    "publishedAt": "2024-08-25T14:57:56Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape Data for Market Research (full project)",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/skT4gSdiP9Q/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/skT4gSdiP9Q/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/skT4gSdiP9Q/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/skT4gSdiP9Q/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/skT4gSdiP9Q/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape Data for Market Research (full project)",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "7203",
                    "likeCount": "326",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT54M48S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "mqr881IYGn0": {
                "snippet": {
                    "publishedAt": "2024-08-18T09:50:45Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Easiest Way to Avoid Being Blocked When Web Scraping",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/mqr881IYGn0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/mqr881IYGn0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/mqr881IYGn0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/mqr881IYGn0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/mqr881IYGn0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Easiest Way to Avoid Being Blocked When Web Scraping",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "3857",
                    "likeCount": "208",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT8M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "HNKz7qzwGr8": {
                "snippet": {
                    "publishedAt": "2024-08-11T10:16:36Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I run my Python scripts everyday in the cloud",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/HNKz7qzwGr8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/HNKz7qzwGr8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/HNKz7qzwGr8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/HNKz7qzwGr8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/HNKz7qzwGr8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I run my Python scripts everyday in the cloud",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WEB\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING (Digital Ocean)\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "7511",
                    "likeCount": "291",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT17M11S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GA_x_drLnw4": {
                "snippet": {
                    "publishedAt": "2024-08-04T09:30:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Saving raw HTML to MongoDB clip #coding #webscraping #datascraping #python",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GA_x_drLnw4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GA_x_drLnw4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GA_x_drLnw4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GA_x_drLnw4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Saving raw HTML to MongoDB clip #coding #webscraping #datascraping #python",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "936",
                    "likeCount": "27",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "t_8rMOHpXOw": {
                "snippet": {
                    "publishedAt": "2024-08-04T09:30:07Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Is this how pro's scrape HUGE amounts of data?",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/t_8rMOHpXOw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/t_8rMOHpXOw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/t_8rMOHpXOw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/t_8rMOHpXOw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/t_8rMOHpXOw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Is this how pro's scrape HUGE amounts of data?",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "6257",
                    "likeCount": "270",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT20M34S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "tzg_v2w1ybw": {
                "snippet": {
                    "publishedAt": "2024-07-28T12:19:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I built a distributed scraping system, but was it worth it?",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/tzg_v2w1ybw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/tzg_v2w1ybw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/tzg_v2w1ybw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/tzg_v2w1ybw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/tzg_v2w1ybw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I built a distributed scraping system, but was it worth it?",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "3181",
                    "likeCount": "114",
                    "favoriteCount": "0",
                    "commentCount": "14"
                },
                "contentDetails": {
                    "duration": "PT6M51S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "tuf9KoZ6JyI": {
                "snippet": {
                    "publishedAt": "2024-07-23T17:02:28Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Every Web Scraper should know THIS",
                    "description": "\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\nhttps://www.scrapingbee.com?fpr=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/tuf9KoZ6JyI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/tuf9KoZ6JyI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/tuf9KoZ6JyI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/tuf9KoZ6JyI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/tuf9KoZ6JyI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Every Web Scraper should know THIS",
                        "description": "\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\nhttps://www.scrapingbee.com?fpr=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4378",
                    "likeCount": "269",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT5M59S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "wJqr9gdGWOw": {
                "snippet": {
                    "publishedAt": "2024-07-21T13:04:21Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Use Data Pipelines in my Web Scrapers",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/wJqr9gdGWOw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/wJqr9gdGWOw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/wJqr9gdGWOw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/wJqr9gdGWOw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/wJqr9gdGWOw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Use Data Pipelines in my Web Scrapers",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "2486",
                    "likeCount": "97",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT12M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "x_JjL29nNVw": {
                "snippet": {
                    "publishedAt": "2024-07-14T12:40:23Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Automation- product checker and buyer",
                    "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/x_JjL29nNVw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/x_JjL29nNVw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/x_JjL29nNVw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/x_JjL29nNVw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/x_JjL29nNVw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Automation- product checker and buyer",
                        "description": "Check Out ProxyScrape here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis video was sponsored by ProxyScrape."
                    }
                },
                "statistics": {
                    "viewCount": "2326",
                    "likeCount": "92",
                    "favoriteCount": "0",
                    "commentCount": "10"
                },
                "contentDetails": {
                    "duration": "PT24M11S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "N5gpH8bZQGk": {
                "snippet": {
                    "publishedAt": "2024-07-07T08:57:31Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Want Scrapy without the project folder? Use this.",
                    "description": "Check Out ProxyScrapy here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/N5gpH8bZQGk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/N5gpH8bZQGk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/N5gpH8bZQGk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/N5gpH8bZQGk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/N5gpH8bZQGk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Want Scrapy without the project folder? Use this.",
                        "description": "Check Out ProxyScrapy here: https://proxyscrape.com/?ref=jhnwr\n\n\u27a1 WORK WITH ME\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "3468",
                    "likeCount": "138",
                    "favoriteCount": "0",
                    "commentCount": "9"
                },
                "contentDetails": {
                    "duration": "PT19M24S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Hg_iLFURnAk": {
                "snippet": {
                    "publishedAt": "2024-07-02T13:00:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "My System for Easily Scraping 150k Items from the web",
                    "description": "Use JWR at checkout to get +2GB of proxies for free: https://go.nodemaven.com/scrapingproxy\n\n\u27a1 E-commerce Data Extraction Specialist\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://go.nodemaven.com/scrapingproxy\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Hg_iLFURnAk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Hg_iLFURnAk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Hg_iLFURnAk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Hg_iLFURnAk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Hg_iLFURnAk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "My System for Easily Scraping 150k Items from the web",
                        "description": "Use JWR at checkout to get +2GB of proxies for free: https://go.nodemaven.com/scrapingproxy\n\n\u27a1 E-commerce Data Extraction Specialist\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://go.nodemaven.com/scrapingproxy\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "5394",
                    "likeCount": "203",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT44M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "t38kDQ1-lxo": {
                "snippet": {
                    "publishedAt": "2024-06-29T12:13:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Playwright Isn't THAT slow for Scraping, if you do this",
                    "description": "\u27a1 E-commerce Data Extraction Specialist\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://nodemaven.com/?a_aid=JohnWatsonRooney\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/t38kDQ1-lxo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/t38kDQ1-lxo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/t38kDQ1-lxo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/t38kDQ1-lxo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/t38kDQ1-lxo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Playwright Isn't THAT slow for Scraping, if you do this",
                        "description": "\u27a1 E-commerce Data Extraction Specialist\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://nodemaven.com/?a_aid=JohnWatsonRooney\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "2749",
                    "likeCount": "74",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT23M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uVZEec0R2AQ": {
                "snippet": {
                    "publishedAt": "2024-06-23T11:29:43Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Simple Automation Script my Colleagues Loved.",
                    "description": "The first 500 people to use my link https://skl.sh/johnwatsonrooney06241 will get a 1 month free trial of Skillshare premium!\n\nThis video is sponsored by Skillshare\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uVZEec0R2AQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uVZEec0R2AQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uVZEec0R2AQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uVZEec0R2AQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uVZEec0R2AQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Simple Automation Script my Colleagues Loved.",
                        "description": "The first 500 people to use my link https://skl.sh/johnwatsonrooney06241 will get a 1 month free trial of Skillshare premium!\n\nThis video is sponsored by Skillshare\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4143",
                    "likeCount": "125",
                    "favoriteCount": "0",
                    "commentCount": "7"
                },
                "contentDetails": {
                    "duration": "PT12M55S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xclcwbZ9dmQ": {
                "snippet": {
                    "publishedAt": "2024-06-16T12:11:46Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping 7000 Products in 20 Minutes",
                    "description": "Go to https://proxyscrape.com/?ref=jhnwr for the Proxies I use.\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis Video was sponsored by Proxyscrape.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xclcwbZ9dmQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xclcwbZ9dmQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xclcwbZ9dmQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xclcwbZ9dmQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xclcwbZ9dmQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping 7000 Products in 20 Minutes",
                        "description": "Go to https://proxyscrape.com/?ref=jhnwr for the Proxies I use.\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\nThis Video was sponsored by Proxyscrape."
                    }
                },
                "statistics": {
                    "viewCount": "5071",
                    "likeCount": "197",
                    "favoriteCount": "0",
                    "commentCount": "22"
                },
                "contentDetails": {
                    "duration": "PT20M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "XpGvq755J2U": {
                "snippet": {
                    "publishedAt": "2024-06-10T06:59:07Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape 7k Products with Python (code along)",
                    "description": "A short but complete project of scraping 7k+ products with Python.\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/XpGvq755J2U/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/XpGvq755J2U/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/XpGvq755J2U/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/XpGvq755J2U/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/XpGvq755J2U/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape 7k Products with Python (code along)",
                        "description": "A short but complete project of scraping 7k+ products with Python.\n\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "9460",
                    "likeCount": "410",
                    "favoriteCount": "0",
                    "commentCount": "22"
                },
                "contentDetails": {
                    "duration": "PT27M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WtEtHmGehoA": {
                "snippet": {
                    "publishedAt": "2024-05-19T13:02:08Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This will change Web Scraping forever.",
                    "description": "What to try this yourself? Sign up at https://www.zyte.com/ and use code JWR203 for $20 for free each month for 3 months. Limited availability first come first serve. Once you have created an account enter the coupon code JWR203 under settings, subscriptions, modify & enter code.\n\nZyte gave me access to their API and NEW AI spider tech to see how it compares to scraping manually, with incredible results.\n\nThis video was sponsored by Zyte.\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WtEtHmGehoA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WtEtHmGehoA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WtEtHmGehoA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WtEtHmGehoA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WtEtHmGehoA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "defaultLanguage": "en-GB",
                    "localized": {
                        "title": "This will change Web Scraping forever.",
                        "description": "What to try this yourself? Sign up at https://www.zyte.com/ and use code JWR203 for $20 for free each month for 3 months. Limited availability first come first serve. Once you have created an account enter the coupon code JWR203 under settings, subscriptions, modify & enter code.\n\nZyte gave me access to their API and NEW AI spider tech to see how it compares to scraping manually, with incredible results.\n\nThis video was sponsored by Zyte.\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    },
                    "defaultAudioLanguage": "en-GB"
                },
                "statistics": {
                    "viewCount": "9332",
                    "likeCount": "255",
                    "favoriteCount": "0",
                    "commentCount": "30"
                },
                "contentDetails": {
                    "duration": "PT9M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "q1GDSHhaH0E": {
                "snippet": {
                    "publishedAt": "2024-04-28T11:15:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The most important Python script I ever wrote",
                    "description": "The story of my first and most important automation script, plus an example of what it would look like now.\n\n\u2705 WORK WITH ME \u2705\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n\u27a1 TIMESTAMPS\n00:00 Story\n03:21 Code Start",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/q1GDSHhaH0E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/q1GDSHhaH0E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/q1GDSHhaH0E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/q1GDSHhaH0E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/q1GDSHhaH0E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The most important Python script I ever wrote",
                        "description": "The story of my first and most important automation script, plus an example of what it would look like now.\n\n\u2705 WORK WITH ME \u2705\nhttps://johnwr.com\n\n\u27a1 COMMUNITY\nhttps://discord.gg/C4J2uckpbR\nhttps://www.patreon.com/johnwatsonrooney \n\n\u27a1 PROXIES\nhttps://www.scrapingbee.com/?fpr=jhnwr\nhttps://proxyscrape.com/?ref=jhnwr\n\n\u27a1 HOSTING\nhttps://m.do.co/c/c7c90f161ff6\n\nIf you are new, welcome. I'm John, a self taught Python developer working in the web and data space. I specialize in data extraction and automation. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n\u26a0 DISCLAIMER\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n\u27a1 TIMESTAMPS\n00:00 Story\n03:21 Code Start"
                    }
                },
                "statistics": {
                    "viewCount": "205474",
                    "likeCount": "4466",
                    "favoriteCount": "0",
                    "commentCount": "167"
                },
                "contentDetails": {
                    "duration": "PT19M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "39jB8nJBrCI": {
                "snippet": {
                    "publishedAt": "2024-04-19T12:00:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Why I chose Python & Polars for Data Analysis",
                    "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney/ . You\u2019ll also get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\njoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nWork with me: https://johnwr.com\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/39jB8nJBrCI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/39jB8nJBrCI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/39jB8nJBrCI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/39jB8nJBrCI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/39jB8nJBrCI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Why I chose Python & Polars for Data Analysis",
                        "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney/ . You\u2019ll also get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\njoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nWork with me: https://johnwr.com\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "7101",
                    "likeCount": "253",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT24M33S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "00yQfxC7PFU": {
                "snippet": {
                    "publishedAt": "2024-04-10T15:25:57Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Best Tools to Scrape Data in 2024",
                    "description": "Python has a great ecosystem for webscraping and in this video I run through the packages I use everyday to scrape data.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n# Timestamps\n\n00:00 Best?\n01:13 Http Clients\n04:26 HTML Parsing\n05:55 Saving Data\n06:18 Frameworks\n08:00 Scrapy\n09:20 Paid Options\n10:38 My Go To",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/00yQfxC7PFU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/00yQfxC7PFU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/00yQfxC7PFU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/00yQfxC7PFU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/00yQfxC7PFU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Best Tools to Scrape Data in 2024",
                        "description": "Python has a great ecosystem for webscraping and in this video I run through the packages I use everyday to scrape data.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n# Timestamps\n\n00:00 Best?\n01:13 Http Clients\n04:26 HTML Parsing\n05:55 Saving Data\n06:18 Frameworks\n08:00 Scrapy\n09:20 Paid Options\n10:38 My Go To"
                    }
                },
                "statistics": {
                    "viewCount": "8700",
                    "likeCount": "409",
                    "favoriteCount": "0",
                    "commentCount": "39"
                },
                "contentDetails": {
                    "duration": "PT11M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "C6CDg2jhYc4": {
                "snippet": {
                    "publishedAt": "2024-04-03T12:13:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Is Your Scraper Slow? Try THIS Simple Method",
                    "description": "Get Proxies from Nodemaven Now: https://go.nodemaven.com/scrapingproxy\nUse Code: JWR for +2 GB on purchase\n\nThreads and parallel processing are still useful for scraping, even though most of the waiting is I/O which is best served by async, it still can make your code much faster in the right situations, and is very simple to implement.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/C6CDg2jhYc4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/C6CDg2jhYc4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/C6CDg2jhYc4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/C6CDg2jhYc4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/C6CDg2jhYc4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Is Your Scraper Slow? Try THIS Simple Method",
                        "description": "Get Proxies from Nodemaven Now: https://go.nodemaven.com/scrapingproxy\nUse Code: JWR for +2 GB on purchase\n\nThreads and parallel processing are still useful for scraping, even though most of the waiting is I/O which is best served by async, it still can make your code much faster in the right situations, and is very simple to implement.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "5455",
                    "likeCount": "214",
                    "favoriteCount": "0",
                    "commentCount": "20"
                },
                "contentDetails": {
                    "duration": "PT10M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "E4wU8y7r1Uc": {
                "snippet": {
                    "publishedAt": "2024-03-29T13:26:46Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping with Playwright 101 - Easy Mode",
                    "description": "Playwright is an incredible versatile tool for browser automation, and in this video I run thorugh a simple project to get you up and running scraping data with PW & Python\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n:: Chapters ::\n00:00 - checking site\n02:18 - start code\n05:24 - detail page\n11:13 - pagination\n16:30 - summary and run",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/E4wU8y7r1Uc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/E4wU8y7r1Uc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/E4wU8y7r1Uc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/E4wU8y7r1Uc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/E4wU8y7r1Uc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping with Playwright 101 - Easy Mode",
                        "description": "Playwright is an incredible versatile tool for browser automation, and in this video I run thorugh a simple project to get you up and running scraping data with PW & Python\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://proxyscrape.com/?ref=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.\n\n:: Chapters ::\n00:00 - checking site\n02:18 - start code\n05:24 - detail page\n11:13 - pagination\n16:30 - summary and run"
                    }
                },
                "statistics": {
                    "viewCount": "13265",
                    "likeCount": "392",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT19M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "u-8a4e9iEEk": {
                "snippet": {
                    "publishedAt": "2024-03-23T15:45:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Cleaning up 1000 Scraped Products with Polars",
                    "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney/ . You\u2019ll also get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\nA look into how to clean up scraped product data using Pythons Polars package.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/u-8a4e9iEEk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/u-8a4e9iEEk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/u-8a4e9iEEk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/u-8a4e9iEEk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/u-8a4e9iEEk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Cleaning up 1000 Scraped Products with Polars",
                        "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney/ . You\u2019ll also get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\nA look into how to clean up scraped product data using Pythons Polars package.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "5499",
                    "likeCount": "238",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT15M30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "f_HuvJ3CkMs": {
                "snippet": {
                    "publishedAt": "2024-03-17T15:38:58Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Website to Dataset in an instant",
                    "description": "1000 items in one API request... creating a dataset from a simple API call. I enjoyed this one, there will be a part 2 where I clean the data with Pandas.\n\nThis is a scrapy project using the sitemap spider, saving the data to an sqlite database using a pipeline.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get early content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/f_HuvJ3CkMs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/f_HuvJ3CkMs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/f_HuvJ3CkMs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/f_HuvJ3CkMs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/f_HuvJ3CkMs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Website to Dataset in an instant",
                        "description": "1000 items in one API request... creating a dataset from a simple API call. I enjoyed this one, there will be a part 2 where I clean the data with Pandas.\n\nThis is a scrapy project using the sitemap spider, saving the data to an sqlite database using a pipeline.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get early content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "7185",
                    "likeCount": "358",
                    "favoriteCount": "0",
                    "commentCount": "30"
                },
                "contentDetails": {
                    "duration": "PT13M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "4j39AOVhKtQ": {
                "snippet": {
                    "publishedAt": "2024-03-10T21:02:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This is a Scraping Cheat Code (for certain sites)",
                    "description": "Scrapy keeps on giving, the sitemap spider automatically extracts links from XML sitemaps and yields requests based on a given rule set.\n\nThis is a scrapy project using the sitemap spider, saving the data to an sqlite database using a pipeline.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/4j39AOVhKtQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/4j39AOVhKtQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/4j39AOVhKtQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/4j39AOVhKtQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/4j39AOVhKtQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This is a Scraping Cheat Code (for certain sites)",
                        "description": "Scrapy keeps on giving, the sitemap spider automatically extracts links from XML sitemaps and yields requests based on a given rule set.\n\nThis is a scrapy project using the sitemap spider, saving the data to an sqlite database using a pipeline.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "5109",
                    "likeCount": "150",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT32M8S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "o_7weX730bQ": {
                "snippet": {
                    "publishedAt": "2024-03-03T13:39:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Let me explain my new Rust love affair..",
                    "description": "Let me explain my new Rust love affair..\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/o_7weX730bQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/o_7weX730bQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/o_7weX730bQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/o_7weX730bQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/o_7weX730bQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Let me explain my new Rust love affair..",
                        "description": "Let me explain my new Rust love affair..\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "1048",
                    "likeCount": "32",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT12M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "NqcPLp8a4Eg": {
                "snippet": {
                    "publishedAt": "2024-02-23T13:45:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Stop Wasting Time on Simple Excel Tasks, Use Python",
                    "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney . The first 200 of you will get 20% off Brilliant\u2019s annual premium subscription.\n\nThis video was sponsored by Brilliant\n\nCode & demo files : https://github.com/jhnwr/auto-reporting\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/NqcPLp8a4Eg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/NqcPLp8a4Eg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/NqcPLp8a4Eg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/NqcPLp8a4Eg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/NqcPLp8a4Eg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Stop Wasting Time on Simple Excel Tasks, Use Python",
                        "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney . The first 200 of you will get 20% off Brilliant\u2019s annual premium subscription.\n\nThis video was sponsored by Brilliant\n\nCode & demo files : https://github.com/jhnwr/auto-reporting\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "10841",
                    "likeCount": "436",
                    "favoriteCount": "0",
                    "commentCount": "50"
                },
                "contentDetails": {
                    "duration": "PT17M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "nzTxSWAklhg": {
                "snippet": {
                    "publishedAt": "2024-02-18T13:08:41Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The HTML Element I check FIRST when Web Scraping",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nDoing some string parsing to grab the structured data from a script tag.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/nzTxSWAklhg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/nzTxSWAklhg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/nzTxSWAklhg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/nzTxSWAklhg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/nzTxSWAklhg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The HTML Element I check FIRST when Web Scraping",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nDoing some string parsing to grab the structured data from a script tag.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "3031",
                    "likeCount": "123",
                    "favoriteCount": "0",
                    "commentCount": "9"
                },
                "contentDetails": {
                    "duration": "PT17M",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "JSUr5_R_Nvs": {
                "snippet": {
                    "publishedAt": "2024-02-04T14:00:17Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Try this SIMPLE trick when scraping product data",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nusing the schema.org standards we can easily scrape product data for lots of different pages. \n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/JSUr5_R_Nvs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/JSUr5_R_Nvs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/JSUr5_R_Nvs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/JSUr5_R_Nvs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/JSUr5_R_Nvs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Try this SIMPLE trick when scraping product data",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nusing the schema.org standards we can easily scrape product data for lots of different pages. \n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4075",
                    "likeCount": "150",
                    "favoriteCount": "0",
                    "commentCount": "25"
                },
                "contentDetails": {
                    "duration": "PT13M32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "irhgasxXeFM": {
                "snippet": {
                    "publishedAt": "2024-01-28T20:26:13Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Get Started with Scrapy Redis",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nA look at distributed scraping with scrapy and redis\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/irhgasxXeFM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/irhgasxXeFM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/irhgasxXeFM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/irhgasxXeFM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/irhgasxXeFM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy",
                        "redis",
                        "distributed scraping",
                        "scrapy-redis",
                        "john watson rooney",
                        "web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Get Started with Scrapy Redis",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nA look at distributed scraping with scrapy and redis\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "3002",
                    "likeCount": "116",
                    "favoriteCount": "0",
                    "commentCount": "8"
                },
                "contentDetails": {
                    "duration": "PT12M18S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Irs6PG36qz8": {
                "snippet": {
                    "publishedAt": "2024-01-21T13:10:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "still the best way to scrape data.",
                    "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney . The first 200 of you will get 20% off Brilliant\u2019s annual premium subscription.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nA full project video where I look at combining multiple scraping techniques into one to suit my needs for data extraction.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\n\nThis video was sponsored by Brilliant\n\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Irs6PG36qz8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Irs6PG36qz8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Irs6PG36qz8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Irs6PG36qz8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Irs6PG36qz8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "still the best way to scrape data.",
                        "description": "To try everything Brilliant has to offer\u2014free\u2014for a full 30 days, visit https://brilliant.org/JohnWatsonRooney . The first 200 of you will get 20% off Brilliant\u2019s annual premium subscription.\n\nJoin the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nA full project video where I look at combining multiple scraping techniques into one to suit my needs for data extraction.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nA rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\n\nThis video was sponsored by Brilliant\n\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "16696",
                    "likeCount": "483",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT41M1S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "C71OTJFaMec": {
                "snippet": {
                    "publishedAt": "2024-01-14T07:35:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Use Python-RQ to create a scraper queue",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nBuild easy scraping queues with python-rq ready to be implemented into a scraping web app.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/C71OTJFaMec/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/C71OTJFaMec/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/C71OTJFaMec/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/C71OTJFaMec/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/C71OTJFaMec/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Use Python-RQ to create a scraper queue",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nBuild easy scraping queues with python-rq ready to be implemented into a scraping web app.\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4717",
                    "likeCount": "201",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT10M39S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "T73KxH9d_W0": {
                "snippet": {
                    "publishedAt": "2024-01-07T07:38:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I had no idea you could scrape this site this way",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nI've scraped RSS feeds before, grabbing the XML, but had no idea this site had one...\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nThe Scraper API I use https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/T73KxH9d_W0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/T73KxH9d_W0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/T73KxH9d_W0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/T73KxH9d_W0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/T73KxH9d_W0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I had no idea you could scrape this site this way",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nI've scraped RSS feeds before, grabbing the XML, but had no idea this site had one...\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nThe Scraper API I use https://www.scrapingbee.com?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I recommend https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4619",
                    "likeCount": "236",
                    "favoriteCount": "0",
                    "commentCount": "18"
                },
                "contentDetails": {
                    "duration": "PT8M17S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ZhQcUNlR0oI": {
                "snippet": {
                    "publishedAt": "2023-12-01T09:57:58Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping for Beginners Live, PLUS Challenge Site",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ZhQcUNlR0oI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ZhQcUNlR0oI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ZhQcUNlR0oI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ZhQcUNlR0oI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ZhQcUNlR0oI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping for Beginners Live, PLUS Challenge Site",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "4916",
                    "likeCount": "164",
                    "favoriteCount": "0",
                    "commentCount": "7"
                },
                "contentDetails": {
                    "duration": "PT1H15M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "n_EGHAF3SDQ": {
                "snippet": {
                    "publishedAt": "2023-11-29T14:11:46Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This is the ONLY way I'll use Selenium now",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nSince trying out Selenium Grid, its the only way I use Selenium now. With Docker is easy to setup and run, allowing concurrent requests meaning faster scraping and greater flexibility and use cases.\n\n00:00 Intro\n00:55 Starter Code\n02:42 Grid via Jar file\n03:22 Code Changes\n04:59 Concurrent Futures\n06:59 Docker\n\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/n_EGHAF3SDQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/n_EGHAF3SDQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/n_EGHAF3SDQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/n_EGHAF3SDQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/n_EGHAF3SDQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This is the ONLY way I'll use Selenium now",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nSince trying out Selenium Grid, its the only way I use Selenium now. With Docker is easy to setup and run, allowing concurrent requests meaning faster scraping and greater flexibility and use cases.\n\n00:00 Intro\n00:55 Starter Code\n02:42 Grid via Jar file\n03:22 Code Changes\n04:59 Concurrent Futures\n06:59 Docker\n\n\nIf you are new, welcome! I am John, a self taught Python developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "8325",
                    "likeCount": "318",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT9M27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "NKB0PyqQD0U": {
                "snippet": {
                    "publishedAt": "2023-11-24T09:17:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy + Redis? Spider From a Queue? & 60K Subs Stream",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/NKB0PyqQD0U/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/NKB0PyqQD0U/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/NKB0PyqQD0U/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/NKB0PyqQD0U/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/NKB0PyqQD0U/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy + Redis? Spider From a Queue? & 60K Subs Stream",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "1789",
                    "likeCount": "61",
                    "favoriteCount": "0",
                    "commentCount": "0"
                },
                "contentDetails": {
                    "duration": "PT44M12S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ZOY6_is4SBM": {
                "snippet": {
                    "publishedAt": "2023-11-22T14:46:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping HTML Tables VS Dynamic JavaScript Tables",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nSeeing dynamic pages often puts beginners off, but I'm here to show you that scraping data from JavaScript rendered tables is easy and often I'd rather do that than parse HTML.\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ZOY6_is4SBM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ZOY6_is4SBM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ZOY6_is4SBM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ZOY6_is4SBM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ZOY6_is4SBM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping HTML Tables VS Dynamic JavaScript Tables",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nSeeing dynamic pages often puts beginners off, but I'm here to show you that scraping data from JavaScript rendered tables is easy and often I'd rather do that than parse HTML.\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "4238",
                    "likeCount": "128",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT6M34S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GUL4TrVh3Fc": {
                "snippet": {
                    "publishedAt": "2023-11-21T10:53:43Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Planning Next Web Scraping Video",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GUL4TrVh3Fc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GUL4TrVh3Fc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GUL4TrVh3Fc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GUL4TrVh3Fc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/GUL4TrVh3Fc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Planning Next Web Scraping Video",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "873",
                    "likeCount": "33",
                    "favoriteCount": "0",
                    "commentCount": "0"
                },
                "contentDetails": {
                    "duration": "PT54M5S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "TW3E00QvQ4U": {
                "snippet": {
                    "publishedAt": "2023-11-20T10:25:27Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Talking Python and Stream test settings",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/TW3E00QvQ4U/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/TW3E00QvQ4U/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/TW3E00QvQ4U/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/TW3E00QvQ4U/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/TW3E00QvQ4U/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Talking Python and Stream test settings",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "972",
                    "likeCount": "34",
                    "favoriteCount": "0",
                    "commentCount": "0"
                },
                "contentDetails": {
                    "duration": "PT50M46S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "4tRRAOlBh_k": {
                "snippet": {
                    "publishedAt": "2023-11-18T11:02:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "A look at scraping with Elixir and chatting",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/4tRRAOlBh_k/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/4tRRAOlBh_k/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/4tRRAOlBh_k/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/4tRRAOlBh_k/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/4tRRAOlBh_k/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "A look at scraping with Elixir and chatting",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR"
                    },
                    "defaultAudioLanguage": "en-US"
                },
                "statistics": {
                    "viewCount": "2105",
                    "likeCount": "60",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT1H8M49S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "r7pMqU2kYqc": {
                "snippet": {
                    "publishedAt": "2023-11-16T13:23:41Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy in 30 Minutes (start here.)",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the 5th video in the learn web scraping series, learning to use Python's premier scraping framework, Scrapy. We will redo the project from scratch and compare the code we have written to how it looks in Scrapy.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/r7pMqU2kYqc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/r7pMqU2kYqc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/r7pMqU2kYqc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/r7pMqU2kYqc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/r7pMqU2kYqc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy in 30 Minutes (start here.)",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the 5th video in the learn web scraping series, learning to use Python's premier scraping framework, Scrapy. We will redo the project from scratch and compare the code we have written to how it looks in Scrapy.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I recommend https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "17909",
                    "likeCount": "523",
                    "favoriteCount": "0",
                    "commentCount": "49"
                },
                "contentDetails": {
                    "duration": "PT30M2S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Q_ZLJ77zApY": {
                "snippet": {
                    "publishedAt": "2023-11-08T14:41:34Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Webscraping with Python How to Save to CSV, JSON and Clean Data",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the fourth video in the webscraping 101 series, aimed out how to export out scraped data to json and csv, along with some simple data cleaning pipelines.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Q_ZLJ77zApY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Q_ZLJ77zApY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Q_ZLJ77zApY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Q_ZLJ77zApY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Q_ZLJ77zApY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Webscraping with Python How to Save to CSV, JSON and Clean Data",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the fourth video in the webscraping 101 series, aimed out how to export out scraped data to json and csv, along with some simple data cleaning pipelines.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "6040",
                    "likeCount": "220",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT20M5S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uj2qi3uuQtU": {
                "snippet": {
                    "publishedAt": "2023-10-22T13:22:27Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "30 lines of GO Code to Scrape Anything",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIt's no secret to my regular viewers that I have a soft spot for GO and whenever I come accross things like Geziyor that I didn't know existed I'm aways happy to try them out. This one doesn't disappoint either, very Scrapy-like and with build in JS Rendering it looks to be a really good example of a web scraping framework outside of Python. This is a preliminary look aimed at showing you quickly what it can do in hope that you try it yourself and report back (in the discord wink wink!)\n\nhttps://github.com/geziyor/geziyor\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nIPRoyal Proxies I use https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uj2qi3uuQtU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uj2qi3uuQtU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uj2qi3uuQtU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uj2qi3uuQtU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uj2qi3uuQtU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "30 lines of GO Code to Scrape Anything",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIt's no secret to my regular viewers that I have a soft spot for GO and whenever I come accross things like Geziyor that I didn't know existed I'm aways happy to try them out. This one doesn't disappoint either, very Scrapy-like and with build in JS Rendering it looks to be a really good example of a web scraping framework outside of Python. This is a preliminary look aimed at showing you quickly what it can do in hope that you try it yourself and report back (in the discord wink wink!)\n\nhttps://github.com/geziyor/geziyor\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nIPRoyal Proxies I use https://iproyal.com/?r=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "8161",
                    "likeCount": "296",
                    "favoriteCount": "0",
                    "commentCount": "29"
                },
                "contentDetails": {
                    "duration": "PT6M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "DHvzCVLv_FA": {
                "snippet": {
                    "publishedAt": "2023-10-18T13:02:22Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with Python - Get URLs, Extract Data",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the third video in the series of scraping data for beginners. We're going to add functionality to scrape from the actual product pages rather than just the search page. Adding in dataclasses will also help us handle our data.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/DHvzCVLv_FA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/DHvzCVLv_FA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/DHvzCVLv_FA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/DHvzCVLv_FA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/DHvzCVLv_FA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with Python - Get URLs, Extract Data",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the third video in the series of scraping data for beginners. We're going to add functionality to scrape from the actual product pages rather than just the search page. Adding in dataclasses will also help us handle our data.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "10718",
                    "likeCount": "338",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT20M50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ZgVus_rmDBQ": {
                "snippet": {
                    "publishedAt": "2023-10-17T12:58:44Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with Python - How to handle pagination",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the second video in the series of scraping data for beginners. We're gonna to really clean up our code by adding functions and adding support for pagination, including how to break out of loops.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ZgVus_rmDBQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ZgVus_rmDBQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ZgVus_rmDBQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ZgVus_rmDBQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ZgVus_rmDBQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with Python - How to handle pagination",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the second video in the series of scraping data for beginners. We're gonna to really clean up our code by adding functions and adding support for pagination, including how to break out of loops.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "10780",
                    "likeCount": "386",
                    "favoriteCount": "0",
                    "commentCount": "44"
                },
                "contentDetails": {
                    "duration": "PT17M52S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "36l1-gjLU0o": {
                "snippet": {
                    "publishedAt": "2023-10-17T07:53:28Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I Scrape with a headless Browser, a lot",
                    "description": "# DISCORD! : https://discord.gg/GgZGcHdt\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/36l1-gjLU0o/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/36l1-gjLU0o/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/36l1-gjLU0o/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/36l1-gjLU0o/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/36l1-gjLU0o/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I Scrape with a headless Browser, a lot",
                        "description": "# DISCORD! : https://discord.gg/GgZGcHdt\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "3618",
                    "likeCount": "110",
                    "favoriteCount": "0",
                    "commentCount": "1"
                },
                "contentDetails": {
                    "duration": "PT57M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "1PCWwK0AsE0": {
                "snippet": {
                    "publishedAt": "2023-10-16T13:20:55Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with Python - Start HERE",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the first video in the series of scraping data for beginners. I wanted to make sure we used a real website rather than the standard test site to give you an idea of a more common project you will want to complete. However this is still a basic example designed to get you started in the world of data extraction and web scraping.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nRundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you choose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/1PCWwK0AsE0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/1PCWwK0AsE0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/1PCWwK0AsE0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/1PCWwK0AsE0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/1PCWwK0AsE0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with Python - Start HERE",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nThis is the first video in the series of scraping data for beginners. I wanted to make sure we used a real website rather than the standard test site to give you an idea of a more common project you will want to complete. However this is still a basic example designed to get you started in the world of data extraction and web scraping.\n\nThis is a series so make sure you subscribe to get the remaining episodes as they are released!\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\n\nRecommender Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\n\nRundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\n\nProxies I use https://nodemaven.com/?a_aid=JohnWatsonRooney\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you choose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "37687",
                    "likeCount": "1284",
                    "favoriteCount": "0",
                    "commentCount": "91"
                },
                "contentDetails": {
                    "duration": "PT20M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "cOXdNXEf1OQ": {
                "snippet": {
                    "publishedAt": "2023-10-12T08:35:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping Live + New Discord Server!",
                    "description": "# DISCORD! : https://discord.gg/C4J2uckpbR\n# Patreon: https://www.patreon.com/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/cOXdNXEf1OQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/cOXdNXEf1OQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/cOXdNXEf1OQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/cOXdNXEf1OQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/cOXdNXEf1OQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping Live + New Discord Server!",
                        "description": "# DISCORD! : https://discord.gg/C4J2uckpbR\n# Patreon: https://www.patreon.com/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "2178",
                    "likeCount": "87",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT1H6M39S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GRu117xiusQ": {
                "snippet": {
                    "publishedAt": "2023-10-08T15:06:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape Data with Multiple Selenium Instances",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nSelenium Grid first look for web scraping concurrently with headless chrome\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GRu117xiusQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GRu117xiusQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GRu117xiusQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GRu117xiusQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/GRu117xiusQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape Data with Multiple Selenium Instances",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nSelenium Grid first look for web scraping concurrently with headless chrome\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "13880",
                    "likeCount": "473",
                    "favoriteCount": "0",
                    "commentCount": "57"
                },
                "contentDetails": {
                    "duration": "PT12M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Op_7blG43uQ": {
                "snippet": {
                    "publishedAt": "2023-10-01T13:45:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Is This The Best Way to Scrape at Scale?",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nELT is a data concept that store the data into a datastore before transforming - it gives us access to the raw data to parse through later. I have heard of some people using this method for scraping data, saving pages of HTML into a database to query later so I thought I would try it out and see how I got on.\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Op_7blG43uQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Op_7blG43uQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Op_7blG43uQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Op_7blG43uQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Op_7blG43uQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Is This The Best Way to Scrape at Scale?",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nELT is a data concept that store the data into a datastore before transforming - it gives us access to the raw data to parse through later. I have heard of some people using this method for scraping data, saving pages of HTML into a database to query later so I thought I would try it out and see how I got on.\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "3903",
                    "likeCount": "160",
                    "favoriteCount": "0",
                    "commentCount": "25"
                },
                "contentDetails": {
                    "duration": "PT12M59S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "D5RTv_675yU": {
                "snippet": {
                    "publishedAt": "2023-09-27T12:45:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I swapped my project to Scrapy, was it a Mistake?",
                    "description": "I rewrote this scraper: https://youtu.be/iRR-kv-3u_c with Scrapy, I think it might be better? \n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/D5RTv_675yU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/D5RTv_675yU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/D5RTv_675yU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/D5RTv_675yU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/D5RTv_675yU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I swapped my project to Scrapy, was it a Mistake?",
                        "description": "I rewrote this scraper: https://youtu.be/iRR-kv-3u_c with Scrapy, I think it might be better? \n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "3391",
                    "likeCount": "110",
                    "favoriteCount": "0",
                    "commentCount": "30"
                },
                "contentDetails": {
                    "duration": "PT13M32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "fMYPAd3kgeU": {
                "snippet": {
                    "publishedAt": "2023-09-23T12:19:59Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I Don't Parse with Selenium (Just get me the HTML)",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/fMYPAd3kgeU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/fMYPAd3kgeU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/fMYPAd3kgeU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/fMYPAd3kgeU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/fMYPAd3kgeU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "selenium",
                        "python selenium",
                        "python",
                        "web scraping",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I Don't Parse with Selenium (Just get me the HTML)",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "4918",
                    "likeCount": "172",
                    "favoriteCount": "0",
                    "commentCount": "24"
                },
                "contentDetails": {
                    "duration": "PT7M29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "vxvqNvc75KU": {
                "snippet": {
                    "publishedAt": "2023-09-17T16:37:47Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Sending API URL Queries with Python Requests",
                    "description": "Learn how to use requests to send query params quickly and easily uses dicts and dataclasses.\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/vxvqNvc75KU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/vxvqNvc75KU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/vxvqNvc75KU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/vxvqNvc75KU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/vxvqNvc75KU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Sending API URL Queries with Python Requests",
                        "description": "Learn how to use requests to send query params quickly and easily uses dicts and dataclasses.\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "6703",
                    "likeCount": "268",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT9M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "5__nYFNZM6M": {
                "snippet": {
                    "publishedAt": "2023-09-13T12:45:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This Scraping Package is Coming back?",
                    "description": "Requests-HTML is an all in one scraping library for Python and with a couple of fixes still works well. Its main USP for me is everything included in one, requests, html parsing with css selectors, and rendering javascript pages with headless chrome.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/5__nYFNZM6M/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/5__nYFNZM6M/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/5__nYFNZM6M/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/5__nYFNZM6M/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/5__nYFNZM6M/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This Scraping Package is Coming back?",
                        "description": "Requests-HTML is an all in one scraping library for Python and with a couple of fixes still works well. Its main USP for me is everything included in one, requests, html parsing with css selectors, and rendering javascript pages with headless chrome.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "2545",
                    "likeCount": "106",
                    "favoriteCount": "0",
                    "commentCount": "13"
                },
                "contentDetails": {
                    "duration": "PT7M8S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ToRYYt9daqE": {
                "snippet": {
                    "publishedAt": "2023-08-30T13:44:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping Product Data from Multiple Sites",
                    "description": "scraping multiple sites made easy by using a scraper script and json config file.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ToRYYt9daqE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ToRYYt9daqE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ToRYYt9daqE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ToRYYt9daqE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ToRYYt9daqE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping Product Data from Multiple Sites",
                        "description": "scraping multiple sites made easy by using a scraper script and json config file.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "6499",
                    "likeCount": "267",
                    "favoriteCount": "0",
                    "commentCount": "16"
                },
                "contentDetails": {
                    "duration": "PT12M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "HVWNRMEH9Ro": {
                "snippet": {
                    "publishedAt": "2023-08-16T14:46:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This script I threw together saves me hours.",
                    "description": "Finding out the best way to scrape data from a site is time consuming, this script uses selenium wire to view the network requests from a site and give you back a list of urls and json responses.\n\n# Proxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/HVWNRMEH9Ro/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/HVWNRMEH9Ro/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/HVWNRMEH9Ro/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/HVWNRMEH9Ro/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/HVWNRMEH9Ro/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This script I threw together saves me hours.",
                        "description": "Finding out the best way to scrape data from a site is time consuming, this script uses selenium wire to view the network requests from a site and give you back a list of urls and json responses.\n\n# Proxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW free tier)\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "20636",
                    "likeCount": "962",
                    "favoriteCount": "0",
                    "commentCount": "73"
                },
                "contentDetails": {
                    "duration": "PT13M38S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "aQkdg3P0L4Y": {
                "snippet": {
                    "publishedAt": "2023-07-30T13:45:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "2 Ways to add Logging to your Python Code",
                    "description": "Yes sometimes I log with print(). I know..\n\n\nhttps://github.com/jhnwr/youtube\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/aQkdg3P0L4Y/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/aQkdg3P0L4Y/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/aQkdg3P0L4Y/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/aQkdg3P0L4Y/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/aQkdg3P0L4Y/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "2 Ways to add Logging to your Python Code",
                        "description": "Yes sometimes I log with print(). I know..\n\n\nhttps://github.com/jhnwr/youtube\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "4753",
                    "likeCount": "184",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT9M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "80IAKt1qCKo": {
                "snippet": {
                    "publishedAt": "2023-07-23T14:45:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Browsers are Essential now? Scraping Amazon in 2023",
                    "description": "Scraping Amazon in 2023 using Playwright and Python.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/80IAKt1qCKo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/80IAKt1qCKo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/80IAKt1qCKo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/80IAKt1qCKo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/80IAKt1qCKo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Browsers are Essential now? Scraping Amazon in 2023",
                        "description": "Scraping Amazon in 2023 using Playwright and Python.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "15390",
                    "likeCount": "537",
                    "favoriteCount": "0",
                    "commentCount": "75"
                },
                "contentDetails": {
                    "duration": "PT14M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "i1lFRRSbvSI": {
                "snippet": {
                    "publishedAt": "2023-07-16T14:45:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Why you get an Attribute Error scraping data (and how to fix it)",
                    "description": "Avoid the dreaded attribute error when web scraping by creating your own text extract function\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/i1lFRRSbvSI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/i1lFRRSbvSI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/i1lFRRSbvSI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/i1lFRRSbvSI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/i1lFRRSbvSI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Why you get an Attribute Error scraping data (and how to fix it)",
                        "description": "Avoid the dreaded attribute error when web scraping by creating your own text extract function\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "5510",
                    "likeCount": "221",
                    "favoriteCount": "0",
                    "commentCount": "24"
                },
                "contentDetails": {
                    "duration": "PT7M",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xIREsEZMz0I": {
                "snippet": {
                    "publishedAt": "2023-07-03T19:48:23Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This Python Library makes CLI tools a breeze.",
                    "description": "I love a good CLI tool and in this video I will show you how I use Click to create a basic tool to grab the latest episode information from a podcast I listen to, GoTime!\n\nhttps://github.com/jhnwr/youtube/tree/main/scrapercli\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xIREsEZMz0I/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xIREsEZMz0I/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xIREsEZMz0I/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xIREsEZMz0I/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xIREsEZMz0I/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This Python Library makes CLI tools a breeze.",
                        "description": "I love a good CLI tool and in this video I will show you how I use Click to create a basic tool to grab the latest episode information from a podcast I listen to, GoTime!\n\nhttps://github.com/jhnwr/youtube/tree/main/scrapercli\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "5724",
                    "likeCount": "180",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT9M59S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "T1xAqWNdfoY": {
                "snippet": {
                    "publishedAt": "2023-06-25T14:37:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Add a Database to your Web Scraper - Full Code How to",
                    "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/T1xAqWNdfoY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/T1xAqWNdfoY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/T1xAqWNdfoY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/T1xAqWNdfoY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/T1xAqWNdfoY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Add a Database to your Web Scraper - Full Code How to",
                        "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "12551",
                    "likeCount": "327",
                    "favoriteCount": "0",
                    "commentCount": "24"
                },
                "contentDetails": {
                    "duration": "PT25M17S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uVCE0CxrpV8": {
                "snippet": {
                    "publishedAt": "2023-06-11T13:00:40Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Who is FASTER? Scrapy vs GO vs ME",
                    "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nA fun look at scraping 3 ways, to see which is fastest, Scrapy, GO, or my own ASYNC code\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uVCE0CxrpV8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uVCE0CxrpV8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uVCE0CxrpV8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uVCE0CxrpV8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uVCE0CxrpV8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Who is FASTER? Scrapy vs GO vs ME",
                        "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nA fun look at scraping 3 ways, to see which is fastest, Scrapy, GO, or my own ASYNC code\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "6752",
                    "likeCount": "169",
                    "favoriteCount": "0",
                    "commentCount": "18"
                },
                "contentDetails": {
                    "duration": "PT7M41S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WZshV5nYVQc": {
                "snippet": {
                    "publishedAt": "2023-06-04T13:51:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape .aspx sites with this method",
                    "description": "most of the test sites are easy to scrape but unless you know how you could easily get stuck on this aspx site with drop down boxes. In this video i'll show you how to scrape these sites using the viewstate header to grab all the data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WZshV5nYVQc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WZshV5nYVQc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WZshV5nYVQc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WZshV5nYVQc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WZshV5nYVQc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "web scraping tutorial",
                        "aspx scraper",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape .aspx sites with this method",
                        "description": "most of the test sites are easy to scrape but unless you know how you could easily get stuck on this aspx site with drop down boxes. In this video i'll show you how to scrape these sites using the viewstate header to grab all the data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "9905",
                    "likeCount": "211",
                    "favoriteCount": "0",
                    "commentCount": "24"
                },
                "contentDetails": {
                    "duration": "PT12M11S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "zZSAQxdJFcQ": {
                "snippet": {
                    "publishedAt": "2023-05-28T13:45:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Use THIS to stay JUST under rate limits with Async",
                    "description": "AIOLimiter lets you control your async requests using a leaky bucket system, this can be very useful for implementing async when you still need to come under a rate limit.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/zZSAQxdJFcQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/zZSAQxdJFcQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/zZSAQxdJFcQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/zZSAQxdJFcQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/zZSAQxdJFcQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Use THIS to stay JUST under rate limits with Async",
                        "description": "AIOLimiter lets you control your async requests using a leaky bucket system, this can be very useful for implementing async when you still need to come under a rate limit.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "9488",
                    "likeCount": "403",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT6M36S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "1QyORzuRedE": {
                "snippet": {
                    "publishedAt": "2023-05-21T15:58:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Supercharge Your Scraper With ASYNC (here's how)",
                    "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nAsync can make your code way more efficient by allowing it to do extra work inbetween waiting for requests and responses. In this video I will show you how to implement async into a web scraper and drastically reduce the time taken to scrape 1000 pages of data.\n\nhttps://github.com/jhnwr/youtube/tree/main/synctoasync\n\noriginal code video: https://youtu.be/iRR-kv-3u_c\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/1QyORzuRedE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/1QyORzuRedE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/1QyORzuRedE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/1QyORzuRedE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/1QyORzuRedE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python",
                        "async",
                        "async/await",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Supercharge Your Scraper With ASYNC (here's how)",
                        "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nAsync can make your code way more efficient by allowing it to do extra work inbetween waiting for requests and responses. In this video I will show you how to implement async into a web scraper and drastically reduce the time taken to scrape 1000 pages of data.\n\nhttps://github.com/jhnwr/youtube/tree/main/synctoasync\n\noriginal code video: https://youtu.be/iRR-kv-3u_c\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "11499",
                    "likeCount": "357",
                    "favoriteCount": "0",
                    "commentCount": "17"
                },
                "contentDetails": {
                    "duration": "PT14M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "iRR-kv-3u_c": {
                "snippet": {
                    "publishedAt": "2023-05-14T13:45:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Modern HTML Scraping with Pythons BEST Tools",
                    "description": "There's still plenty of modern sites that are HTML and can be scraped using simple methods. In this video I code from scratch a complete web scraping project up to saving the data. I will use dataclasses, handle responses, use urljoin and scrape detail pages and pagination.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/iRR-kv-3u_c/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/iRR-kv-3u_c/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/iRR-kv-3u_c/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/iRR-kv-3u_c/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/iRR-kv-3u_c/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "html parsing",
                        "selectolax",
                        "httpx",
                        "john watson rooney",
                        "python web scraping",
                        "python",
                        "learn",
                        "code",
                        "tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Modern HTML Scraping with Pythons BEST Tools",
                        "description": "There's still plenty of modern sites that are HTML and can be scraped using simple methods. In this video I code from scratch a complete web scraping project up to saving the data. I will use dataclasses, handle responses, use urljoin and scrape detail pages and pagination.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "13788",
                    "likeCount": "599",
                    "favoriteCount": "0",
                    "commentCount": "61"
                },
                "contentDetails": {
                    "duration": "PT24M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xzxWLVCUvLo": {
                "snippet": {
                    "publishedAt": "2023-05-10T12:55:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Just Use Pydantic",
                    "description": "Pydantic is great for data validation and parsing, giving us a much better option that standard for working with data in Python. In this video I will show you how to create Pydantic models from shopify product json where we don't want to include large amounts of the data. by adding in to our models only the fields we are interested in we can omit the rest of the data and avoid having to write and rewrite complex indexing and gets on our dictionary, improving readability and usage\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xzxWLVCUvLo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xzxWLVCUvLo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xzxWLVCUvLo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xzxWLVCUvLo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xzxWLVCUvLo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python pydantic",
                        "pydantic models",
                        "data validation",
                        "learn python",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Just Use Pydantic",
                        "description": "Pydantic is great for data validation and parsing, giving us a much better option that standard for working with data in Python. In this video I will show you how to create Pydantic models from shopify product json where we don't want to include large amounts of the data. by adding in to our models only the fields we are interested in we can omit the rest of the data and avoid having to write and rewrite complex indexing and gets on our dictionary, improving readability and usage\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr"
                    }
                },
                "statistics": {
                    "viewCount": "25368",
                    "likeCount": "717",
                    "favoriteCount": "0",
                    "commentCount": "30"
                },
                "contentDetails": {
                    "duration": "PT8M11S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "vnDNoBn1Jf4": {
                "snippet": {
                    "publishedAt": "2023-05-07T13:45:07Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Are CLI Frameworks Worth it? Trying TYPER",
                    "description": "Having a look at building better CLI apps with Python and Typer - a framework from tiangolo (FastAPI)\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 Explanation\n00:41 Initial App\n02:37 Scraper\n06:13 Improvements",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/vnDNoBn1Jf4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/vnDNoBn1Jf4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/vnDNoBn1Jf4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/vnDNoBn1Jf4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/vnDNoBn1Jf4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python cli",
                        "web scraping",
                        "amazon web scraping",
                        "learn python",
                        "cli python",
                        "python typer",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Are CLI Frameworks Worth it? Trying TYPER",
                        "description": "Having a look at building better CLI apps with Python and Typer - a framework from tiangolo (FastAPI)\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 Explanation\n00:41 Initial App\n02:37 Scraper\n06:13 Improvements"
                    }
                },
                "statistics": {
                    "viewCount": "9485",
                    "likeCount": "276",
                    "favoriteCount": "0",
                    "commentCount": "14"
                },
                "contentDetails": {
                    "duration": "PT11M23S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "VDf7nfjLwRU": {
                "snippet": {
                    "publishedAt": "2023-04-22T13:00:27Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "3 Ways To Scrape Infinite Scroll Sites with Playwright",
                    "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nThis is a great method for easily scraping infinite scroll websites. Three ways to scroll down the page in playwright, and using the network events we can easily expose JSON data being transferred from the websites backend.\n\nI use this method a lot for exploring sites and seeing whats going on but it's also a great way to extract data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/VDf7nfjLwRU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/VDf7nfjLwRU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/VDf7nfjLwRU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/VDf7nfjLwRU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/VDf7nfjLwRU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "web scraping",
                        "python web scraping",
                        "infinite scroll",
                        "data extraction"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "3 Ways To Scrape Infinite Scroll Sites with Playwright",
                        "description": "Check out ScrapingBee for youself here: https://www.scrapingbee.com/?utm_source=youtube&utm_medium=link&utm_campaign=jwrooney\n\nThis is a great method for easily scraping infinite scroll websites. Three ways to scroll down the page in playwright, and using the network events we can easily expose JSON data being transferred from the websites backend.\n\nI use this method a lot for exploring sites and seeing whats going on but it's also a great way to extract data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "21721",
                    "likeCount": "489",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT12M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_SDkkb80AEk": {
                "snippet": {
                    "publishedAt": "2023-04-14T23:28:20Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Don't Rush into Freelancing, I did and Made this Mistake",
                    "description": "Getting your first clients is always a challenge, but when you get there make sure you don't make this massive mistake when taking on work. Always write up a complete in detail scope/brief of what you are going to do, how long it is going to take and what you are going to charge. Get it written up and agreed by your clients.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_SDkkb80AEk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_SDkkb80AEk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_SDkkb80AEk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_SDkkb80AEk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_SDkkb80AEk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "freelance code",
                        "starting freelancing",
                        "freelance coding"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Don't Rush into Freelancing, I did and Made this Mistake",
                        "description": "Getting your first clients is always a challenge, but when you get there make sure you don't make this massive mistake when taking on work. Always write up a complete in detail scope/brief of what you are going to do, how long it is going to take and what you are going to charge. Get it written up and agreed by your clients.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "5660",
                    "likeCount": "318",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT6M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "qX0jZqlmO2o": {
                "snippet": {
                    "publishedAt": "2023-03-29T11:45:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy is THE best, but I don't use it.",
                    "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 02:14 Find out more at iproyal.club/JohnWatsonRooney\n\nI've been asked before why I don't use Scrapy as much in my videos, and whether I use it for my own projects. The answer is I don't really, and in this video I explain why.\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 Hardest Part of Scraping\n01:00 Why I Don't use it\n02:14 IPRoyal\n03:22 Scrapy Usecases\n04:45 For beginners?\n05:24 What I Use",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/qX0jZqlmO2o/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/qX0jZqlmO2o/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/qX0jZqlmO2o/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/qX0jZqlmO2o/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/qX0jZqlmO2o/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "learning scrapy",
                        "web scraping",
                        "python",
                        "python scrapy",
                        "learn scrapy",
                        "python web scraping",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy is THE best, but I don't use it.",
                        "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 02:14 Find out more at iproyal.club/JohnWatsonRooney\n\nI've been asked before why I don't use Scrapy as much in my videos, and whether I use it for my own projects. The answer is I don't really, and in this video I explain why.\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 Hardest Part of Scraping\n01:00 Why I Don't use it\n02:14 IPRoyal\n03:22 Scrapy Usecases\n04:45 For beginners?\n05:24 What I Use"
                    }
                },
                "statistics": {
                    "viewCount": "9476",
                    "likeCount": "304",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT6M14S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "UvFphlHWchU": {
                "snippet": {
                    "publishedAt": "2023-03-26T14:45:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping Made Easy Using this Method.",
                    "description": "Sometimes it is that easy - check for the websites API and make a curl request, you might find its open and available! this video shows how to check, grab and export such data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/UvFphlHWchU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/UvFphlHWchU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/UvFphlHWchU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/UvFphlHWchU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/UvFphlHWchU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python",
                        "john watson rooney",
                        "coding tutorial",
                        "how to scrape data",
                        "scraping dynamic content",
                        "scraping javascript"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping Made Easy Using this Method.",
                        "description": "Sometimes it is that easy - check for the websites API and make a curl request, you might find its open and available! this video shows how to check, grab and export such data.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "12137",
                    "likeCount": "407",
                    "favoriteCount": "0",
                    "commentCount": "28"
                },
                "contentDetails": {
                    "duration": "PT9M41S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "sTefsbUCLL0": {
                "snippet": {
                    "publishedAt": "2023-03-22T14:19:56Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "You Should Make Your OWN HTTP Clients for APIs (Shopify x Python)",
                    "description": "in this video I look at using inheritance and subclasses with python to create a simple API client class to make requesting data from the shopify API easier. There is a Python SDK for Shopify but I wanted to make my own simpler client I can reuse to grab data from stores. Using \"super()\" we can inherit from the requests.Session class and add in the few bits we need, to manage the rate limiting and sending the token for each request.\n\nhttps://github.com/jhnwr/youtube/tree/main/subclasses-http-client\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/sTefsbUCLL0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/sTefsbUCLL0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/sTefsbUCLL0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/sTefsbUCLL0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/sTefsbUCLL0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "shopify",
                        "http client",
                        "shopify rate limit",
                        "python subclass",
                        "python super()"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "You Should Make Your OWN HTTP Clients for APIs (Shopify x Python)",
                        "description": "in this video I look at using inheritance and subclasses with python to create a simple API client class to make requesting data from the shopify API easier. There is a Python SDK for Shopify but I wanted to make my own simpler client I can reuse to grab data from stores. Using \"super()\" we can inherit from the requests.Session class and add in the few bits we need, to manage the rate limiting and sending the token for each request.\n\nhttps://github.com/jhnwr/youtube/tree/main/subclasses-http-client\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "8007",
                    "likeCount": "251",
                    "favoriteCount": "0",
                    "commentCount": "17"
                },
                "contentDetails": {
                    "duration": "PT12M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "0MjH90eS9-w": {
                "snippet": {
                    "publishedAt": "2023-03-15T13:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Parse Data Scraped from SCRIPT tags",
                    "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 03:37 Find out more at iproyal.club/JohnWatsonRooney\n\nIt's easy to get carried away and forget to check all the obvious signs that the data is right there for you.. this video demonstrates the web scraping method of parsing information from inside the script tag on the page.\n\nThis is usually passed into the HTML by the JavaScript framework.\n\nhttps://github.com/Nykakin/chompjs\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/0MjH90eS9-w/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/0MjH90eS9-w/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/0MjH90eS9-w/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/0MjH90eS9-w/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/0MjH90eS9-w/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Parse Data Scraped from SCRIPT tags",
                        "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 03:37 Find out more at iproyal.club/JohnWatsonRooney\n\nIt's easy to get carried away and forget to check all the obvious signs that the data is right there for you.. this video demonstrates the web scraping method of parsing information from inside the script tag on the page.\n\nThis is usually passed into the HTML by the JavaScript framework.\n\nhttps://github.com/Nykakin/chompjs\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "7542",
                    "likeCount": "256",
                    "favoriteCount": "0",
                    "commentCount": "22"
                },
                "contentDetails": {
                    "duration": "PT10M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "4WQba4KwmRs": {
                "snippet": {
                    "publishedAt": "2023-03-08T14:00:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Try THIS Simple Python Decorator (It's Super Useful)",
                    "description": "Decorators in Python have lots of great uses, and I think this one is one of the simplest yet most powerful uses to help avoid bugs and keep your code neat and tidy.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/4WQba4KwmRs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/4WQba4KwmRs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/4WQba4KwmRs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/4WQba4KwmRs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/4WQba4KwmRs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "python",
                        "learn python",
                        "python decorator",
                        "python decorators",
                        "registration decorator",
                        "python coding",
                        "python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Try THIS Simple Python Decorator (It's Super Useful)",
                        "description": "Decorators in Python have lots of great uses, and I think this one is one of the simplest yet most powerful uses to help avoid bugs and keep your code neat and tidy.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "9876",
                    "likeCount": "459",
                    "favoriteCount": "0",
                    "commentCount": "24"
                },
                "contentDetails": {
                    "duration": "PT3M37S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "-vmwfiky5QA": {
                "snippet": {
                    "publishedAt": "2023-03-07T22:15:55Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Flatten Lists of Lists with |Itertools CHAIN",
                    "description": "itertools is one of the best things in the standard python library! use chain, you won't regret it.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/-vmwfiky5QA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/-vmwfiky5QA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/-vmwfiky5QA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/-vmwfiky5QA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/-vmwfiky5QA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Flatten Lists of Lists with |Itertools CHAIN",
                        "description": "itertools is one of the best things in the standard python library! use chain, you won't regret it."
                    }
                },
                "statistics": {
                    "viewCount": "4792",
                    "likeCount": "301",
                    "favoriteCount": "0",
                    "commentCount": "13"
                },
                "contentDetails": {
                    "duration": "PT58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GAGM7HddbEk": {
                "snippet": {
                    "publishedAt": "2023-02-27T13:36:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Don't Keep Requesting API Data, DO THIS!",
                    "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 02:05 Find out more at iproyal.club/JohnWatsonRooney\n\nFind out how to start using basic caching in your API responses and FastAPI application with requests-cache\n\nUPDATE\nSil Kogelman:\n\n\"A little code update is required to make the code from this tutorial run.\nrequests_cache released version 1.0.0 on 2023-03-01 with a breaking change:\nline 23 and 26 now need () after session.cache.urls as it has been replaced with a method that returns a list of sorted unique URLs. \"\n\nhttps://github.com/requests-cache/requests-cache\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\n\nTimestamps\n00:00 intro\n00:19 functools cache\n02:05 IPRoyal\n03:10 Requests-cache\n07:06 FastAPI with Cache",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GAGM7HddbEk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GAGM7HddbEk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GAGM7HddbEk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GAGM7HddbEk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/GAGM7HddbEk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "python",
                        "caching",
                        "fastapi"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Don't Keep Requesting API Data, DO THIS!",
                        "description": "Grab IPRoyal Proxies with a 30% discount while it lasts! Click here to find the 30% off coupon code: 02:05 Find out more at iproyal.club/JohnWatsonRooney\n\nFind out how to start using basic caching in your API responses and FastAPI application with requests-cache\n\nUPDATE\nSil Kogelman:\n\n\"A little code update is required to make the code from this tutorial run.\nrequests_cache released version 1.0.0 on 2023-03-01 with a breaking change:\nline 23 and 26 now need () after session.cache.urls as it has been replaced with a method that returns a list of sorted unique URLs. \"\n\nhttps://github.com/requests-cache/requests-cache\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: iproyal.club/JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\n\nTimestamps\n00:00 intro\n00:19 functools cache\n02:05 IPRoyal\n03:10 Requests-cache\n07:06 FastAPI with Cache"
                    }
                },
                "statistics": {
                    "viewCount": "11924",
                    "likeCount": "430",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT9M52S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_7pAlxV73ig": {
                "snippet": {
                    "publishedAt": "2023-02-17T17:32:38Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Film My YouTube Videos",
                    "description": "How I film Myself\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_7pAlxV73ig/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_7pAlxV73ig/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_7pAlxV73ig/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_7pAlxV73ig/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_7pAlxV73ig/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Film My YouTube Videos",
                        "description": "How I film Myself\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "4154",
                    "likeCount": "131",
                    "favoriteCount": "0",
                    "commentCount": "10"
                },
                "contentDetails": {
                    "duration": "PT17S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "tGejYtmppQI": {
                "snippet": {
                    "publishedAt": "2023-02-16T12:22:41Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping multiples websites with one Python script",
                    "description": "Writing a simple web scraping script to do some basic price comparison\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/tGejYtmppQI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/tGejYtmppQI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/tGejYtmppQI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/tGejYtmppQI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/tGejYtmppQI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "john watson rooney",
                        "web scrapping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping multiples websites with one Python script",
                        "description": "Writing a simple web scraping script to do some basic price comparison\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "25955",
                    "likeCount": "772",
                    "favoriteCount": "0",
                    "commentCount": "55"
                },
                "contentDetails": {
                    "duration": "PT8M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "s4_6c4_Cr90": {
                "snippet": {
                    "publishedAt": "2023-02-15T21:19:13Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "My Top 5 Neovim Colourschemes",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/s4_6c4_Cr90/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/s4_6c4_Cr90/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/s4_6c4_Cr90/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/s4_6c4_Cr90/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/s4_6c4_Cr90/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "My Top 5 Neovim Colourschemes",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "42121",
                    "likeCount": "1413",
                    "favoriteCount": "0",
                    "commentCount": "48"
                },
                "contentDetails": {
                    "duration": "PT29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "qYSWWGz9Z6s": {
                "snippet": {
                    "publishedAt": "2023-02-10T13:45:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Automate your job with Python",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nLearning automation with Python and Playwright can save you hours of work! Use the codegen feature to make it easy too\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/qYSWWGz9Z6s/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/qYSWWGz9Z6s/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/qYSWWGz9Z6s/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/qYSWWGz9Z6s/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/qYSWWGz9Z6s/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python automation",
                        "python palywright",
                        "jobn watson rooney",
                        "python playwright",
                        "playwright automation",
                        "python automation tutorial",
                        "python automation projects",
                        "python automation ideas"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Automate your job with Python",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nLearning automation with Python and Playwright can save you hours of work! Use the codegen feature to make it easy too\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "420781",
                    "likeCount": "16070",
                    "favoriteCount": "0",
                    "commentCount": "279"
                },
                "contentDetails": {
                    "duration": "PT6M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "v4Z_Nwb4fgw": {
                "snippet": {
                    "publishedAt": "2023-02-07T22:02:41Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Named Slices in Python Improves Readability",
                    "description": "Assigning your slices to a variable, aka naming them, helps improve the readability of your code 10x and helps when dealing with structured data from more unusual formats and places.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/v4Z_Nwb4fgw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/v4Z_Nwb4fgw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/v4Z_Nwb4fgw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/v4Z_Nwb4fgw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/v4Z_Nwb4fgw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Named Slices in Python Improves Readability",
                        "description": "Assigning your slices to a variable, aka naming them, helps improve the readability of your code 10x and helps when dealing with structured data from more unusual formats and places."
                    }
                },
                "statistics": {
                    "viewCount": "10789",
                    "likeCount": "539",
                    "favoriteCount": "0",
                    "commentCount": "14"
                },
                "contentDetails": {
                    "duration": "PT25S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "wUSgA8WEy4Q": {
                "snippet": {
                    "publishedAt": "2023-02-03T15:08:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with GO... Easy AND Fast?!",
                    "description": "This has to be the easiest way I've ever implemented ASync web scraping, and its super fast. Go and Colly have been great for pure HTML web scraping, allowing easy crawling of pages, data gathering and providing a generally good experience overall. I know its not Python but I think its well worth checking out.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n\n00:00 Intro\n00:30 Scraper Code\n10:20 Refactor & Async",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/wUSgA8WEy4Q/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/wUSgA8WEy4Q/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/wUSgA8WEy4Q/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/wUSgA8WEy4Q/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/wUSgA8WEy4Q/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "golang",
                        "golang projects",
                        "golang tutorial",
                        "golang tutorial for beginners",
                        "learn web scraping",
                        "john watson rooney",
                        "programming",
                        "web scraping tutorial",
                        "async scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with GO... Easy AND Fast?!",
                        "description": "This has to be the easiest way I've ever implemented ASync web scraping, and its super fast. Go and Colly have been great for pure HTML web scraping, allowing easy crawling of pages, data gathering and providing a generally good experience overall. I know its not Python but I think its well worth checking out.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n\n00:00 Intro\n00:30 Scraper Code\n10:20 Refactor & Async"
                    }
                },
                "statistics": {
                    "viewCount": "12769",
                    "likeCount": "349",
                    "favoriteCount": "0",
                    "commentCount": "43"
                },
                "contentDetails": {
                    "duration": "PT14M35S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8YP378HHgdE": {
                "snippet": {
                    "publishedAt": "2023-02-03T00:11:26Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Easy Executable with GOlang",
                    "description": "Making my web scraping into a exe file for mac windows and linux, with one command?!",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8YP378HHgdE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8YP378HHgdE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8YP378HHgdE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8YP378HHgdE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8YP378HHgdE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Easy Executable with GOlang",
                        "description": "Making my web scraping into a exe file for mac windows and linux, with one command?!"
                    }
                },
                "statistics": {
                    "viewCount": "6868",
                    "likeCount": "163",
                    "favoriteCount": "0",
                    "commentCount": "5"
                },
                "contentDetails": {
                    "duration": "PT24S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "st7RG6Bzyxs": {
                "snippet": {
                    "publishedAt": "2023-01-30T15:05:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping Methods You NEED to Know",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nThe most common web scraping techniques you need to know\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/st7RG6Bzyxs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/st7RG6Bzyxs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/st7RG6Bzyxs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/st7RG6Bzyxs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/st7RG6Bzyxs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scrapping",
                        "web scraping",
                        "john watson rooney",
                        "python web scraping",
                        "web scraping tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping Methods You NEED to Know",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nThe most common web scraping techniques you need to know\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "15007",
                    "likeCount": "492",
                    "favoriteCount": "0",
                    "commentCount": "48"
                },
                "contentDetails": {
                    "duration": "PT7M42S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "qhB5K-6vu00": {
                "snippet": {
                    "publishedAt": "2023-01-29T16:27:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "ASYNC web scraping with GO and Colly.",
                    "description": "Adding ASYNC capabilities to a Go Colly web scraping project is simple and provides great results. more and more GO is proving to be a fantastic language for scraping basic data, but it still lags behind Python when it comes to data science as this is not what GO is intended for",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/qhB5K-6vu00/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/qhB5K-6vu00/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/qhB5K-6vu00/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/qhB5K-6vu00/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/qhB5K-6vu00/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "ASYNC web scraping with GO and Colly.",
                        "description": "Adding ASYNC capabilities to a Go Colly web scraping project is simple and provides great results. more and more GO is proving to be a fantastic language for scraping basic data, but it still lags behind Python when it comes to data science as this is not what GO is intended for"
                    }
                },
                "statistics": {
                    "viewCount": "8551",
                    "likeCount": "290",
                    "favoriteCount": "0",
                    "commentCount": "8"
                },
                "contentDetails": {
                    "duration": "PT27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "PHxv5NhQCvk": {
                "snippet": {
                    "publishedAt": "2023-01-28T15:41:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Parse URL's in a FLASH",
                    "description": "urllib is built in to the standard lib and is great for parsing and break up urls into managable chunks. extract any of the information, especially useful when working with APIs and web scraping.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/PHxv5NhQCvk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/PHxv5NhQCvk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/PHxv5NhQCvk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/PHxv5NhQCvk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/PHxv5NhQCvk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Parse URL's in a FLASH",
                        "description": "urllib is built in to the standard lib and is great for parsing and break up urls into managable chunks. extract any of the information, especially useful when working with APIs and web scraping."
                    }
                },
                "statistics": {
                    "viewCount": "7111",
                    "likeCount": "273",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT31S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_b7Ni92TyOw": {
                "snippet": {
                    "publishedAt": "2023-01-16T14:00:21Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "What's So Special About this Python Framework?!",
                    "description": "I really enjoy looking at new frameworks and seeing how things work together.\n\nRobyn is a Python framework written in Rust that is FAST and exciting, I will be watching its development closely!\n\nhttps://github.com/sansyrox/robyn\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timstamps\n\n00:00 intro\n01:14 robyn\n03:31 code\n04:40 benchmarks*\n05:31 fastapi & comparison",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_b7Ni92TyOw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_b7Ni92TyOw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_b7Ni92TyOw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_b7Ni92TyOw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_b7Ni92TyOw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "What's So Special About this Python Framework?!",
                        "description": "I really enjoy looking at new frameworks and seeing how things work together.\n\nRobyn is a Python framework written in Rust that is FAST and exciting, I will be watching its development closely!\n\nhttps://github.com/sansyrox/robyn\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timstamps\n\n00:00 intro\n01:14 robyn\n03:31 code\n04:40 benchmarks*\n05:31 fastapi & comparison"
                    }
                },
                "statistics": {
                    "viewCount": "10839",
                    "likeCount": "386",
                    "favoriteCount": "0",
                    "commentCount": "49"
                },
                "contentDetails": {
                    "duration": "PT6M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "gU67zKePoX4": {
                "snippet": {
                    "publishedAt": "2023-01-13T11:12:27Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting Web Scraping & Looking at Repos",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/gU67zKePoX4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/gU67zKePoX4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/gU67zKePoX4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/gU67zKePoX4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/gU67zKePoX4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting Web Scraping & Looking at Repos",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1259",
                    "likeCount": "46",
                    "favoriteCount": "0",
                    "commentCount": "0"
                },
                "contentDetails": {
                    "duration": "PT1H12M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Vcxi9jPe9Dw": {
                "snippet": {
                    "publishedAt": "2023-01-12T12:10:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting Web Scraping Projects in 2023",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Vcxi9jPe9Dw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Vcxi9jPe9Dw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Vcxi9jPe9Dw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Vcxi9jPe9Dw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Vcxi9jPe9Dw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live",
                        "web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting Web Scraping Projects in 2023",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    },
                    "defaultAudioLanguage": "en"
                },
                "statistics": {
                    "viewCount": "1451",
                    "likeCount": "47",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT1H30M51S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "5_i6sA4jZcs": {
                "snippet": {
                    "publishedAt": "2023-01-09T18:57:36Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Add Arguments Easily with ARGPARSE",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/5_i6sA4jZcs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/5_i6sA4jZcs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/5_i6sA4jZcs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/5_i6sA4jZcs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/5_i6sA4jZcs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Add Arguments Easily with ARGPARSE",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "5423",
                    "likeCount": "152",
                    "favoriteCount": "0",
                    "commentCount": "1"
                },
                "contentDetails": {
                    "duration": "PT38S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_5YnNCyVSC8": {
                "snippet": {
                    "publishedAt": "2023-01-09T10:12:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Live chatting Web Scraping Projects, tips and methods p2",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_5YnNCyVSC8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_5YnNCyVSC8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_5YnNCyVSC8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_5YnNCyVSC8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_5YnNCyVSC8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Live chatting Web Scraping Projects, tips and methods p2",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1387",
                    "likeCount": "67",
                    "favoriteCount": "0",
                    "commentCount": "1"
                },
                "contentDetails": {
                    "duration": "PT1H1M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "zF1hOH8CC1I": {
                "snippet": {
                    "publishedAt": "2023-01-08T21:07:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Live chatting Web Scraping Projects, tips and methods p1",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/zF1hOH8CC1I/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/zF1hOH8CC1I/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/zF1hOH8CC1I/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/zF1hOH8CC1I/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/zF1hOH8CC1I/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Live chatting Web Scraping Projects, tips and methods p1",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1097",
                    "likeCount": "34",
                    "favoriteCount": "0",
                    "commentCount": "2"
                },
                "contentDetails": {
                    "duration": "PT16M14S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WlZx9f7AxUI": {
                "snippet": {
                    "publishedAt": "2023-01-08T16:51:54Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "THIS is a better way to return scraped data.",
                    "description": "Using generator expressions and functions we can use yield to extract data from an html page and avoid having to use costly lists of lists, and lists of dicts. this makes our lives easier when it comes to outputting the scraped data.\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WlZx9f7AxUI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WlZx9f7AxUI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WlZx9f7AxUI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WlZx9f7AxUI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WlZx9f7AxUI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python generators",
                        "python yield",
                        "web scrapping",
                        "web scraping python",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "THIS is a better way to return scraped data.",
                        "description": "Using generator expressions and functions we can use yield to extract data from an html page and avoid having to use costly lists of lists, and lists of dicts. this makes our lives easier when it comes to outputting the scraped data.\n\nhttps://github.com/jhnwr/youtube\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "6252",
                    "likeCount": "215",
                    "favoriteCount": "0",
                    "commentCount": "31"
                },
                "contentDetails": {
                    "duration": "PT5M",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "63fTdNyMgmk": {
                "snippet": {
                    "publishedAt": "2023-01-04T20:53:33Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping Skeleton Project in Python",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/63fTdNyMgmk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/63fTdNyMgmk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/63fTdNyMgmk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/63fTdNyMgmk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/63fTdNyMgmk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping Skeleton Project in Python",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "27555",
                    "likeCount": "1298",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT48S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "A9ZDqxvwNDs": {
                "snippet": {
                    "publishedAt": "2022-12-30T13:14:37Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Scrape (almost) ANY Website with Python",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nUsing browser automation isn't generally my go to for scraping but sometimes it gives us an easy option for grabbing data. Scaling is an issue however, but combining playwright with scrapy gives us a good solid robust scraping method to add to our repertoire.\n\nJavaScript to Scroll to the bottom of the page:\n\n\"setInterval(function () {var scrollingElement = (document.scrollingElement || document.body);scrollingElement.scrollTop = scrollingElement.scrollHeight;}, 200);\",\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n01:49 Playwright & Selectolax\n07:14 Playwright & Scrapy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/A9ZDqxvwNDs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/A9ZDqxvwNDs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/A9ZDqxvwNDs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/A9ZDqxvwNDs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/A9ZDqxvwNDs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "web scraping with python",
                        "python scrapy",
                        "scrapy",
                        "scrapy playwright",
                        "python playwright",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Scrape (almost) ANY Website with Python",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nUsing browser automation isn't generally my go to for scraping but sometimes it gives us an easy option for grabbing data. Scaling is an issue however, but combining playwright with scrapy gives us a good solid robust scraping method to add to our repertoire.\n\nJavaScript to Scroll to the bottom of the page:\n\n\"setInterval(function () {var scrollingElement = (document.scrollingElement || document.body);scrollingElement.scrollTop = scrollingElement.scrollHeight;}, 200);\",\n\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n01:49 Playwright & Selectolax\n07:14 Playwright & Scrapy"
                    }
                },
                "statistics": {
                    "viewCount": "39744",
                    "likeCount": "911",
                    "favoriteCount": "0",
                    "commentCount": "82"
                },
                "contentDetails": {
                    "duration": "PT13M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "B1JWFbV7RB0": {
                "snippet": {
                    "publishedAt": "2022-12-29T21:01:53Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Should Requests be In the Standard Library?",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/B1JWFbV7RB0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/B1JWFbV7RB0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/B1JWFbV7RB0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/B1JWFbV7RB0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/B1JWFbV7RB0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Should Requests be In the Standard Library?",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "3043",
                    "likeCount": "109",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "giiLmJnOnok": {
                "snippet": {
                    "publishedAt": "2022-12-29T00:27:43Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Playwright Click Pages - Python Web Scraping",
                    "description": "",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/giiLmJnOnok/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/giiLmJnOnok/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/giiLmJnOnok/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/giiLmJnOnok/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/giiLmJnOnok/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "playwright",
                        "python",
                        "web scraping",
                        "web scrpaing pagination"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Playwright Click Pages - Python Web Scraping",
                        "description": ""
                    }
                },
                "statistics": {
                    "viewCount": "11283",
                    "likeCount": "354",
                    "favoriteCount": "0",
                    "commentCount": "17"
                },
                "contentDetails": {
                    "duration": "PT50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "X4WctWZ2ANw": {
                "snippet": {
                    "publishedAt": "2022-12-19T14:00:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Use Recursion in Python for API Pagination",
                    "description": "Use my code \"JOHNWATSONROONEY\" or link \u200bhttps://rize.io/u/johnwatsonrooney\u00a0to be the first 1000 people to get a 25% discount off your first three months with Rize\n\nThis video was sponsored by Rize.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# timestamps\n00:00 Intro\n01:54 Code",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/X4WctWZ2ANw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/X4WctWZ2ANw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/X4WctWZ2ANw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/X4WctWZ2ANw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/X4WctWZ2ANw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Use Recursion in Python for API Pagination",
                        "description": "Use my code \"JOHNWATSONROONEY\" or link \u200bhttps://rize.io/u/johnwatsonrooney\u00a0to be the first 1000 people to get a 25% discount off your first three months with Rize\n\nThis video was sponsored by Rize.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# timestamps\n00:00 Intro\n01:54 Code"
                    }
                },
                "statistics": {
                    "viewCount": "4457",
                    "likeCount": "135",
                    "favoriteCount": "0",
                    "commentCount": "20"
                },
                "contentDetails": {
                    "duration": "PT7M31S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "HpRsfpPuUzE": {
                "snippet": {
                    "publishedAt": "2022-12-06T13:30:07Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Best Web Scraping Combo? Use These In Your Projects",
                    "description": "A full Python project using my 2 current favorite tools, HTTP Client HTTPX and HTML Parser Selectolax.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/HpRsfpPuUzE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/HpRsfpPuUzE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/HpRsfpPuUzE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/HpRsfpPuUzE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/HpRsfpPuUzE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "scrapping data",
                        "john waston rooney",
                        "selectolax",
                        "httpx",
                        "python html parsing"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Best Web Scraping Combo? Use These In Your Projects",
                        "description": "A full Python project using my 2 current favorite tools, HTTP Client HTTPX and HTML Parser Selectolax.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "43741",
                    "likeCount": "1497",
                    "favoriteCount": "0",
                    "commentCount": "124"
                },
                "contentDetails": {
                    "duration": "PT20M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "iWVd2umjLk8": {
                "snippet": {
                    "publishedAt": "2022-11-29T13:30:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Python Tools a Pro Web Scraper Uses Day to Day",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Languages\n00:52 Extracting Data\n04:03 Transform it\n05:19 Save it\n06:32 Frameworks\n07:55 Extras",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/iWVd2umjLk8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/iWVd2umjLk8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/iWVd2umjLk8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/iWVd2umjLk8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/iWVd2umjLk8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "web scraping",
                        "python web scraping",
                        "web scrapping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Python Tools a Pro Web Scraper Uses Day to Day",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Languages\n00:52 Extracting Data\n04:03 Transform it\n05:19 Save it\n06:32 Frameworks\n07:55 Extras"
                    }
                },
                "statistics": {
                    "viewCount": "13499",
                    "likeCount": "571",
                    "favoriteCount": "0",
                    "commentCount": "67"
                },
                "contentDetails": {
                    "duration": "PT9M32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "qO38y-m8_G8": {
                "snippet": {
                    "publishedAt": "2022-11-14T13:46:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How a Web Scraping Pro Parses HTML in Python",
                    "description": "HTML Parsing tips and helping hints for those who are learning web scraping with python, and an HTML parsing library like beautiful soup.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/qO38y-m8_G8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/qO38y-m8_G8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/qO38y-m8_G8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/qO38y-m8_G8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/qO38y-m8_G8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "html parsing",
                        "beautifulsoup",
                        "python bs4",
                        "bs4",
                        "soup find",
                        "find_all",
                        "web scraping",
                        "web scraping with python",
                        "web scrapping",
                        "python scrapping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How a Web Scraping Pro Parses HTML in Python",
                        "description": "HTML Parsing tips and helping hints for those who are learning web scraping with python, and an HTML parsing library like beautiful soup.\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "7325",
                    "likeCount": "271",
                    "favoriteCount": "0",
                    "commentCount": "21"
                },
                "contentDetails": {
                    "duration": "PT6M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "D4xCGnwjMZQ": {
                "snippet": {
                    "publishedAt": "2022-11-07T13:30:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "BeautifulSoup is NOT the king of HTML Parsers (try this one)",
                    "description": "Keep exploring at http://brilliant.org/JohnWatsonRooney/. Get started for free, and hurry\u2014the first 200 people get 20% off an annual premium subscription\n\nI'm moving on from defaulting to BS4! For the web scraping work i do i am after something fast and a bit more focused, minimal features but still easy to use. there are two options i consider in this video, Parsel from Scrapy, and Selectolax - a wrapper around a C library called Modest, written in cpython. which one do you think i'm going to use...\n\nThis video was sponsored by brilliant.\n\nhttps://parsel.readthedocs.io/en/latest/index.html\nhttps://github.com/rushter/selectolax\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/D4xCGnwjMZQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/D4xCGnwjMZQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/D4xCGnwjMZQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/D4xCGnwjMZQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/D4xCGnwjMZQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "selectolax",
                        "html parsing",
                        "web scraping",
                        "web scrapping",
                        "python web scraping",
                        "scrap data"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "BeautifulSoup is NOT the king of HTML Parsers (try this one)",
                        "description": "Keep exploring at http://brilliant.org/JohnWatsonRooney/. Get started for free, and hurry\u2014the first 200 people get 20% off an annual premium subscription\n\nI'm moving on from defaulting to BS4! For the web scraping work i do i am after something fast and a bit more focused, minimal features but still easy to use. there are two options i consider in this video, Parsel from Scrapy, and Selectolax - a wrapper around a C library called Modest, written in cpython. which one do you think i'm going to use...\n\nThis video was sponsored by brilliant.\n\nhttps://parsel.readthedocs.io/en/latest/index.html\nhttps://github.com/rushter/selectolax\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "26614",
                    "likeCount": "751",
                    "favoriteCount": "0",
                    "commentCount": "72"
                },
                "contentDetails": {
                    "duration": "PT8M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "zOx8Com2OKI": {
                "snippet": {
                    "publishedAt": "2022-10-31T13:23:43Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Full Project with Scrapy - The BEST Scraping Framework",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n00:35 CrawlSpider\n02:09 LinkExtractor Rules\n03:21 Proxies\n06:19 Items & Itemloader\n12:19 Running the Spider\n13:33 Results",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/zOx8Com2OKI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/zOx8Com2OKI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/zOx8Com2OKI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/zOx8Com2OKI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/zOx8Com2OKI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "john watson rooney",
                        "scrapy",
                        "learn scrapy",
                        "web scraping with python",
                        "python web scrapping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Full Project with Scrapy - The BEST Scraping Framework",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n00:35 CrawlSpider\n02:09 LinkExtractor Rules\n03:21 Proxies\n06:19 Items & Itemloader\n12:19 Running the Spider\n13:33 Results"
                    }
                },
                "statistics": {
                    "viewCount": "11185",
                    "likeCount": "391",
                    "favoriteCount": "0",
                    "commentCount": "46"
                },
                "contentDetails": {
                    "duration": "PT15M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ow451CjBV-U": {
                "snippet": {
                    "publishedAt": "2022-10-24T13:30:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Does This Feature Make Flask-RESTful Worth Using?",
                    "description": "I've been creating a lot of minimal API's recently and when I found this flask extension I liked the look of I wanted to give it a go. This demo API should hopefully give you an idea of what its about, and while I probably won't use it much more outside of this it was a fun learning project either way.\n\nhttps://flask-restful.readthedocs.io/en/latest/\nhttps://github.com/jhnwr/flask-restful-demo\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ow451CjBV-U/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ow451CjBV-U/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ow451CjBV-U/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ow451CjBV-U/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ow451CjBV-U/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "flask",
                        "flask restful",
                        "flask api",
                        "john watson rooney",
                        "learn python",
                        "python backend",
                        "python flask"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Does This Feature Make Flask-RESTful Worth Using?",
                        "description": "I've been creating a lot of minimal API's recently and when I found this flask extension I liked the look of I wanted to give it a go. This demo API should hopefully give you an idea of what its about, and while I probably won't use it much more outside of this it was a fun learning project either way.\n\nhttps://flask-restful.readthedocs.io/en/latest/\nhttps://github.com/jhnwr/flask-restful-demo\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "5415",
                    "likeCount": "119",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT18M30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "LNoVpdBtD4k": {
                "snippet": {
                    "publishedAt": "2022-10-19T20:09:44Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How do YOU Solve this common Web Scraping issue?",
                    "description": "This is a common error we get when an element on the page doesn't exist - abstracting out to a new function to handle is is a great way to keep your code neat and tidy!\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/LNoVpdBtD4k/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/LNoVpdBtD4k/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/LNoVpdBtD4k/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/LNoVpdBtD4k/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/LNoVpdBtD4k/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney",
                        "web scraping",
                        "learn web scraping",
                        "web scrapping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How do YOU Solve this common Web Scraping issue?",
                        "description": "This is a common error we get when an element on the page doesn't exist - abstracting out to a new function to handle is is a great way to keep your code neat and tidy!\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "12421",
                    "likeCount": "354",
                    "favoriteCount": "0",
                    "commentCount": "38"
                },
                "contentDetails": {
                    "duration": "PT3M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "yvN8KnQpUEc": {
                "snippet": {
                    "publishedAt": "2022-10-14T09:34:31Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "LIVE: Fleet?! Python Code? Projects to learn?",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/yvN8KnQpUEc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/yvN8KnQpUEc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/yvN8KnQpUEc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/yvN8KnQpUEc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/yvN8KnQpUEc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "LIVE: Fleet?! Python Code? Projects to learn?",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "2349",
                    "likeCount": "43",
                    "favoriteCount": "0",
                    "commentCount": "4"
                },
                "contentDetails": {
                    "duration": "PT1H13M39S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "9gM75WqXQ-Y": {
                "snippet": {
                    "publishedAt": "2022-10-12T09:43:54Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "LIVE: Chatting Python, Learning Code + Web Scraping QNA",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/9gM75WqXQ-Y/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/9gM75WqXQ-Y/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/9gM75WqXQ-Y/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/9gM75WqXQ-Y/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/9gM75WqXQ-Y/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "LIVE: Chatting Python, Learning Code + Web Scraping QNA",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1453",
                    "likeCount": "64",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT1H3M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CiDaKRyp4Fk": {
                "snippet": {
                    "publishedAt": "2022-10-09T08:21:44Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python & Code Chat",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CiDaKRyp4Fk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CiDaKRyp4Fk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CiDaKRyp4Fk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CiDaKRyp4Fk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CiDaKRyp4Fk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python & Code Chat",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1214",
                    "likeCount": "47",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT1H7M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "G7gZKANSmqk": {
                "snippet": {
                    "publishedAt": "2022-10-06T10:17:22Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Why *ARGS and **KWARGS are Useful in Python",
                    "description": "Keep exploring at http://brilliant.org/JohnWatsonRooney/ Get started for free, and hurry\u2014the first 200 people get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/G7gZKANSmqk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/G7gZKANSmqk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/G7gZKANSmqk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/G7gZKANSmqk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/G7gZKANSmqk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "kwargs",
                        "args",
                        "python function",
                        "python function arguments",
                        "john watson rooney",
                        "learn python",
                        "python tutorial for beginners",
                        "python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Why *ARGS and **KWARGS are Useful in Python",
                        "description": "Keep exploring at http://brilliant.org/JohnWatsonRooney/ Get started for free, and hurry\u2014the first 200 people get 20% off an annual premium subscription.\n\nThis video was sponsored by Brilliant\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "17520",
                    "likeCount": "708",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT10M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "5mpLJxKfnXQ": {
                "snippet": {
                    "publishedAt": "2022-09-29T10:19:38Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Organize Data In Python with Dataclasses",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/5mpLJxKfnXQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/5mpLJxKfnXQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/5mpLJxKfnXQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/5mpLJxKfnXQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/5mpLJxKfnXQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Organize Data In Python with Dataclasses",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n# Scraper API https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "29664",
                    "likeCount": "1010",
                    "favoriteCount": "0",
                    "commentCount": "44"
                },
                "contentDetails": {
                    "duration": "PT10M4S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "QOcChmgLXiI": {
                "snippet": {
                    "publishedAt": "2022-09-20T11:51:44Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Is THIS The Best Way to Build a Scraper API?",
                    "description": "Using FastAPI we are going to create a simple 1 endpoint application that will accept an ASIN number and scrape some product data from amazon, returning it as JSON. \n\nThis is a great beginner level project for those who want to look at learning some basic FastAPI and API's with Python in general.\n\nhttps://github.com/jhnwr/scraperapi\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/QOcChmgLXiI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/QOcChmgLXiI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/QOcChmgLXiI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/QOcChmgLXiI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/QOcChmgLXiI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Is THIS The Best Way to Build a Scraper API?",
                        "description": "Using FastAPI we are going to create a simple 1 endpoint application that will accept an ASIN number and scrape some product data from amazon, returning it as JSON. \n\nThis is a great beginner level project for those who want to look at learning some basic FastAPI and API's with Python in general.\n\nhttps://github.com/jhnwr/scraperapi\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "10462",
                    "likeCount": "367",
                    "favoriteCount": "0",
                    "commentCount": "45"
                },
                "contentDetails": {
                    "duration": "PT11M32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uWg-XAyyJTk": {
                "snippet": {
                    "publishedAt": "2022-09-13T10:45:18Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Try My Price Monitoring Beginner Python Project",
                    "description": "Here's a beginner friendly project that uses functions, web scraping, and saving product data to a database.\n\nCode:\nhttps://github.com/jhnwr/scraper-to-db\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uWg-XAyyJTk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uWg-XAyyJTk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uWg-XAyyJTk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uWg-XAyyJTk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uWg-XAyyJTk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "pony orm",
                        "john watson rooney",
                        "requests",
                        "python requests",
                        "web scraping",
                        "web scraping with python",
                        "web scrapping",
                        "scrap data",
                        "orm",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Try My Price Monitoring Beginner Python Project",
                        "description": "Here's a beginner friendly project that uses functions, web scraping, and saving product data to a database.\n\nCode:\nhttps://github.com/jhnwr/scraper-to-db\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "19076",
                    "likeCount": "629",
                    "favoriteCount": "0",
                    "commentCount": "58"
                },
                "contentDetails": {
                    "duration": "PT18M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "u21tTXDbMXc": {
                "snippet": {
                    "publishedAt": "2022-09-09T21:39:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Checking Out Web Scraping Projects on Github",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/u21tTXDbMXc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/u21tTXDbMXc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/u21tTXDbMXc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/u21tTXDbMXc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/u21tTXDbMXc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "john watson rooney live"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Checking Out Web Scraping Projects on Github",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "8394",
                    "likeCount": "109",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT2H23M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "DR3FFvqvuE0": {
                "snippet": {
                    "publishedAt": "2022-09-06T10:30:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Building a REST API With AIOHTTP and Python",
                    "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\nThis video was sponsored by Brilliant\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 The Plan\n00:42 Framework/Response\n02:51 Routing\n03:44 Request Object/POST\n05:00 Adding a Database\n07:07 Views\n08:39 Serializing JSON\n10:30 Templating\n13:11 Advice",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/DR3FFvqvuE0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/DR3FFvqvuE0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/DR3FFvqvuE0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/DR3FFvqvuE0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/DR3FFvqvuE0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python api",
                        "minimal api",
                        "aiohttp server",
                        "aiohttp",
                        "aiohttp python",
                        "john watson rooney",
                        "python api tutorial",
                        "python tutorial",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Building a REST API With AIOHTTP and Python",
                        "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\nThis video was sponsored by Brilliant\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n# timestamps\n00:00 The Plan\n00:42 Framework/Response\n02:51 Routing\n03:44 Request Object/POST\n05:00 Adding a Database\n07:07 Views\n08:39 Serializing JSON\n10:30 Templating\n13:11 Advice"
                    }
                },
                "statistics": {
                    "viewCount": "6801",
                    "likeCount": "225",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT14M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WO34bLJNiDs": {
                "snippet": {
                    "publishedAt": "2022-09-02T22:48:30Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "LIVE: Chatting and Code stuff",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WO34bLJNiDs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WO34bLJNiDs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WO34bLJNiDs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WO34bLJNiDs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WO34bLJNiDs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "LIVE: Chatting and Code stuff",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "959",
                    "likeCount": "38",
                    "favoriteCount": "0",
                    "commentCount": "4"
                },
                "contentDetails": {
                    "duration": "PT2H17M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "9Bo8IetU9So": {
                "snippet": {
                    "publishedAt": "2022-08-30T12:45:36Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Async & Await in Python Simple & FAST HTTP Requests",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nCode:\nhttps://github.com/jhnwr/httpx-async-shopify\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n00:00 Explanation and Goals\n02:07 Code\n07:46 Why ASYNC?\n08:43  Expanding",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/9Bo8IetU9So/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/9Bo8IetU9So/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/9Bo8IetU9So/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/9Bo8IetU9So/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/9Bo8IetU9So/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "async",
                        "asyncio",
                        "httpx python",
                        "python async requests",
                        "python asyncio",
                        "python async",
                        "python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Async & Await in Python Simple & FAST HTTP Requests",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nCode:\nhttps://github.com/jhnwr/httpx-async-shopify\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n00:00 Explanation and Goals\n02:07 Code\n07:46 Why ASYNC?\n08:43  Expanding"
                    }
                },
                "statistics": {
                    "viewCount": "8714",
                    "likeCount": "335",
                    "favoriteCount": "0",
                    "commentCount": "23"
                },
                "contentDetails": {
                    "duration": "PT9M37S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "u9h7cwC9UlQ": {
                "snippet": {
                    "publishedAt": "2022-08-28T09:07:39Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "LIVE: Chatting and Code stuff",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/u9h7cwC9UlQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/u9h7cwC9UlQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/u9h7cwC9UlQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/u9h7cwC9UlQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/u9h7cwC9UlQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "LIVE: Chatting and Code stuff",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "782",
                    "likeCount": "30",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT1H3M29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xSNQ9Vuoc3c": {
                "snippet": {
                    "publishedAt": "2022-08-27T07:26:45Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting Web Scraping, Python & Learning Code",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xSNQ9Vuoc3c/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xSNQ9Vuoc3c/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xSNQ9Vuoc3c/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xSNQ9Vuoc3c/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xSNQ9Vuoc3c/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting Web Scraping, Python & Learning Code",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1694",
                    "likeCount": "47",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT59M33S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "E39a7kQfjSg": {
                "snippet": {
                    "publishedAt": "2022-08-17T15:30:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Make API Calls Like a PRO - Python API Client x Shopify",
                    "description": "How to use a session object to make a more robust API client with Python\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/E39a7kQfjSg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/E39a7kQfjSg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/E39a7kQfjSg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/E39a7kQfjSg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/E39a7kQfjSg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "rest api",
                        "python shopify",
                        "requests api",
                        "python api request",
                        "shopify api python",
                        "python requests",
                        "intermediate request",
                        "rest api tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Make API Calls Like a PRO - Python API Client x Shopify",
                        "description": "How to use a session object to make a more robust API client with Python\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "37838",
                    "likeCount": "1385",
                    "favoriteCount": "0",
                    "commentCount": "64"
                },
                "contentDetails": {
                    "duration": "PT9M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "daorgv0TdHc": {
                "snippet": {
                    "publishedAt": "2022-08-14T09:55:51Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting YouTube and Creating Programming Content",
                    "description": "Talking about code, answering questions and just generally getting a feel for it\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/daorgv0TdHc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/daorgv0TdHc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/daorgv0TdHc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/daorgv0TdHc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/daorgv0TdHc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting YouTube and Creating Programming Content",
                        "description": "Talking about code, answering questions and just generally getting a feel for it\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "1188",
                    "likeCount": "45",
                    "favoriteCount": "0",
                    "commentCount": "2"
                },
                "contentDetails": {
                    "duration": "PT1H49M50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "jlz0JoQXGN4": {
                "snippet": {
                    "publishedAt": "2022-08-13T08:37:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "LIVE Talking Python",
                    "description": "Talking about code, answering questions and just generally getting a feel for it",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/jlz0JoQXGN4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/jlz0JoQXGN4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/jlz0JoQXGN4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/jlz0JoQXGN4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/jlz0JoQXGN4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "LIVE Talking Python",
                        "description": "Talking about code, answering questions and just generally getting a feel for it"
                    }
                },
                "statistics": {
                    "viewCount": "1179",
                    "likeCount": "43",
                    "favoriteCount": "0",
                    "commentCount": "5"
                },
                "contentDetails": {
                    "duration": "PT1H13M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "HOS5Hix--bE": {
                "snippet": {
                    "publishedAt": "2022-08-07T14:00:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "My Indeed Web Scraper Stopped Working. Here's Why",
                    "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\nThis video was sponsored by Brilliant.\n\nhttps://github.com/jhnwr/indeed-scraper\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/HOS5Hix--bE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/HOS5Hix--bE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/HOS5Hix--bE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/HOS5Hix--bE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/HOS5Hix--bE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scraping python",
                        "indeed scraper",
                        "job scraper",
                        "john watson rooney",
                        "python web scraping",
                        "web scraping tutorial",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "My Indeed Web Scraper Stopped Working. Here's Why",
                        "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\nThis video was sponsored by Brilliant.\n\nhttps://github.com/jhnwr/indeed-scraper\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "13741",
                    "likeCount": "320",
                    "favoriteCount": "0",
                    "commentCount": "75"
                },
                "contentDetails": {
                    "duration": "PT19M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "M3JC-Isbn7E": {
                "snippet": {
                    "publishedAt": "2022-08-06T10:05:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Learning to Code?",
                    "description": "Talking about code, answering questions and just generally getting a feel for it",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/M3JC-Isbn7E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/M3JC-Isbn7E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/M3JC-Isbn7E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/M3JC-Isbn7E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/M3JC-Isbn7E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Learning to Code?",
                        "description": "Talking about code, answering questions and just generally getting a feel for it"
                    }
                },
                "statistics": {
                    "viewCount": "1284",
                    "likeCount": "46",
                    "favoriteCount": "0",
                    "commentCount": "6"
                },
                "contentDetails": {
                    "duration": "PT1H15M31S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ncV7k35-e0s": {
                "snippet": {
                    "publishedAt": "2022-08-02T13:00:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Tortoise ORM for Python Projects - Simple & ASYNC",
                    "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare: \u200bhttps://skl.sh/johnwatsonrooney08221 \n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ncV7k35-e0s/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ncV7k35-e0s/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ncV7k35-e0s/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ncV7k35-e0s/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ncV7k35-e0s/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "tortoise orm",
                        "python orm",
                        "async orm",
                        "john watson rooney",
                        "learn python",
                        "aiosqlite",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Tortoise ORM for Python Projects - Simple & ASYNC",
                        "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare: \u200bhttps://skl.sh/johnwatsonrooney08221 \n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "12902",
                    "likeCount": "226",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT7M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "-0SSdvwK6Ho": {
                "snippet": {
                    "publishedAt": "2022-07-28T13:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape Amazon With Python",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nCode:\nhttps://github.com/jhnwr/amazon-product-scraper\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n00:00 Simple\n02:22 Intermediate\n09:11 Scrapy\n13:30 Extra Method",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/-0SSdvwK6Ho/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/-0SSdvwK6Ho/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/-0SSdvwK6Ho/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/-0SSdvwK6Ho/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/-0SSdvwK6Ho/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "amazon product scraping",
                        "learn python",
                        "python projects",
                        "web scraping",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape Amazon With Python",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\nCode:\nhttps://github.com/jhnwr/amazon-product-scraper\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n00:00 Simple\n02:22 Intermediate\n09:11 Scrapy\n13:30 Extra Method"
                    },
                    "defaultAudioLanguage": "en-US"
                },
                "statistics": {
                    "viewCount": "14248",
                    "likeCount": "362",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT14M34S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "HA1vd3UP1Bc": {
                "snippet": {
                    "publishedAt": "2022-07-25T09:23:49Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting Web Scraping, Python & Learning Code",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/HA1vd3UP1Bc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/HA1vd3UP1Bc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/HA1vd3UP1Bc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/HA1vd3UP1Bc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/HA1vd3UP1Bc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting Web Scraping, Python & Learning Code",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "2122",
                    "likeCount": "94",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT1H15M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "C85WveX-RfQ": {
                "snippet": {
                    "publishedAt": "2022-07-23T11:35:48Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Chatting Web Scraping Technologies, Techniques & General Python Code",
                    "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/C85WveX-RfQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/C85WveX-RfQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/C85WveX-RfQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/C85WveX-RfQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/C85WveX-RfQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Chatting Web Scraping Technologies, Techniques & General Python Code",
                        "description": "# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "1361",
                    "likeCount": "45",
                    "favoriteCount": "0",
                    "commentCount": "2"
                },
                "contentDetails": {
                    "duration": "PT1H8M41S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "z_cdzgrjERQ": {
                "snippet": {
                    "publishedAt": "2022-07-21T13:05:37Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Following Links With Scrapy (regex is GOOD here)",
                    "description": "Using Scrapy, LinkExtractor & Regex to only follow links that the \"a\" tag text matches our criteria\n \n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n00:53 Code Start\n01:35 Links to match\n02:28 Writing the Rules\n05:45 Extracting Data\n06:16 Running and error fixing\n07:10 Results and outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/z_cdzgrjERQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/z_cdzgrjERQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/z_cdzgrjERQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/z_cdzgrjERQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/z_cdzgrjERQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy",
                        "python scrapy",
                        "web scraping with python",
                        "web scraping",
                        "john watson rooney",
                        "link extractor",
                        "scrapy linkextractor"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Following Links With Scrapy (regex is GOOD here)",
                        "description": "Using Scrapy, LinkExtractor & Regex to only follow links that the \"a\" tag text matches our criteria\n \n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n# timestamps\n00:00 Intro\n00:53 Code Start\n01:35 Links to match\n02:28 Writing the Rules\n05:45 Extracting Data\n06:16 Running and error fixing\n07:10 Results and outro"
                    }
                },
                "statistics": {
                    "viewCount": "4435",
                    "likeCount": "178",
                    "favoriteCount": "0",
                    "commentCount": "38"
                },
                "contentDetails": {
                    "duration": "PT8M1S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WsfINO81zIA": {
                "snippet": {
                    "publishedAt": "2022-07-14T13:00:31Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This is how I scrape data from iframes",
                    "description": "Answering a help question on Reddita bout scraping a site that uses iframes\n \n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WsfINO81zIA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WsfINO81zIA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WsfINO81zIA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WsfINO81zIA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WsfINO81zIA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This is how I scrape data from iframes",
                        "description": "Answering a help question on Reddita bout scraping a site that uses iframes\n \n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "12957",
                    "likeCount": "324",
                    "favoriteCount": "0",
                    "commentCount": "55"
                },
                "contentDetails": {
                    "duration": "PT18M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "dXI1VJHl_lE": {
                "snippet": {
                    "publishedAt": "2022-07-07T13:00:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Bubble Sort Algorithm in Python Example: Code and Explanation",
                    "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\ncode: https://github.com/jhnwr/algorithms\n\nThis video was sponsored by Brilliant.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\nThank you to all who help support me via Patreon\n\n# Proxies: https://iproyal.club/JWR50\nThe proxies I use\n\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\nWhere I run my code and deploy apps\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Video\n\nCamera: https://amzn.to/3b5N1ej\nLens: https://amzn.to/3QAm7LT\nLighting: https://amzn.to/3Oivn64\n\n# Audio\n\nInterface: https://amzn.to/3OqEqRQ\nMicrophone: https://amzn.to/3xISfEC\nHeadphones: https://amzn.to/3zQrwZv\n\n# PC\n\nCase: https://amzn.to/3dEz6Jw\nPSU: https://amzn.to/3kc7SfB\nCPU: https://amzn.to/2ILxGSh\nMobo: https://amzn.to/3lWmxw4\nRam: https://amzn.to/31muxPc\nGFX card: https://amzn.to/2SKYraW\n32\" monitor: https://amzn.to/3sqgq98 (main)\n27\" monitor: https://amzn.to/2GAH4r9 (vertical)\n24\" monitor: https://amzn.to/3jIFamt (spare)\nDual monitor arm: https://amzn.to/3wpBvlg\nMouse: https://amzn.to/2SH1ssK\nKeyboard: https://amzn.to/3A1B8jU\n\n# Timestamps\n\n00:00 Explanation\n02:45 Simple Code Example\n07:43 Adding Swap\n09:41 Comparing Simple&Swap Examples\n10:25 Different Data",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/dXI1VJHl_lE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/dXI1VJHl_lE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/dXI1VJHl_lE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/dXI1VJHl_lE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/dXI1VJHl_lE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "bubble sort",
                        "bubble sort algorithm",
                        "python bubble sort",
                        "john watson rooney",
                        "learn python",
                        "basic algorithms",
                        "bubble sort program",
                        "don't use bubble sort"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Bubble Sort Algorithm in Python Example: Code and Explanation",
                        "description": "Visit https://brilliant.org/JohnWatsonRooney/ to get started learning STEM for free, and the first 200 people will get 20% off their annual premium subscription.\n\ncode: https://github.com/jhnwr/algorithms\n\nThis video was sponsored by Brilliant.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\nThank you to all who help support me via Patreon\n\n# Proxies: https://iproyal.club/JWR50\nThe proxies I use\n\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\nWhere I run my code and deploy apps\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Video\n\nCamera: https://amzn.to/3b5N1ej\nLens: https://amzn.to/3QAm7LT\nLighting: https://amzn.to/3Oivn64\n\n# Audio\n\nInterface: https://amzn.to/3OqEqRQ\nMicrophone: https://amzn.to/3xISfEC\nHeadphones: https://amzn.to/3zQrwZv\n\n# PC\n\nCase: https://amzn.to/3dEz6Jw\nPSU: https://amzn.to/3kc7SfB\nCPU: https://amzn.to/2ILxGSh\nMobo: https://amzn.to/3lWmxw4\nRam: https://amzn.to/31muxPc\nGFX card: https://amzn.to/2SKYraW\n32\" monitor: https://amzn.to/3sqgq98 (main)\n27\" monitor: https://amzn.to/2GAH4r9 (vertical)\n24\" monitor: https://amzn.to/3jIFamt (spare)\nDual monitor arm: https://amzn.to/3wpBvlg\nMouse: https://amzn.to/2SH1ssK\nKeyboard: https://amzn.to/3A1B8jU\n\n# Timestamps\n\n00:00 Explanation\n02:45 Simple Code Example\n07:43 Adding Swap\n09:41 Comparing Simple&Swap Examples\n10:25 Different Data"
                    }
                },
                "statistics": {
                    "viewCount": "2916",
                    "likeCount": "118",
                    "favoriteCount": "0",
                    "commentCount": "23"
                },
                "contentDetails": {
                    "duration": "PT11M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Ez9wY7Cls0E": {
                "snippet": {
                    "publishedAt": "2022-06-30T11:35:43Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Truth About Learning to Code.",
                    "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney07221\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\n# Timestamps\n00:00 Hot Take\n02:21 Learning Tips\n04:55 Story time\n06:35 Progression Tips\n08:00 What Sort of Projects I like",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Ez9wY7Cls0E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Ez9wY7Cls0E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Ez9wY7Cls0E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Ez9wY7Cls0E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Ez9wY7Cls0E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn to code",
                        "how to learn to code",
                        "how to learn programming",
                        "john waton rooney",
                        "how to learn to code for beginners"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Truth About Learning to Code.",
                        "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney07221\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n\n# Timestamps\n00:00 Hot Take\n02:21 Learning Tips\n04:55 Story time\n06:35 Progression Tips\n08:00 What Sort of Projects I like"
                    }
                },
                "statistics": {
                    "viewCount": "6293",
                    "likeCount": "297",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT8M38S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "emPgih1AYTs": {
                "snippet": {
                    "publishedAt": "2022-06-22T14:00:21Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I Tried 100s of Free Proxies, Here's the results.",
                    "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/emPgih1AYTs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/emPgih1AYTs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/emPgih1AYTs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/emPgih1AYTs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/emPgih1AYTs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "proxy",
                        "proxies",
                        "john watson rooney",
                        "python proxy",
                        "free proxies",
                        "web scraping",
                        "web scrapping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I Tried 100s of Free Proxies, Here's the results.",
                        "description": "Grab IPRoyal Proxies and get 50% off with code JWR50 at https://iproyal.club/JWR50\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "31236",
                    "likeCount": "401",
                    "favoriteCount": "0",
                    "commentCount": "39"
                },
                "contentDetails": {
                    "duration": "PT8M2S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CgvOCXs8Xec": {
                "snippet": {
                    "publishedAt": "2022-06-14T13:08:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Email Myself Data from my Python Scripts",
                    "description": "This is how I keep myself updated via email using Python. \n\nhttps://github.com/jhnwr/python-email\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CgvOCXs8Xec/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CgvOCXs8Xec/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CgvOCXs8Xec/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CgvOCXs8Xec/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CgvOCXs8Xec/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python email",
                        "email script",
                        "email dataframes",
                        "email with python",
                        "python outlook",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Email Myself Data from my Python Scripts",
                        "description": "This is how I keep myself updated via email using Python. \n\nhttps://github.com/jhnwr/python-email\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "13062",
                    "likeCount": "408",
                    "favoriteCount": "0",
                    "commentCount": "44"
                },
                "contentDetails": {
                    "duration": "PT5M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "zibNBOBsDZk": {
                "snippet": {
                    "publishedAt": "2022-06-05T16:19:36Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to get data from AJAX Requests in Python",
                    "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare:  \nhttps://skl.sh/johnwatsonrooney06221\n\nAJAX is a commonly used tool by front end developers when writing JavaScript code. It fetches data from the backend system asynchronously meaning the website can be much more dynamic and allows new content to be loaded without having to refresh the page. \n\nFor those of you who are learning to extract data from sites knowing the basics of how this works will help you save time working out where the data is coming from and the best ways to get it out.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/zibNBOBsDZk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/zibNBOBsDZk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/zibNBOBsDZk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/zibNBOBsDZk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/zibNBOBsDZk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scrapping",
                        "ajax",
                        "network requests",
                        "learn webscraping",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to get data from AJAX Requests in Python",
                        "description": "The first 1,000 people to use the link will get a 1 month free trial of Skillshare:  \nhttps://skl.sh/johnwatsonrooney06221\n\nAJAX is a commonly used tool by front end developers when writing JavaScript code. It fetches data from the backend system asynchronously meaning the website can be much more dynamic and allows new content to be loaded without having to refresh the page. \n\nFor those of you who are learning to extract data from sites knowing the basics of how this works will help you save time working out where the data is coming from and the best ways to get it out.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "17013",
                    "likeCount": "472",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT5M49S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "OJdFj5hPAKs": {
                "snippet": {
                    "publishedAt": "2022-05-29T17:59:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Django Rest Framework for Beginners - Simple CRUD API",
                    "description": "Django Rest Framework is a powerful tool to create fully functioning APIs with Django. In this video I will show you how to use its basic functionality to create a simple CRUD API that has a database, query parameters, and one-to-many database relationship.\n\n# Code: https://github.com/jhnwr/basic-crud-api\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# timestamps\n00:00 Install and Setup\n00:54 Models\n02:49 Admin\n03:17 Migrations\n04:20 Project URLs\n05:20 Serializers\n06:50 API URLs\n07:55 Views\n11:42 Runserver\n12:05 Usage",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/OJdFj5hPAKs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/OJdFj5hPAKs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/OJdFj5hPAKs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/OJdFj5hPAKs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/OJdFj5hPAKs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "django rest framework",
                        "django",
                        "rest api",
                        "django rest framework tutorial",
                        "python django rest framework",
                        "python crud api",
                        "django crud api",
                        "crud api",
                        "john watson rooney",
                        "django api",
                        "django api tutorial",
                        "api class based views"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Django Rest Framework for Beginners - Simple CRUD API",
                        "description": "Django Rest Framework is a powerful tool to create fully functioning APIs with Django. In this video I will show you how to use its basic functionality to create a simple CRUD API that has a database, query parameters, and one-to-many database relationship.\n\n# Code: https://github.com/jhnwr/basic-crud-api\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# timestamps\n00:00 Install and Setup\n00:54 Models\n02:49 Admin\n03:17 Migrations\n04:20 Project URLs\n05:20 Serializers\n06:50 API URLs\n07:55 Views\n11:42 Runserver\n12:05 Usage"
                    }
                },
                "statistics": {
                    "viewCount": "51962",
                    "likeCount": "1155",
                    "favoriteCount": "0",
                    "commentCount": "57"
                },
                "contentDetails": {
                    "duration": "PT14M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "IUOl4W_3tTg": {
                "snippet": {
                    "publishedAt": "2022-05-25T14:01:22Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Is THIS the Best Way to Scrape Data with Playwright?",
                    "description": "I hack together a script to show how to find JSON data in amongst responses received to a webpage using Playwright. This is intended to show some of the functionality when working with the \"page.on\" response and request with a headless chrome browser. This is the same thing I would do manually inside the network tab of a browser when trying to find out the best way to scrape data from a website.\n\nIt's supposed to be educational, this code is on the whole, pretty bad. But it serves its purpose...\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/IUOl4W_3tTg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/IUOl4W_3tTg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/IUOl4W_3tTg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/IUOl4W_3tTg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/IUOl4W_3tTg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "playwright python",
                        "playwright network",
                        "web scraping",
                        "web scrapping",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Is THIS the Best Way to Scrape Data with Playwright?",
                        "description": "I hack together a script to show how to find JSON data in amongst responses received to a webpage using Playwright. This is intended to show some of the functionality when working with the \"page.on\" response and request with a headless chrome browser. This is the same thing I would do manually inside the network tab of a browser when trying to find out the best way to scrape data from a website.\n\nIt's supposed to be educational, this code is on the whole, pretty bad. But it serves its purpose...\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "11580",
                    "likeCount": "406",
                    "favoriteCount": "0",
                    "commentCount": "31"
                },
                "contentDetails": {
                    "duration": "PT6M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "FPSyjJdudHU": {
                "snippet": {
                    "publishedAt": "2022-05-18T14:00:13Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I Don't Waste Time Parsing HTML (So I do THIS)",
                    "description": "OK so it can't be avoided and this is nothing inherently BAD about parsing loads of HTML for scraping data, but the reason I keep banging on about this is that so many times there is just a much better way to get all the data you need, and often more.\n\nThis video I will walk you all through a script I wrote to grab some data from a modern website and show you how and why I made decisions in my code, plus share some data that you can't get from the HTML.\n\nThere's some other useful tips along the way too, including using more of my current favorite python package, Pydantic.\n\nhttps://jsontopydantic.com/\nhttps://github.com/jhnwr/terrex-scraper\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/FPSyjJdudHU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/FPSyjJdudHU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/FPSyjJdudHU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/FPSyjJdudHU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/FPSyjJdudHU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "john watson rooney",
                        "learn python",
                        "web scraping",
                        "web scrapping",
                        "api scraping",
                        "hidden api",
                        "reverse engineer api"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I Don't Waste Time Parsing HTML (So I do THIS)",
                        "description": "OK so it can't be avoided and this is nothing inherently BAD about parsing loads of HTML for scraping data, but the reason I keep banging on about this is that so many times there is just a much better way to get all the data you need, and often more.\n\nThis video I will walk you all through a script I wrote to grab some data from a modern website and show you how and why I made decisions in my code, plus share some data that you can't get from the HTML.\n\nThere's some other useful tips along the way too, including using more of my current favorite python package, Pydantic.\n\nhttps://jsontopydantic.com/\nhttps://github.com/jhnwr/terrex-scraper\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "84373",
                    "likeCount": "1735",
                    "favoriteCount": "0",
                    "commentCount": "107"
                },
                "contentDetails": {
                    "duration": "PT15M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "q8B3yWw7kmk": {
                "snippet": {
                    "publishedAt": "2022-05-12T06:12:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Live: Chatting Code Stuff & QnA",
                    "description": "First Livestream in a long while! Talking about code, answering questions and just generally getting a feel for it",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/q8B3yWw7kmk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/q8B3yWw7kmk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/q8B3yWw7kmk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/q8B3yWw7kmk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/q8B3yWw7kmk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Live: Chatting Code Stuff & QnA",
                        "description": "First Livestream in a long while! Talking about code, answering questions and just generally getting a feel for it"
                    }
                },
                "statistics": {
                    "viewCount": "1389",
                    "likeCount": "61",
                    "favoriteCount": "0",
                    "commentCount": "10"
                },
                "contentDetails": {
                    "duration": "PT1H5M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "G7s0eGOaRPE": {
                "snippet": {
                    "publishedAt": "2022-05-04T14:54:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The Biggest Mistake Beginners Make When Web Scraping",
                    "description": "The first 1,000 people to use the link or my code johnwatsonrooney will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney05221  \n\nThe biggest mistake I see beginners make is trying to scrape from the frontend system, and not the backend.\n\nThe most common thing I see when I am asking about how to scrape a certain site is people struggling to get data from the front end of a modern website. These sites are using SPA (single page applications) that rely heavily on JavaScript or JS framework to load up the data. This way, whilst sometimes possible is just not option for extracting the data. We need to understand a little bit about how these sites work so we can use the right approach or method to accessing the data.\n\nhttps://github.com/jhnwr/billionaires-scraper\n\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Video\n\nCamera: https://amzn.to/3b5N1ej\nLens: https://amzn.to/3QAm7LT\nLighting: https://amzn.to/3Oivn64\n\n# Audio\n\nInterface: https://amzn.to/3OqEqRQ\nMicrophone: https://amzn.to/3xISfEC\nHeadphones: https://amzn.to/3zQrwZv\n\n# PC\n\nCase: https://amzn.to/3dEz6Jw\nPSU: https://amzn.to/3kc7SfB\nCPU: https://amzn.to/2ILxGSh\nMobo: https://amzn.to/3lWmxw4\nRam: https://amzn.to/31muxPc\nGFX card: https://amzn.to/2SKYraW\n32\" monitor: https://amzn.to/3sqgq98 (main)\n27\" monitor: https://amzn.to/2GAH4r9 (vertical)\n24\" monitor: https://amzn.to/3jIFamt (spare)\nDual monitor arm: https://amzn.to/3wpBvlg\nMouse: https://amzn.to/2SH1ssK\nKeyboard: https://amzn.to/3A1B8jU",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/G7s0eGOaRPE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/G7s0eGOaRPE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/G7s0eGOaRPE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/G7s0eGOaRPE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/G7s0eGOaRPE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "john watson rooney",
                        "web scrapping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The Biggest Mistake Beginners Make When Web Scraping",
                        "description": "The first 1,000 people to use the link or my code johnwatsonrooney will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney05221  \n\nThe biggest mistake I see beginners make is trying to scrape from the frontend system, and not the backend.\n\nThe most common thing I see when I am asking about how to scrape a certain site is people struggling to get data from the front end of a modern website. These sites are using SPA (single page applications) that rely heavily on JavaScript or JS framework to load up the data. This way, whilst sometimes possible is just not option for extracting the data. We need to understand a little bit about how these sites work so we can use the right approach or method to accessing the data.\n\nhttps://github.com/jhnwr/billionaires-scraper\n\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Video\n\nCamera: https://amzn.to/3b5N1ej\nLens: https://amzn.to/3QAm7LT\nLighting: https://amzn.to/3Oivn64\n\n# Audio\n\nInterface: https://amzn.to/3OqEqRQ\nMicrophone: https://amzn.to/3xISfEC\nHeadphones: https://amzn.to/3zQrwZv\n\n# PC\n\nCase: https://amzn.to/3dEz6Jw\nPSU: https://amzn.to/3kc7SfB\nCPU: https://amzn.to/2ILxGSh\nMobo: https://amzn.to/3lWmxw4\nRam: https://amzn.to/31muxPc\nGFX card: https://amzn.to/2SKYraW\n32\" monitor: https://amzn.to/3sqgq98 (main)\n27\" monitor: https://amzn.to/2GAH4r9 (vertical)\n24\" monitor: https://amzn.to/3jIFamt (spare)\nDual monitor arm: https://amzn.to/3wpBvlg\nMouse: https://amzn.to/2SH1ssK\nKeyboard: https://amzn.to/3A1B8jU"
                    }
                },
                "statistics": {
                    "viewCount": "119693",
                    "likeCount": "3254",
                    "favoriteCount": "0",
                    "commentCount": "142"
                },
                "contentDetails": {
                    "duration": "PT10M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_1Nf9KNhsPw": {
                "snippet": {
                    "publishedAt": "2022-04-27T14:05:24Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Pydantic is the Python Package I Wish I'd Learned Earlier",
                    "description": "Pydantic is the data validation we need in Python. It allows us to define a model and set the data types for each field, making it not only easier to work with in our IDE but also checking the types at runtime, which is something that is not in Python as standard.\n\nI've found that it helps when dealing with any external data that we would want to process in our applications, like user submitted data or data from files we have received outside our own ecosystem. So far its been a great addition to the way I code and I think you will love it too!\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API I use: https://www.scrapingbee.com?fpr=jhnwr\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_1Nf9KNhsPw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_1Nf9KNhsPw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_1Nf9KNhsPw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_1Nf9KNhsPw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_1Nf9KNhsPw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "pydantic",
                        "learn python",
                        "python tutorials",
                        "data validation in python",
                        "pydantic models",
                        "pydantic validator",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Pydantic is the Python Package I Wish I'd Learned Earlier",
                        "description": "Pydantic is the data validation we need in Python. It allows us to define a model and set the data types for each field, making it not only easier to work with in our IDE but also checking the types at runtime, which is something that is not in Python as standard.\n\nI've found that it helps when dealing with any external data that we would want to process in our applications, like user submitted data or data from files we have received outside our own ecosystem. So far its been a great addition to the way I code and I think you will love it too!\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API I use: https://www.scrapingbee.com?fpr=jhnwr\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr"
                    }
                },
                "statistics": {
                    "viewCount": "56100",
                    "likeCount": "1628",
                    "favoriteCount": "0",
                    "commentCount": "65"
                },
                "contentDetails": {
                    "duration": "PT11M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "bM7SMx44xgY": {
                "snippet": {
                    "publishedAt": "2022-04-21T13:01:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy Middleware - Custom User Agents",
                    "description": "How to rotate User Agents in Scrapy using custom middleware.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/bM7SMx44xgY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/bM7SMx44xgY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/bM7SMx44xgY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/bM7SMx44xgY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/bM7SMx44xgY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy",
                        "scrapy middleware",
                        "john watson rooney",
                        "rotate user agents",
                        "custom user agent",
                        "scrappy"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy Middleware - Custom User Agents",
                        "description": "How to rotate User Agents in Scrapy using custom middleware.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "8896",
                    "likeCount": "226",
                    "favoriteCount": "0",
                    "commentCount": "18"
                },
                "contentDetails": {
                    "duration": "PT8M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "NU4OlJVj1gs": {
                "snippet": {
                    "publishedAt": "2022-04-19T11:30:08Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "GO for Beginners - Web Scraping with Golang Tutorial",
                    "description": "In this golang video tutorial I will guide you through an excellent example of a beginner project for those who have started learning GO. This basic HTML web scraper will introduce you to some of the GO fundamentals, and also hopefully make a slight more interesting project that you can use to expand your GO skills.\n\nWe will learn how to setup our project and use a web scraping framework called Colly - http://go-colly.org/ to extract some data from a test site.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/NU4OlJVj1gs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/NU4OlJVj1gs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/NU4OlJVj1gs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/NU4OlJVj1gs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/NU4OlJVj1gs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn go",
                        "go projects",
                        "go projects for beginners",
                        "web scraping with go",
                        "go colly",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "GO for Beginners - Web Scraping with Golang Tutorial",
                        "description": "In this golang video tutorial I will guide you through an excellent example of a beginner project for those who have started learning GO. This basic HTML web scraper will introduce you to some of the GO fundamentals, and also hopefully make a slight more interesting project that you can use to expand your GO skills.\n\nWe will learn how to setup our project and use a web scraping framework called Colly - http://go-colly.org/ to extract some data from a test site.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "29436",
                    "likeCount": "946",
                    "favoriteCount": "0",
                    "commentCount": "68"
                },
                "contentDetails": {
                    "duration": "PT17M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "kmosTh85dEs": {
                "snippet": {
                    "publishedAt": "2022-04-11T13:21:52Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Parsing HTML Tables with Python to a Dictionary",
                    "description": "Not all HTML tables are created equal! In this video I wanted to show how I approached this scraping challenge. We wanted the table data, as well as the price and item. I decided to loop through the table rows and add them directly to the our dictionary as key value pairs, meaning we had the option to remove and keep which ones we wanted specifically.\n\nI've also used *args to pass tuples into our functions as arguments which helped keep everything neat and tidy.\n\nIf you wish to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/kmosTh85dEs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/kmosTh85dEs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/kmosTh85dEs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/kmosTh85dEs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/kmosTh85dEs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scraping html",
                        "scraping html tables",
                        "learn python",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Parsing HTML Tables with Python to a Dictionary",
                        "description": "Not all HTML tables are created equal! In this video I wanted to show how I approached this scraping challenge. We wanted the table data, as well as the price and item. I decided to loop through the table rows and add them directly to the our dictionary as key value pairs, meaning we had the option to remove and keep which ones we wanted specifically.\n\nI've also used *args to pass tuples into our functions as arguments which helped keep everything neat and tidy.\n\nIf you wish to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr"
                    }
                },
                "statistics": {
                    "viewCount": "15502",
                    "likeCount": "268",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT11M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "O43XPHC_DEs": {
                "snippet": {
                    "publishedAt": "2022-03-31T12:00:24Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Use THIS Algorithm To Find KEYWORDS in Text - A Short Python Project",
                    "description": "Here's a great short beginner project using the RAKE algorithm to extract keywords from review text that we scraped online. Rake stands forRapid Automatic Keyword Extraction which uses the frequency of words in the text to score up key phrases.\n\npackage used: https://csurfer.github.io/rake-nltk/_build/html/index.html\nmy code: https://github.com/jhnwr/rake-on-reviews\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/O43XPHC_DEs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/O43XPHC_DEs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/O43XPHC_DEs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/O43XPHC_DEs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/O43XPHC_DEs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "rake",
                        "python rake",
                        "rake-nltk",
                        "nltk python",
                        "beginner projects",
                        "python projects for beginners",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Use THIS Algorithm To Find KEYWORDS in Text - A Short Python Project",
                        "description": "Here's a great short beginner project using the RAKE algorithm to extract keywords from review text that we scraped online. Rake stands forRapid Automatic Keyword Extraction which uses the frequency of words in the text to score up key phrases.\n\npackage used: https://csurfer.github.io/rake-nltk/_build/html/index.html\nmy code: https://github.com/jhnwr/rake-on-reviews\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "47284",
                    "likeCount": "1048",
                    "favoriteCount": "0",
                    "commentCount": "53"
                },
                "contentDetails": {
                    "duration": "PT5M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "1oGW-ItQG94": {
                "snippet": {
                    "publishedAt": "2022-03-24T14:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "SQLModel is the Pydantic inspired Python ORM we\u2019ve been waiting for",
                    "description": "The first 1,000 people to use this link will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney03221\n\nAn ORM provides a convient layer for us to be able to use Python Objects to talk to our database. It saves us from having to write our own SQL. If you've built any web apps you'll surely have used one, but in this video I want to talk about a relatively new ORM, created by the the same person who made FastAPI. It's build on top of SQLAlchemy and uses Pydantic to make writing code just that little bit easier! I think you will really enjoy using SQLModel.\n\nhttps://sqlmodel.tiangolo.com/\n\nDemo Code: https://github.com/jhnwr/shopify-product-check",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/1oGW-ItQG94/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/1oGW-ItQG94/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/1oGW-ItQG94/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/1oGW-ItQG94/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/1oGW-ItQG94/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "sqlmodel",
                        "python orm",
                        "python database",
                        "python project",
                        "john watson rooney",
                        "sqlmodel python",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "SQLModel is the Pydantic inspired Python ORM we\u2019ve been waiting for",
                        "description": "The first 1,000 people to use this link will get a 1 month free trial of Skillshare: https://skl.sh/johnwatsonrooney03221\n\nAn ORM provides a convient layer for us to be able to use Python Objects to talk to our database. It saves us from having to write our own SQL. If you've built any web apps you'll surely have used one, but in this video I want to talk about a relatively new ORM, created by the the same person who made FastAPI. It's build on top of SQLAlchemy and uses Pydantic to make writing code just that little bit easier! I think you will really enjoy using SQLModel.\n\nhttps://sqlmodel.tiangolo.com/\n\nDemo Code: https://github.com/jhnwr/shopify-product-check"
                    }
                },
                "statistics": {
                    "viewCount": "31846",
                    "likeCount": "680",
                    "favoriteCount": "0",
                    "commentCount": "40"
                },
                "contentDetails": {
                    "duration": "PT8M36S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "I4pVZuNBnH4": {
                "snippet": {
                    "publishedAt": "2022-03-16T14:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Enumerate Will Save You From THIS!",
                    "description": "Having a counter showing where you are in a loop or other iterable is a very useful thing, and there is a very easy option that I've certainly done before as well as seeing a lot of beginners take. But it's not the right way. We have enumerate() in Python that will give you the index and the value of the iterable we are looping through. It's very useful and I'd recommend you start to add it into your code now.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/I4pVZuNBnH4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/I4pVZuNBnH4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/I4pVZuNBnH4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/I4pVZuNBnH4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/I4pVZuNBnH4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "leran python",
                        "python enumerate",
                        "python enumerate start at 1",
                        "john watson rooney",
                        "programming tutorial python",
                        "learn python",
                        "python tutorial",
                        "enumerate python",
                        "python programming"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Enumerate Will Save You From THIS!",
                        "description": "Having a counter showing where you are in a loop or other iterable is a very useful thing, and there is a very easy option that I've certainly done before as well as seeing a lot of beginners take. But it's not the right way. We have enumerate() in Python that will give you the index and the value of the iterable we are looping through. It's very useful and I'd recommend you start to add it into your code now.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "15764",
                    "likeCount": "721",
                    "favoriteCount": "0",
                    "commentCount": "48"
                },
                "contentDetails": {
                    "duration": "PT4M1S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CJjSOzb0IYs": {
                "snippet": {
                    "publishedAt": "2022-03-09T14:00:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to HIDE Your API Keys in Python Projects",
                    "description": "Never commit your API keys or other sensitive data to github again! Keep it neat and tidy by hiding your api key using one of these 2 methods. Both work and have their uses, but I'd lean towards using the .env file to store your own environment variables. It's easy to recreate this file on your server or anywhere else you need to run your project without having to change any code inside.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CJjSOzb0IYs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CJjSOzb0IYs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CJjSOzb0IYs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CJjSOzb0IYs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CJjSOzb0IYs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "api keys",
                        "hide api key github",
                        "hide api key python",
                        "hide api keys",
                        "python projects",
                        "john watson rooney",
                        "api key python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to HIDE Your API Keys in Python Projects",
                        "description": "Never commit your API keys or other sensitive data to github again! Keep it neat and tidy by hiding your api key using one of these 2 methods. Both work and have their uses, but I'd lean towards using the .env file to store your own environment variables. It's easy to recreate this file on your server or anywhere else you need to run your project without having to change any code inside.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "72682",
                    "likeCount": "1798",
                    "favoriteCount": "0",
                    "commentCount": "78"
                },
                "contentDetails": {
                    "duration": "PT4M27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Ii7x4mpIhIs": {
                "snippet": {
                    "publishedAt": "2022-02-27T14:12:48Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Make 2500 HTTP Requests in 2 Seconds with Async & Await",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nThis is a comparison about how to use Async and Asynio with AIOHttp and Python vs using threads and concurrent futures to best understand how we could make several thousand http requests in just a few seconds. Learning how to do this and understanding how it works will help you when it comes to running your own servers and web services, and stress testing any API environments you offer. \n\n# https://github.com/jhnwr/non-blocking-requests/tree/master\n# text articles from: https://realpython.com/\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Ii7x4mpIhIs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Ii7x4mpIhIs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Ii7x4mpIhIs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Ii7x4mpIhIs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Ii7x4mpIhIs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "async",
                        "python",
                        "async await",
                        "asynchronous",
                        "aiohttp",
                        "python requests",
                        "python web scraping",
                        "john watson rooney",
                        "http requests",
                        "python http request"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Make 2500 HTTP Requests in 2 Seconds with Async & Await",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nThis is a comparison about how to use Async and Asynio with AIOHttp and Python vs using threads and concurrent futures to best understand how we could make several thousand http requests in just a few seconds. Learning how to do this and understanding how it works will help you when it comes to running your own servers and web services, and stress testing any API environments you offer. \n\n# https://github.com/jhnwr/non-blocking-requests/tree/master\n# text articles from: https://realpython.com/\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "126917",
                    "likeCount": "2599",
                    "favoriteCount": "0",
                    "commentCount": "113"
                },
                "contentDetails": {
                    "duration": "PT4M27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "PBRMvAKz_rQ": {
                "snippet": {
                    "publishedAt": "2022-02-18T12:00:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Are You Still Using Excel? AUTOMATE it with PYTHON",
                    "description": "If you do the same thing over and over in excel at work you should seriously consider automating it with Python and Pandas! I'll show you how to easily import several csv files into a dataframe, and create some summary pivote tables of the data to share.\n\ncode here: https://github.com/jhnwr/automate-csv-pandas\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/PBRMvAKz_rQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/PBRMvAKz_rQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/PBRMvAKz_rQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/PBRMvAKz_rQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/PBRMvAKz_rQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python pandas",
                        "python automation",
                        "python pandas tutorial",
                        "python pandas dataframe",
                        "pandas",
                        "pandas read csv",
                        "pandas read mutli",
                        "automate reports",
                        "automate excel",
                        "pandas pivotes",
                        "pandas tutorial python",
                        "python excel",
                        "python pandas csv",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Are You Still Using Excel? AUTOMATE it with PYTHON",
                        "description": "If you do the same thing over and over in excel at work you should seriously consider automating it with Python and Pandas! I'll show you how to easily import several csv files into a dataframe, and create some summary pivote tables of the data to share.\n\ncode here: https://github.com/jhnwr/automate-csv-pandas\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr"
                    }
                },
                "statistics": {
                    "viewCount": "50248",
                    "likeCount": "1481",
                    "favoriteCount": "0",
                    "commentCount": "81"
                },
                "contentDetails": {
                    "duration": "PT7M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "YjpGdFwIAxg": {
                "snippet": {
                    "publishedAt": "2022-02-09T15:00:31Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Parse HTML Tables to JSON With Python",
                    "description": "A fun and simple Python Project for beginners, scraping football league table data from HTML to a python dictionary to JSON file.\n\nExtracting Data and Transforming it into another format is a necessary skill to learn, and in this video I will show you how to take the data from an HTML table online and turn it into a well structured Python Dictionary and in turn a JSON file. JSON is the best format for moving and dealing with data and either of the 2 methods I show will work in making your life easier.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/YjpGdFwIAxg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/YjpGdFwIAxg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/YjpGdFwIAxg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/YjpGdFwIAxg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/YjpGdFwIAxg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python tutorial",
                        "python",
                        "python web scraping",
                        "web scraping tutorial",
                        "web scraping with python",
                        "john watson rooney",
                        "web scrapping",
                        "convert html tables to json",
                        "extract data from html",
                        "requests-html",
                        "pandas read html",
                        "extract transform and load",
                        "requests-html tutorial",
                        "python requests-html"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Parse HTML Tables to JSON With Python",
                        "description": "A fun and simple Python Project for beginners, scraping football league table data from HTML to a python dictionary to JSON file.\n\nExtracting Data and Transforming it into another format is a necessary skill to learn, and in this video I will show you how to take the data from an HTML table online and turn it into a well structured Python Dictionary and in turn a JSON file. JSON is the best format for moving and dealing with data and either of the 2 methods I show will work in making your life easier.\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "14053",
                    "likeCount": "338",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT16M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "LEH05TuuEg0": {
                "snippet": {
                    "publishedAt": "2022-02-02T19:03:54Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "FIX Your AttributeError in Python & WHY You See it",
                    "description": "We all find ourselves spending hours trying to fix errors, and without a little help it can be very frustrating! the most common error i get asked about is this one, the attribute error. When trying to scrape data it can be heard to work out what this one means if you are new to Python. In this video I explain the most common reasons you might get this and how to sort it out.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/LEH05TuuEg0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/LEH05TuuEg0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/LEH05TuuEg0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/LEH05TuuEg0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/LEH05TuuEg0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python",
                        "python web scraping",
                        "attribute error in python",
                        "learn webscraping",
                        "web scrapping",
                        "john watson rooney",
                        "web scraping with python",
                        "web scraping error",
                        "web scraping tutorial",
                        "web scraping problems",
                        "how to scrape data"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "FIX Your AttributeError in Python & WHY You See it",
                        "description": "We all find ourselves spending hours trying to fix errors, and without a little help it can be very frustrating! the most common error i get asked about is this one, the attribute error. When trying to scrape data it can be heard to work out what this one means if you are new to Python. In this video I explain the most common reasons you might get this and how to sort it out.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "42368",
                    "likeCount": "487",
                    "favoriteCount": "0",
                    "commentCount": "41"
                },
                "contentDetails": {
                    "duration": "PT5M10S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GyB43hudfQw": {
                "snippet": {
                    "publishedAt": "2022-01-23T15:08:26Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Learn Web Scraping With Python: Full Project - HTML, Save to CSV, Pagination",
                    "description": "This video includes a complete how to of web scraping with Python for beginners. I go through scraping an HTML website, talking about why I have done what I've done and the reasons behind my decisions. It includes, getting data from the server, parsing HTML to get the product information, using functions to not repeat code and make it more organized, dealing with pagination, some small error handling and exporting the final data to a CSV file. Follow along and learn how to web scrape / data extraction with Python.\n\nhttps://github.com/jhnwr/basic-html-scraper\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GyB43hudfQw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GyB43hudfQw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GyB43hudfQw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GyB43hudfQw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/GyB43hudfQw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping",
                        "python",
                        "learn web scraping",
                        "web scrapping",
                        "requests-html",
                        "data extraction",
                        "html scraping",
                        "web scraping tutorial",
                        "python web scraping tutorial",
                        "john watston rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Learn Web Scraping With Python: Full Project - HTML, Save to CSV, Pagination",
                        "description": "This video includes a complete how to of web scraping with Python for beginners. I go through scraping an HTML website, talking about why I have done what I've done and the reasons behind my decisions. It includes, getting data from the server, parsing HTML to get the product information, using functions to not repeat code and make it more organized, dealing with pagination, some small error handling and exporting the final data to a CSV file. Follow along and learn how to web scrape / data extraction with Python.\n\nhttps://github.com/jhnwr/basic-html-scraper\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "38278",
                    "likeCount": "1010",
                    "favoriteCount": "0",
                    "commentCount": "95"
                },
                "contentDetails": {
                    "duration": "PT36M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "_LLSiBMD_sk": {
                "snippet": {
                    "publishedAt": "2022-01-12T15:19:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Turn Websites into Real Time API's with ScrapyRT",
                    "description": "Scrapy is a Python web scraping framework and using the add-on scrapyrt we can turn our project into a web service! this opens up a lot of opportunities for data extraction and expanding and managing your spiders. In this video we explore the concept with a basic example and talk about some of its limitations as well as where it excels.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/_LLSiBMD_sk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/_LLSiBMD_sk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/_LLSiBMD_sk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/_LLSiBMD_sk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/_LLSiBMD_sk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "web scraping with python",
                        "scrapy",
                        "scrapyrt",
                        "website api",
                        "web scraping tutorial",
                        "python web scraping",
                        "data extraction",
                        "data extraction tools",
                        "john watson rooney",
                        "learn scrapy",
                        "scrapy web service",
                        "scrapy api"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Turn Websites into Real Time API's with ScrapyRT",
                        "description": "Scrapy is a Python web scraping framework and using the add-on scrapyrt we can turn our project into a web service! this opens up a lot of opportunities for data extraction and expanding and managing your spiders. In this video we explore the concept with a basic example and talk about some of its limitations as well as where it excels.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "11874",
                    "likeCount": "331",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT5M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "2FNcJKCfrzI": {
                "snippet": {
                    "publishedAt": "2022-01-09T17:16:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "HTTPX is the ASYNC Requests I was Looking For",
                    "description": "HTTPX is a great alternative to using requests that offers the simplicity for simple applications but also comes fully ready for async and await via asyncio, making it a very powerful all in one HTTP client for Python. In this video I show you how it is similar to requests and also demonstrate a simply async API request version.\n\nhttps://github.com/encode/httpx\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/2FNcJKCfrzI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/2FNcJKCfrzI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/2FNcJKCfrzI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/2FNcJKCfrzI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/2FNcJKCfrzI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python tutorial",
                        "python",
                        "httpx python",
                        "python requests",
                        "learn python",
                        "python api tutorial",
                        "python api",
                        "john watson rooney",
                        "python http",
                        "python http client",
                        "python http api"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "HTTPX is the ASYNC Requests I was Looking For",
                        "description": "HTTPX is a great alternative to using requests that offers the simplicity for simple applications but also comes fully ready for async and await via asyncio, making it a very powerful all in one HTTP client for Python. In this video I show you how it is similar to requests and also demonstrate a simply async API request version.\n\nhttps://github.com/encode/httpx\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "20212",
                    "likeCount": "646",
                    "favoriteCount": "0",
                    "commentCount": "34"
                },
                "contentDetails": {
                    "duration": "PT7M23S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "UD4VzOfhBCQ": {
                "snippet": {
                    "publishedAt": "2021-12-19T15:00:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape Amazon Product Reviews with Python",
                    "description": "Scraping Amazon reviews with Python is an easy project that also has some real world use, comparing products and doing research. In this video I show you how I would write a basic Amazon review scraper, much improved from my previous video on this topic, using better fitting tech and writing a more stable scraper.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/UD4VzOfhBCQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/UD4VzOfhBCQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/UD4VzOfhBCQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/UD4VzOfhBCQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/UD4VzOfhBCQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape Amazon Product Reviews with Python",
                        "description": "Scraping Amazon reviews with Python is an easy project that also has some real world use, comparing products and doing research. In this video I show you how I would write a basic Amazon review scraper, much improved from my previous video on this topic, using better fitting tech and writing a more stable scraper.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Oxylabs: https://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 - code JR15\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "16917",
                    "likeCount": "395",
                    "favoriteCount": "0",
                    "commentCount": "60"
                },
                "contentDetails": {
                    "duration": "PT18M51S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "EJNJ5_i_zu8": {
                "snippet": {
                    "publishedAt": "2021-12-12T14:30:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Want To Learn Web Scraping? Start HERE",
                    "description": "Thanks to Oxylabs for sponsoring this video \nhttps://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 \nAdd code \u201cJR15\" at checkout to save 15%\n\n\nI wanted to dump as much information as I could regarding how to get start web scraping! this video includes the top 3 methods I use, the main tools I use, and some basic pitfalls that beginners get stuck at. If you found any of this interesting you'll find dedicated videos on all of it for free on my YouTube channel. I'll have loads more Python, web and Node.js videos coming up soon too.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/EJNJ5_i_zu8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/EJNJ5_i_zu8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/EJNJ5_i_zu8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/EJNJ5_i_zu8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/EJNJ5_i_zu8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python",
                        "web scraping tutorial",
                        "web scraping how to",
                        "web scraping with python",
                        "web scrapping",
                        "python web scraping",
                        "how to scrape data",
                        "web scraping 101"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Want To Learn Web Scraping? Start HERE",
                        "description": "Thanks to Oxylabs for sponsoring this video \nhttps://oxylabs.go2cloud.org/aff_c?offer_id=7&aff_id=356 \nAdd code \u201cJR15\" at checkout to save 15%\n\n\nI wanted to dump as much information as I could regarding how to get start web scraping! this video includes the top 3 methods I use, the main tools I use, and some basic pitfalls that beginners get stuck at. If you found any of this interesting you'll find dedicated videos on all of it for free on my YouTube channel. I'll have loads more Python, web and Node.js videos coming up soon too.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    },
                    "defaultAudioLanguage": "en-US"
                },
                "statistics": {
                    "viewCount": "28103",
                    "likeCount": "1081",
                    "favoriteCount": "0",
                    "commentCount": "46"
                },
                "contentDetails": {
                    "duration": "PT10M54S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "0wO7K-SoUHM": {
                "snippet": {
                    "publishedAt": "2021-11-28T14:30:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape JavaScript Websites with Scrapy and Playwright",
                    "description": "No page is out of reach! Using scrapy and playwright we have the best of both worlds for javascript rendering and data scraping capabilities. In this project i will show you how to get started with a basic scraper on a javascript heavy website, using scrapy-playwright. By putting the headless browser infront of scrapy to make the requests we are able to render out the page, and even wait for certain selectors to be visible before we return the page DOM/HTML and have it be parsed with Scrapy\n\nDoing it this way we have many benefits; scrapy items, item loader, pipelines, middleware all accessible for us to use. There are a few drawbacks however, any web scraping using a real browser is inheritly slower - this is something we can't avoid, as the nature of this method requries loading a browser up to access the page. It does however give us access to sites that we previously would have issues scraping.\n\nhttps://github.com/scrapy-plugins/scrapy-playwright\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/0wO7K-SoUHM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/0wO7K-SoUHM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/0wO7K-SoUHM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/0wO7K-SoUHM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/0wO7K-SoUHM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "playwright",
                        "scrapy",
                        "scrapy playwright",
                        "scrape dynamic data",
                        "render javascript",
                        "scraping javascript",
                        "python web scraping",
                        "web scraping tutorial",
                        "web scraping with python",
                        "learn scrapy",
                        "python scrapy",
                        "web scrapping",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape JavaScript Websites with Scrapy and Playwright",
                        "description": "No page is out of reach! Using scrapy and playwright we have the best of both worlds for javascript rendering and data scraping capabilities. In this project i will show you how to get started with a basic scraper on a javascript heavy website, using scrapy-playwright. By putting the headless browser infront of scrapy to make the requests we are able to render out the page, and even wait for certain selectors to be visible before we return the page DOM/HTML and have it be parsed with Scrapy\n\nDoing it this way we have many benefits; scrapy items, item loader, pipelines, middleware all accessible for us to use. There are a few drawbacks however, any web scraping using a real browser is inheritly slower - this is something we can't avoid, as the nature of this method requries loading a browser up to access the page. It does however give us access to sites that we previously would have issues scraping.\n\nhttps://github.com/scrapy-plugins/scrapy-playwright\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "52986",
                    "likeCount": "1203",
                    "favoriteCount": "0",
                    "commentCount": "169"
                },
                "contentDetails": {
                    "duration": "PT11M12S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "VM8mE9iXAMo": {
                "snippet": {
                    "publishedAt": "2021-11-24T14:39:18Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "AM I Missing out NOT Using Node for Web Scraping?",
                    "description": "Web scraping methods at their core are fairly simple, use your code to create a request to a server, and work through the resulting HTML with an HTML parsing program. Having done a lot of scraping videos using Python I thought I'd try Node JS for creating a simple HTML Amazon scraper. It's just one page and was a fun exercise learning about how the other languages work.\n\nWe use axios and cheerio as our requests and beautifulsoup replacements and write our scraper in about the same amount of lines as Python. Both work well and I would say use which ever you are more comfortable with. \n\nPython does have Scrapy though..\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/VM8mE9iXAMo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/VM8mE9iXAMo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/VM8mE9iXAMo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/VM8mE9iXAMo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/VM8mE9iXAMo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "nodejs",
                        "javascript",
                        "python vs node js",
                        "amazon web scraper",
                        "web scrapping",
                        "scraping data from amazon",
                        "python web scraping",
                        "web scraping tutorial",
                        "web scraping with python",
                        "web scraping with node",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "AM I Missing out NOT Using Node for Web Scraping?",
                        "description": "Web scraping methods at their core are fairly simple, use your code to create a request to a server, and work through the resulting HTML with an HTML parsing program. Having done a lot of scraping videos using Python I thought I'd try Node JS for creating a simple HTML Amazon scraper. It's just one page and was a fun exercise learning about how the other languages work.\n\nWe use axios and cheerio as our requests and beautifulsoup replacements and write our scraper in about the same amount of lines as Python. Both work well and I would say use which ever you are more comfortable with. \n\nPython does have Scrapy though..\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "7493",
                    "likeCount": "220",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT9M12S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "oPjfDkge8Vc": {
                "snippet": {
                    "publishedAt": "2021-11-21T19:49:57Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "THIS is Playwrights BEST Feature for Web Automation",
                    "description": "Playwrights codegen feature will record your inputs and convert it to code, makign creating the basis of your automation script quick and easy. This is one of the best features in my opinion as it saves a LOT of time writing out selectors and clicks and fills. It's not perfect though as we find out.\n\nThis video runs through an example of how to automate buying and item online for testing purposes to demonstrate what Playwright it capable of. We overcome some scrolling issues and output the final piece of data to out terminal.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/oPjfDkge8Vc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/oPjfDkge8Vc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/oPjfDkge8Vc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/oPjfDkge8Vc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/oPjfDkge8Vc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "playwright",
                        "browser automation",
                        "python playwright",
                        "playwright tutorial",
                        "playwright testing",
                        "automatic order placing",
                        "e-commerce store testing",
                        "python tutorial",
                        "python automation",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "THIS is Playwrights BEST Feature for Web Automation",
                        "description": "Playwrights codegen feature will record your inputs and convert it to code, makign creating the basis of your automation script quick and easy. This is one of the best features in my opinion as it saves a LOT of time writing out selectors and clicks and fills. It's not perfect though as we find out.\n\nThis video runs through an example of how to automate buying and item online for testing purposes to demonstrate what Playwright it capable of. We overcome some scrolling issues and output the final piece of data to out terminal.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "44131",
                    "likeCount": "1121",
                    "favoriteCount": "0",
                    "commentCount": "90"
                },
                "contentDetails": {
                    "duration": "PT9M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "H2-5ecFwHHQ": {
                "snippet": {
                    "publishedAt": "2021-11-14T15:00:13Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Login and Scrape Data with Playwright and Python",
                    "description": "Selenium no more.. Playwright is an easy to use, powerful, convenient and modern approach to browser automation. It works very well with Python giving us access to control our browser with code. \n\nIn this short mini series I am going to demo some of my favourite Playwright features starting with this video, logging into a demo dashboard to pull out a simple piece of data.\n\n\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies  I use https://proxyscrape.com/?ref=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/H2-5ecFwHHQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/H2-5ecFwHHQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/H2-5ecFwHHQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/H2-5ecFwHHQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/H2-5ecFwHHQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "playwright",
                        "playwright tutorial",
                        "playwright python",
                        "scrape data behind login",
                        "browser automation",
                        "python browser automation",
                        "playwright automation",
                        "playwright scraper",
                        "web scraping",
                        "web scraping login",
                        "john watson rooney"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Login and Scrape Data with Playwright and Python",
                        "description": "Selenium no more.. Playwright is an easy to use, powerful, convenient and modern approach to browser automation. It works very well with Python giving us access to control our browser with code. \n\nIn this short mini series I am going to demo some of my favourite Playwright features starting with this video, logging into a demo dashboard to pull out a simple piece of data.\n\n\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies  I use https://proxyscrape.com/?ref=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "117069",
                    "likeCount": "3201",
                    "favoriteCount": "0",
                    "commentCount": "174"
                },
                "contentDetails": {
                    "duration": "PT10M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "b3OEo0p6tUM": {
                "snippet": {
                    "publishedAt": "2021-11-09T22:11:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "New to Scrapy? Try it WITH BeautifulSoup to Parse HTML Easily",
                    "description": "Options and variety! If you are new to Scrapy and want to try it out but aren't confident with CSS selectors or XPATH, or perhaps you just want to move some scrapers over to Scrapy for the added benefits of the framework and don't want to rewrite the selectors, you can use BS4 very easily inside your Scrapy project. We can pass the response.text that comes back from the Scrapy request into BeautifulSoup and create a soup object that we can work with.\n\nKeep it easy if you prefer the way BS4 parses HTML!\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/b3OEo0p6tUM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/b3OEo0p6tUM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/b3OEo0p6tUM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/b3OEo0p6tUM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/b3OEo0p6tUM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "scrapy",
                        "beautifulsoup",
                        "beautifulsoup4 python",
                        "parsing html",
                        "lxml",
                        "scrapy beginner project",
                        "learn scrapy",
                        "web scraping tutorial",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "New to Scrapy? Try it WITH BeautifulSoup to Parse HTML Easily",
                        "description": "Options and variety! If you are new to Scrapy and want to try it out but aren't confident with CSS selectors or XPATH, or perhaps you just want to move some scrapers over to Scrapy for the added benefits of the framework and don't want to rewrite the selectors, you can use BS4 very easily inside your Scrapy project. We can pass the response.text that comes back from the Scrapy request into BeautifulSoup and create a soup object that we can work with.\n\nKeep it easy if you prefer the way BS4 parses HTML!\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "7041",
                    "likeCount": "167",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT7M18S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ks-iekIJy6M": {
                "snippet": {
                    "publishedAt": "2021-11-05T20:06:38Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "HIDING Data with JavaScript? Web Scraping Obfuscation",
                    "description": "Websites often take measures to stop bots carelessly scraping data. There are good ways and not so good ways. This is a showcase of how some methods are covering, or obfuscating data within a website which is easily deciphered and broken with minimal code. This educational video should help people work out which levels of data security is for them.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ks-iekIJy6M/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ks-iekIJy6M/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ks-iekIJy6M/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ks-iekIJy6M/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ks-iekIJy6M/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "obfuscation",
                        "obfuscate",
                        "python web scraping",
                        "web scraping",
                        "javascript obfuscation",
                        "javascript website obfuscation",
                        "hidden website data",
                        "web scraping with python",
                        "requests html",
                        "scraping javascript",
                        "what is obfuscation",
                        "obfuscation explained",
                        "email obfuscation"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "HIDING Data with JavaScript? Web Scraping Obfuscation",
                        "description": "Websites often take measures to stop bots carelessly scraping data. There are good ways and not so good ways. This is a showcase of how some methods are covering, or obfuscating data within a website which is easily deciphered and broken with minimal code. This educational video should help people work out which levels of data security is for them.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "8538",
                    "likeCount": "345",
                    "favoriteCount": "0",
                    "commentCount": "26"
                },
                "contentDetails": {
                    "duration": "PT12M50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "o1g8prnkuiQ": {
                "snippet": {
                    "publishedAt": "2021-10-30T16:29:41Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Following LINKS Automatically with Scrapy CrawlSpider",
                    "description": "Scrapy gives us access to two main spiders classes, the generic spider which we have used lots of time before in other videos plus this CrawlSpider that works in a slightly different way. We can give it a rule set and get it to follow links automatically, passing the ones that we want matched back to our parse function with a callback. This makes incredibly easy full website data scraping. In this video I will explain to you how to use the CrawlSpider, what the Rule and LinkExtrator do and how to use them, and also demo how it works.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/o1g8prnkuiQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/o1g8prnkuiQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/o1g8prnkuiQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/o1g8prnkuiQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/o1g8prnkuiQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python",
                        "scrapy",
                        "web scraping tutorial",
                        "web scraping with python",
                        "python web scraping",
                        "web crawler",
                        "web crawling",
                        "scrapy rules",
                        "scrapy linkextrator",
                        "scrapy crawl spider",
                        "crawlspider",
                        "crawlspider example",
                        "crawlspider rules",
                        "crawlspider scrapy example",
                        "crawlspider scrapy"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Following LINKS Automatically with Scrapy CrawlSpider",
                        "description": "Scrapy gives us access to two main spiders classes, the generic spider which we have used lots of time before in other videos plus this CrawlSpider that works in a slightly different way. We can give it a rule set and get it to follow links automatically, passing the ones that we want matched back to our parse function with a callback. This makes incredibly easy full website data scraping. In this video I will explain to you how to use the CrawlSpider, what the Rule and LinkExtrator do and how to use them, and also demo how it works.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "33318",
                    "likeCount": "683",
                    "favoriteCount": "0",
                    "commentCount": "45"
                },
                "contentDetails": {
                    "duration": "PT14M33S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "cta1yCb3vA8": {
                "snippet": {
                    "publishedAt": "2021-10-17T16:00:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping Weather Data with Python",
                    "description": "Here's a beginner level web scraping tutorial for you, scraping weather data from google. I am using requests-html & python - this is my preferred html parsing library as it gives a simple to use syntax and access to CSS selectors to make extraing elements very easy.\n\n\nAt the end of the video I talk a bit about why you should always use an API if there is one available for things like this, however scraping data this way for personal projects is just fine.\n\n\nIf you wish to support me, you can do so with any of these links:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/cta1yCb3vA8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/cta1yCb3vA8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/cta1yCb3vA8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/cta1yCb3vA8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/cta1yCb3vA8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping weather data python",
                        "pytohn web scraping",
                        "web scraping",
                        "web scrapping",
                        "python tutorial",
                        "python",
                        "python beginner tutorial",
                        "beginner web scraping",
                        "python web scraping",
                        "requests-html",
                        "html parsing",
                        "html scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping Weather Data with Python",
                        "description": "Here's a beginner level web scraping tutorial for you, scraping weather data from google. I am using requests-html & python - this is my preferred html parsing library as it gives a simple to use syntax and access to CSS selectors to make extraing elements very easy.\n\n\nAt the end of the video I talk a bit about why you should always use an API if there is one available for things like this, however scraping data this way for personal projects is just fine.\n\n\nIf you wish to support me, you can do so with any of these links:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "63308",
                    "likeCount": "1183",
                    "favoriteCount": "0",
                    "commentCount": "75"
                },
                "contentDetails": {
                    "duration": "PT10M48S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "yLOUJegHoMg": {
                "snippet": {
                    "publishedAt": "2021-10-15T17:00:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Use Scrapy Shell When Creating Web Scraping Projects",
                    "description": "Scrapy comes with its own powerful shell that gives us access to a few necessary and extremely useful commands, and lets us save a temporary version of the webpage that we can interrogate with XPath or CSS selectors to get out the data we want. It works great for grabbing the selectors needed for the elements and copying into our Spider.\n\n\nIt does a few other things, and in this video I will show you how to change headers, including user-agents, make multiple requests in the same shell and how to view the response. I also show you bpython which makes the shell super nice to user and view, although this one works best on linux and mac, not so great on windows.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/yLOUJegHoMg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/yLOUJegHoMg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/yLOUJegHoMg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/yLOUJegHoMg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/yLOUJegHoMg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy",
                        "scrapy shell",
                        "scrapy request",
                        "scrapy user agent",
                        "scrapy shell headers",
                        "scrapy response",
                        "web scraping with scrapy",
                        "python scrapy"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Use Scrapy Shell When Creating Web Scraping Projects",
                        "description": "Scrapy comes with its own powerful shell that gives us access to a few necessary and extremely useful commands, and lets us save a temporary version of the webpage that we can interrogate with XPath or CSS selectors to get out the data we want. It works great for grabbing the selectors needed for the elements and copying into our Spider.\n\n\nIt does a few other things, and in this video I will show you how to change headers, including user-agents, make multiple requests in the same shell and how to view the response. I also show you bpython which makes the shell super nice to user and view, although this one works best on linux and mac, not so great on windows.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "5370",
                    "likeCount": "141",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT7M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ULv9x0GQFbw": {
                "snippet": {
                    "publishedAt": "2021-10-11T20:54:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Handle Errors & Exceptions with Requests and Python",
                    "description": "Learning how to raise and handle your exceptions properly in Python is an extremely useful skill especially when paired with good logging. It enables you to deal with (handle) them at the time and not suffer the consequences further down in your code.\n\n\nIn this video I'll show you a few basic examples of how to raise and log exceptions using the requests HTTP library for Python. We will look at the HTTPerror as well as the ConnctionError and log them accordingly.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ULv9x0GQFbw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ULv9x0GQFbw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ULv9x0GQFbw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ULv9x0GQFbw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ULv9x0GQFbw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "exception handling",
                        "python exceptions",
                        "requests exceptions",
                        "python requests",
                        "logging exceptions",
                        "python requests error handling",
                        "python exception handling",
                        "python tutorial",
                        "requests httperror"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Handle Errors & Exceptions with Requests and Python",
                        "description": "Learning how to raise and handle your exceptions properly in Python is an extremely useful skill especially when paired with good logging. It enables you to deal with (handle) them at the time and not suffer the consequences further down in your code.\n\n\nIn this video I'll show you a few basic examples of how to raise and log exceptions using the requests HTTP library for Python. We will look at the HTTPerror as well as the ConnctionError and log them accordingly.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "17047",
                    "likeCount": "364",
                    "favoriteCount": "0",
                    "commentCount": "20"
                },
                "contentDetails": {
                    "duration": "PT6M46S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "EmDwXmwxVW8": {
                "snippet": {
                    "publishedAt": "2021-09-30T16:01:32Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "A Short and SIMPLE HTML Web Scraper in 6 lines of CODE",
                    "description": "Just a fun video where I thought I'd see how few lines of code I could write to get a functional web scraper. I chose Python and Requests-HTML as it is both the extract and transform (download and parse) parts all in one and I much prefer using CSS selectors these days for HTML parsing. The website had to be HTML and i was going to get 2 points of data from the main page. Sometimes it's nice just to write some short code snippets and who knows maybe this will help someone out!\n\n\nIf you wish to Support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/EmDwXmwxVW8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/EmDwXmwxVW8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/EmDwXmwxVW8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/EmDwXmwxVW8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/EmDwXmwxVW8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "requests-html",
                        "css selectors",
                        "python web scraping",
                        "web scraping python",
                        "python tutorial",
                        "web scraping tutorial",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "A Short and SIMPLE HTML Web Scraper in 6 lines of CODE",
                        "description": "Just a fun video where I thought I'd see how few lines of code I could write to get a functional web scraper. I chose Python and Requests-HTML as it is both the extract and transform (download and parse) parts all in one and I much prefer using CSS selectors these days for HTML parsing. The website had to be HTML and i was going to get 2 points of data from the main page. Sometimes it's nice just to write some short code snippets and who knows maybe this will help someone out!\n\n\nIf you wish to Support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    },
                    "defaultAudioLanguage": "en-US"
                },
                "statistics": {
                    "viewCount": "6799",
                    "likeCount": "156",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT6M41S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "gzQUzslnfeU": {
                "snippet": {
                    "publishedAt": "2021-09-29T14:30:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Retry HTTP Requests Using a Decorator in Python",
                    "description": "Failed requests to a server can cause us all sorts of issues, but rather than just handle the exception and log it away, retry it X amount of times using a retry decorator like this one. \n\nI'll write and demo a retry decorator to show you how it works in principle, however if you are after something that is already written and perfected check out Retry-2 here: https://pypi.org/project/retry2/\n\nthe code in my example is here: https://github.com/jhnwr/retry-requests\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/gzQUzslnfeU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/gzQUzslnfeU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/gzQUzslnfeU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/gzQUzslnfeU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/gzQUzslnfeU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "requests retries",
                        "pytohn requests",
                        "python retry",
                        "retry decorator",
                        "python decorator",
                        "web scraping",
                        "retrying requests",
                        "retry same request"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Retry HTTP Requests Using a Decorator in Python",
                        "description": "Failed requests to a server can cause us all sorts of issues, but rather than just handle the exception and log it away, retry it X amount of times using a retry decorator like this one. \n\nI'll write and demo a retry decorator to show you how it works in principle, however if you are after something that is already written and perfected check out Retry-2 here: https://pypi.org/project/retry2/\n\nthe code in my example is here: https://github.com/jhnwr/retry-requests\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "11988",
                    "likeCount": "360",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT6M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "LFG2Kx1m-Dc": {
                "snippet": {
                    "publishedAt": "2021-09-23T20:27:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "This SQLite Database Model is Easy and Ready for your Python Projects!",
                    "description": "Here is an example model.py file we can use to easily save data to a databse in Python. SQLite3 is a great entry level DB we can use within our Python code to make our data persistent. In this tutorial example I mock up a products database and show you how create a table, insert and view the data saved. \n\n\nThe best thing is that you can import this file into your own projects making it a good base to play around and learn with\n\n\nIf you wish to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/LFG2Kx1m-Dc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/LFG2Kx1m-Dc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/LFG2Kx1m-Dc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/LFG2Kx1m-Dc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/LFG2Kx1m-Dc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "sqlite3",
                        "sqlite",
                        "sqlite3 python",
                        "learn sqlite3",
                        "sqlite3 insert",
                        "tutorial",
                        "sqlite database",
                        "setup sqlite3",
                        "python database",
                        "sqlite tutorial",
                        "sqlite python",
                        "save to db python",
                        "python sqlite3",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "This SQLite Database Model is Easy and Ready for your Python Projects!",
                        "description": "Here is an example model.py file we can use to easily save data to a databse in Python. SQLite3 is a great entry level DB we can use within our Python code to make our data persistent. In this tutorial example I mock up a products database and show you how create a table, insert and view the data saved. \n\n\nThe best thing is that you can import this file into your own projects making it a good base to play around and learn with\n\n\nIf you wish to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "18650",
                    "likeCount": "514",
                    "favoriteCount": "0",
                    "commentCount": "40"
                },
                "contentDetails": {
                    "duration": "PT11M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ouWLsFTgaQw": {
                "snippet": {
                    "publishedAt": "2021-09-14T19:04:24Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Create A Web Scraper Class in Python and requests-html",
                    "description": "Python is an object orientated programming language and learning how to use class objects is essential. this video will cover the basics of making our own Amazon web scraping class that returns some basic information about a product. the focus is on taking an existing short script and creating a reusable class object we can import into our other project files where necessary.\n\n\n\nhttps://github.com/jhnwr/scraper-template\n\n\nSupport Me:\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ouWLsFTgaQw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ouWLsFTgaQw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ouWLsFTgaQw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ouWLsFTgaQw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ouWLsFTgaQw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "pytohn web scraping",
                        "web scrapping",
                        "python classes",
                        "python classes explained",
                        "how to write a class in python",
                        "web scraping",
                        "amazon web scraper"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Create A Web Scraper Class in Python and requests-html",
                        "description": "Python is an object orientated programming language and learning how to use class objects is essential. this video will cover the basics of making our own Amazon web scraping class that returns some basic information about a product. the focus is on taking an existing short script and creating a reusable class object we can import into our other project files where necessary.\n\n\n\nhttps://github.com/jhnwr/scraper-template\n\n\nSupport Me:\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "10030",
                    "likeCount": "295",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT7M30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "fYmQLv16-44": {
                "snippet": {
                    "publishedAt": "2021-09-09T21:00:49Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Add LOGGING to Your Python Projects for Beginners",
                    "description": "As you scrape more and more sites and save more data its a good idea to learn the basics of logging for you Python files so you have a good understanding of whats going on, where its going on and any issues that come up. In this video I'll show you the simplest way to get some good logging for your web scrapers.\n\n\nIf you'd like to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/fYmQLv16-44/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/fYmQLv16-44/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/fYmQLv16-44/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/fYmQLv16-44/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/fYmQLv16-44/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "web scrapping",
                        "python logging",
                        "simple logging",
                        "code tutorial",
                        "web scraper logs"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Add LOGGING to Your Python Projects for Beginners",
                        "description": "As you scrape more and more sites and save more data its a good idea to learn the basics of logging for you Python files so you have a good understanding of whats going on, where its going on and any issues that come up. In this video I'll show you the simplest way to get some good logging for your web scrapers.\n\n\nIf you'd like to support me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "34189",
                    "likeCount": "870",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT6M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "qxj7EXYeNls": {
                "snippet": {
                    "publishedAt": "2021-09-07T22:32:20Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping Data from JavaScript rendered tables with Python",
                    "description": "Spending time rendering pages or parsing HTML does work, but always check this first. by looking in the network tab we find the API is open for us to grab all the data in one go and in 3 lines of code I have all of it in JSON format ready to be anaylsed or stored.\n\n\nIt's not always this simple but always check!\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/qxj7EXYeNls/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/qxj7EXYeNls/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/qxj7EXYeNls/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/qxj7EXYeNls/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/qxj7EXYeNls/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "scraping javascript tables",
                        "web scraping",
                        "scraping tables",
                        "js tables",
                        "web scrapping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping Data from JavaScript rendered tables with Python",
                        "description": "Spending time rendering pages or parsing HTML does work, but always check this first. by looking in the network tab we find the API is open for us to grab all the data in one go and in 3 lines of code I have all of it in JSON format ready to be anaylsed or stored.\n\n\nIt's not always this simple but always check!\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "27858",
                    "likeCount": "569",
                    "favoriteCount": "0",
                    "commentCount": "65"
                },
                "contentDetails": {
                    "duration": "PT5M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "cw5QtDxwTIQ": {
                "snippet": {
                    "publishedAt": "2021-09-05T12:30:17Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Add a Database to your Scrapy Project",
                    "description": "Scrapy is a full featured web scraping framework for Python. In this video I will show you how to create your own Scrapy Pipeline to save scraped data to a SQLITE database using sqlite3. Scrapy and its configuration can look daunting to a beginner but taking the time to learn is well worth it in my opinion. \n\n\nHopefully this video will help you understand how to save scraped data to a database using Scrapy\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/cw5QtDxwTIQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/cw5QtDxwTIQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/cw5QtDxwTIQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/cw5QtDxwTIQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/cw5QtDxwTIQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy tutorial",
                        "scrapy to db",
                        "scrape to database",
                        "scrapy sqlite",
                        "scrapy database",
                        "web scraping with python",
                        "python scrapy tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Add a Database to your Scrapy Project",
                        "description": "Scrapy is a full featured web scraping framework for Python. In this video I will show you how to create your own Scrapy Pipeline to save scraped data to a SQLITE database using sqlite3. Scrapy and its configuration can look daunting to a beginner but taking the time to learn is well worth it in my opinion. \n\n\nHopefully this video will help you understand how to save scraped data to a database using Scrapy\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "13719",
                    "likeCount": "336",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT8M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "pSyiJKdCKtc": {
                "snippet": {
                    "publishedAt": "2021-08-29T16:00:17Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Get Started with Scrapy - Python's Best Web Scraping Framework",
                    "description": "I've been using Scrapy a lot more recently and have been reaping the benefits of a dedicated we scraping framework written in Python. It's fast and simple - once you know how. It can be daunting to those who are new but hopefully this video will help simplify some of the higher entry barriers for beginners with Scrapy. \n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\nSound:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/pSyiJKdCKtc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/pSyiJKdCKtc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/pSyiJKdCKtc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/pSyiJKdCKtc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/pSyiJKdCKtc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "Scrapy",
                        "Scrappy",
                        "scrapy project",
                        "scrapy shell",
                        "allowed domains",
                        "web scraping",
                        "python web scraping",
                        "scraping framework"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Get Started with Scrapy - Python's Best Web Scraping Framework",
                        "description": "I've been using Scrapy a lot more recently and have been reaping the benefits of a dedicated we scraping framework written in Python. It's fast and simple - once you know how. It can be daunting to those who are new but hopefully this video will help simplify some of the higher entry barriers for beginners with Scrapy. \n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\nSound:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "18209",
                    "likeCount": "381",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT23M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "RZI-v-Z1W4c": {
                "snippet": {
                    "publishedAt": "2021-08-22T16:00:17Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to store data with Python and SQLite3",
                    "description": "If you are not storing your data into a database yet and aren't sure where to start let me help you - use SQLITE. In Python we have easy access to sqlite databases and I will show you how to easily create, connect and add data to you new database, including a project based example, where we don't want to add data that already exists.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/RZI-v-Z1W4c/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/RZI-v-Z1W4c/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/RZI-v-Z1W4c/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/RZI-v-Z1W4c/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/RZI-v-Z1W4c/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scrapping",
                        "web scraping",
                        "python database",
                        "sqlite3",
                        "save to db python",
                        "sqlite database",
                        "sqlite",
                        "sqlite3 python create database",
                        "sqlite3 tables",
                        "sqlite3 primary key",
                        "sqlite python create database",
                        "python database tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to store data with Python and SQLite3",
                        "description": "If you are not storing your data into a database yet and aren't sure where to start let me help you - use SQLITE. In Python we have easy access to sqlite databases and I will show you how to easily create, connect and add data to you new database, including a project based example, where we don't want to add data that already exists.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "45225",
                    "likeCount": "1126",
                    "favoriteCount": "0",
                    "commentCount": "66"
                },
                "contentDetails": {
                    "duration": "PT9M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xjieRVnuPcQ": {
                "snippet": {
                    "publishedAt": "2021-08-08T17:00:28Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Hidden APIs with Scrapy - easy JSON data extraction",
                    "description": "I've shown this web scraping method before but never using Scrapy, and given that the Scrapy framework gives us some reaslly good features I thought it was about time I demo'd this. This is it in its most basic form.\n\n\nThis Scrapy project will should you the basic methods for scraping API like data from a website, be it a proper API or the API endpoint you find when scraping a web site.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xjieRVnuPcQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xjieRVnuPcQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xjieRVnuPcQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xjieRVnuPcQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xjieRVnuPcQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Hidden APIs with Scrapy - easy JSON data extraction",
                        "description": "I've shown this web scraping method before but never using Scrapy, and given that the Scrapy framework gives us some reaslly good features I thought it was about time I demo'd this. This is it in its most basic form.\n\n\nThis Scrapy project will should you the basic methods for scraping API like data from a website, be it a proper API or the API endpoint you find when scraping a web site.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "43835",
                    "likeCount": "846",
                    "favoriteCount": "0",
                    "commentCount": "78"
                },
                "contentDetails": {
                    "duration": "PT9M59S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Xw2eNRh4pf8": {
                "snippet": {
                    "publishedAt": "2021-08-04T17:00:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Using Inspect Element for Web Scraping? Watch THIS",
                    "description": "All is not what it seems. JavaScipt uses the DOM, or document object model to change what we see in our browser, versus what the raw source code is. If you have struggled to scrape a site before this could help you understand why what your code sees is different to what our browser has rendered!\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Xw2eNRh4pf8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Xw2eNRh4pf8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Xw2eNRh4pf8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Xw2eNRh4pf8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Xw2eNRh4pf8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Using Inspect Element for Web Scraping? Watch THIS",
                        "description": "All is not what it seems. JavaScipt uses the DOM, or document object model to change what we see in our browser, versus what the raw source code is. If you have struggled to scrape a site before this could help you understand why what your code sees is different to what our browser has rendered!\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "12265",
                    "likeCount": "208",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT5M17S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "DqtlR0y0suo": {
                "snippet": {
                    "publishedAt": "2021-08-01T15:57:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Always Check for the Hidden API when Web Scraping",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nIf this method if available, its the best way to scrape data from site. I will show you how to find the API endpoint that we can use to directly get the JSON data that is being sent from the server, before JavaScript gets its mucky paws on it and makes it look like what we see in our browser. Its quick and simple, and with just a few extra tips and techniques it can transform your web scraping.\n\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/DqtlR0y0suo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/DqtlR0y0suo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/DqtlR0y0suo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/DqtlR0y0suo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/DqtlR0y0suo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "learn python",
                        "modern web scraping",
                        "api endpoints",
                        "hidden api",
                        "web scrapping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Always Check for the Hidden API when Web Scraping",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nIf this method if available, its the best way to scrape data from site. I will show you how to find the API endpoint that we can use to directly get the JSON data that is being sent from the server, before JavaScript gets its mucky paws on it and makes it look like what we see in our browser. Its quick and simple, and with just a few extra tips and techniques it can transform your web scraping.\n\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney"
                    }
                },
                "statistics": {
                    "viewCount": "641369",
                    "likeCount": "15645",
                    "favoriteCount": "0",
                    "commentCount": "547"
                },
                "contentDetails": {
                    "duration": "PT11M50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "aIHTgF6polk": {
                "snippet": {
                    "publishedAt": "2021-07-18T16:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "I Think Scrapy Is Easier Than BS4",
                    "description": "If you want to up your web scraping game, or have been learning python and web scraping for a while but haven't looked at Scrapy, I can help. \n\n\nThis video is a quick run down of the basic scrapy components, and contains a full HTML scraper including pagination. Using CSS selectors, tested with the Scrapy Shell, we are able to get this project underway quickly and easily under 50 lines of written code.\n\n\nAlthough I show an equivalent scraper using BeautifulSoup its worth noting I am not comparing the two. Scrapy is a full web scraping framework, while BS4 is jsut an HTML parser, and a good one that at. It is still the best option in the right situations!\n\n\n\nSupport Me:\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/aIHTgF6polk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/aIHTgF6polk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/aIHTgF6polk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/aIHTgF6polk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/aIHTgF6polk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn scrapy",
                        "web scraping",
                        "python web scraping",
                        "scrapy framework",
                        "scrappy"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "I Think Scrapy Is Easier Than BS4",
                        "description": "If you want to up your web scraping game, or have been learning python and web scraping for a while but haven't looked at Scrapy, I can help. \n\n\nThis video is a quick run down of the basic scrapy components, and contains a full HTML scraper including pagination. Using CSS selectors, tested with the Scrapy Shell, we are able to get this project underway quickly and easily under 50 lines of written code.\n\n\nAlthough I show an equivalent scraper using BeautifulSoup its worth noting I am not comparing the two. Scrapy is a full web scraping framework, while BS4 is jsut an HTML parser, and a good one that at. It is still the best option in the right situations!\n\n\n\nSupport Me:\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "40475",
                    "likeCount": "624",
                    "favoriteCount": "0",
                    "commentCount": "73"
                },
                "contentDetails": {
                    "duration": "PT12M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "QEANQsoEmHI": {
                "snippet": {
                    "publishedAt": "2021-07-13T17:30:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "These 5 Things Help my make better Web Scrapers",
                    "description": "Let me share with you 5 useful tips for web scraping content. Extracting data from the web to analyze is a common need for modern businesses and finding the quickest and most efficient ways of doing so has become a useful skill. \n\nThis video shares 5 tips for helping you on your way to building better spiders and scrapers.\n\nIf you would like to support me and my work:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------\n\n# timestamps\n00:00 intro\n00:21 Response Object\n00:58 Custom Headers\n02:10 Proxies\n03:17 Network Tab\n03:50 Render JS\n04:42 Bonus\n05:30 Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/QEANQsoEmHI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/QEANQsoEmHI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/QEANQsoEmHI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/QEANQsoEmHI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/QEANQsoEmHI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "web scraping tips",
                        "python for beginners",
                        "help web scraping",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "These 5 Things Help my make better Web Scrapers",
                        "description": "Let me share with you 5 useful tips for web scraping content. Extracting data from the web to analyze is a common need for modern businesses and finding the quickest and most efficient ways of doing so has become a useful skill. \n\nThis video shares 5 tips for helping you on your way to building better spiders and scrapers.\n\nIf you would like to support me and my work:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------\n\n# timestamps\n00:00 intro\n00:21 Response Object\n00:58 Custom Headers\n02:10 Proxies\n03:17 Network Tab\n03:50 Render JS\n04:42 Bonus\n05:30 Outro"
                    }
                },
                "statistics": {
                    "viewCount": "6698",
                    "likeCount": "342",
                    "favoriteCount": "0",
                    "commentCount": "45"
                },
                "contentDetails": {
                    "duration": "PT5M39S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CnCBbiLw-HU": {
                "snippet": {
                    "publishedAt": "2021-06-27T17:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Automate Excel Work with Python and Pandas",
                    "description": "Excel tasks are repetitive and boring! Automate them and make your life easier using Python and Pandas. Opening CSV and XLSX files into a Pandas Dataframe is super easy, and setting up to do some basic editing and manipulation with that data can save you hours off your day job.\n\nI will show you how automating tasks such as combining CSV files into one, moving columns around, creating pivot tables and vlookups is easy in Pandas, as well as exporting into all the popular file formats.\n\n\nLearning how to use Pandas is also highly recommended for anyone interested in data as it is Pythons go to for Data Science, so starting small with some basic dataframe manipulation will set you off down the right path.\n\n\nSupport Me:\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# timestamps\n00:00 Intro\n00:38 Data\n01:45 read_csv\n03:46 Change Columns\n08:23 Edit Column Data\n09:56 Add Multiple Files Together\n12:56 Pivot Tables\n17:00 vlookups (merging)\n20:00 Exporting\n21:10 Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CnCBbiLw-HU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CnCBbiLw-HU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CnCBbiLw-HU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CnCBbiLw-HU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CnCBbiLw-HU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python automation",
                        "python excel",
                        "python pandas library",
                        "python tutorial excel",
                        "python excel automation",
                        "automate excel with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Automate Excel Work with Python and Pandas",
                        "description": "Excel tasks are repetitive and boring! Automate them and make your life easier using Python and Pandas. Opening CSV and XLSX files into a Pandas Dataframe is super easy, and setting up to do some basic editing and manipulation with that data can save you hours off your day job.\n\nI will show you how automating tasks such as combining CSV files into one, moving columns around, creating pivot tables and vlookups is easy in Pandas, as well as exporting into all the popular file formats.\n\n\nLearning how to use Pandas is also highly recommended for anyone interested in data as it is Pythons go to for Data Science, so starting small with some basic dataframe manipulation will set you off down the right path.\n\n\nSupport Me:\n\n# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# timestamps\n00:00 Intro\n00:38 Data\n01:45 read_csv\n03:46 Change Columns\n08:23 Edit Column Data\n09:56 Add Multiple Files Together\n12:56 Pivot Tables\n17:00 vlookups (merging)\n20:00 Exporting\n21:10 Outro"
                    }
                },
                "statistics": {
                    "viewCount": "98779",
                    "likeCount": "2286",
                    "favoriteCount": "0",
                    "commentCount": "118"
                },
                "contentDetails": {
                    "duration": "PT21M29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "-oPuGc05Lxs": {
                "snippet": {
                    "publishedAt": "2021-06-20T17:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Working With APIs in Python - Pagination and Data Extraction",
                    "description": "In this video I will show you how to work with an API using Python to extract data. Using the requests module\nwe can request the data in JSON format and then parse it out. Each response comes with some extra info too that\nwe can use to work out how many pages we need to request and the total amount of items we should expect to get.\n\nWorking with APIs in Python is a core skill for any developer so hopefully you can use this video as a good learning\n\nresource and start requesting data from APIs in your own projects!\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# timestamps\n\n\n00:00 - Intro\n00:56 - Endpoints\n03:42 - Code Example\n21:20 - Results and Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/-oPuGc05Lxs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/-oPuGc05Lxs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/-oPuGc05Lxs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/-oPuGc05Lxs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/-oPuGc05Lxs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "working with apis in python",
                        "wokring with apis",
                        "python api",
                        "learn python",
                        "rest api python",
                        "rest api explained",
                        "get data from api",
                        "api pagination",
                        "api pagination python",
                        "api pagination example"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Working With APIs in Python - Pagination and Data Extraction",
                        "description": "In this video I will show you how to work with an API using Python to extract data. Using the requests module\nwe can request the data in JSON format and then parse it out. Each response comes with some extra info too that\nwe can use to work out how many pages we need to request and the total amount of items we should expect to get.\n\nWorking with APIs in Python is a core skill for any developer so hopefully you can use this video as a good learning\n\nresource and start requesting data from APIs in your own projects!\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# timestamps\n\n\n00:00 - Intro\n00:56 - Endpoints\n03:42 - Code Example\n21:20 - Results and Outro"
                    }
                },
                "statistics": {
                    "viewCount": "106985",
                    "likeCount": "3048",
                    "favoriteCount": "0",
                    "commentCount": "136"
                },
                "contentDetails": {
                    "duration": "PT22M36S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CbsbunnH8Q0": {
                "snippet": {
                    "publishedAt": "2021-06-13T14:15:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Create Shopify Private Apps with Python",
                    "description": "In this video I am going to show you how to create a Private app on Shopify, and then use the API information to update products on your store. This example will demonstrate how to change the status of a product through the Shopify API using Python requests and a JSON payload.  We will use a GET request to get all the product data, find the ID and then a PUT request to update a specfic data field.\n\nSupport Me:\n\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CbsbunnH8Q0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CbsbunnH8Q0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CbsbunnH8Q0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CbsbunnH8Q0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CbsbunnH8Q0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "shopify private app",
                        "shopify app development",
                        "how to create private shopify apps",
                        "shopify rest api",
                        "shopify api",
                        "shopify product api",
                        "shopify python api tutorial",
                        "shopify python tutorial",
                        "creating shopify apps",
                        "shopify app tutorial",
                        "shopify app",
                        "shopify api secret",
                        "shopify admin app",
                        "shopify api key"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Create Shopify Private Apps with Python",
                        "description": "In this video I am going to show you how to create a Private app on Shopify, and then use the API information to update products on your store. This example will demonstrate how to change the status of a product through the Shopify API using Python requests and a JSON payload.  We will use a GET request to get all the product data, find the ID and then a PUT request to update a specfic data field.\n\nSupport Me:\n\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "24388",
                    "likeCount": "492",
                    "favoriteCount": "0",
                    "commentCount": "59"
                },
                "contentDetails": {
                    "duration": "PT15M20S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "0D_BqtQtBZc": {
                "snippet": {
                    "publishedAt": "2021-06-06T16:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Create Your Own Scraper API with FastAPI and Python",
                    "description": "In this video I demonstrate how easy it can be using FastAPI to turn a website into an API. Utilising a simple web scraping class, we can pass in an argument to the API and recieve back data based on the keyword tag we requested. \n\nNext episode I'll show you how to deploy the app we made to Heroku for free.\n\nSupport Me:\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 Intro\n00:28 Requirements\n01:09 Write the Scraper\n08:47 FastAPI app()\n13:24 Conclusion & Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/0D_BqtQtBZc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/0D_BqtQtBZc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/0D_BqtQtBZc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/0D_BqtQtBZc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/0D_BqtQtBZc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "create your own api",
                        "create your own api python",
                        "create your own api gateway",
                        "python api",
                        "fastapi scraper",
                        "code tutorial",
                        "learn python",
                        "python programming tutorial",
                        "web scraping",
                        "fastapi tutorial python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Create Your Own Scraper API with FastAPI and Python",
                        "description": "In this video I demonstrate how easy it can be using FastAPI to turn a website into an API. Utilising a simple web scraping class, we can pass in an argument to the API and recieve back data based on the keyword tag we requested. \n\nNext episode I'll show you how to deploy the app we made to Heroku for free.\n\nSupport Me:\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 Intro\n00:28 Requirements\n01:09 Write the Scraper\n08:47 FastAPI app()\n13:24 Conclusion & Outro"
                    }
                },
                "statistics": {
                    "viewCount": "19593",
                    "likeCount": "705",
                    "favoriteCount": "0",
                    "commentCount": "69"
                },
                "contentDetails": {
                    "duration": "PT14M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "lUwZ9rS0SeM": {
                "snippet": {
                    "publishedAt": "2021-05-23T17:00:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with AIOHTTP and Python",
                    "description": "AIOHttp is a client and server side library for Python 3.6 and above that enables us to create http requests asynchronously. It\u2019s fully featured allowing sessions, cookies, custom headers, and everything else you\u2019d expect to see - so naturally I thought it would be a useful tool to share for creating more advanced web scrapers.\n\n\nWhen we are scraping data from the web the chances are we will need to make multiple requests to the server to extract the information we are after, given that each of these requests takes time we find that our code is effectively sat waiting for the response from the server before making the next. This slows the process right down. In its simplest form AIOHTTP allows us to use the Python asyncio library to send vast numbers of requests in a short amount of time, letting us create faster and more efficient web scrapers.\n\n\nSupport Me:\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n#Timestamps\n\n\n00:00 Intro\n01:17 Docs\n02:12 Demo Code\n03:54 Web Scraper\n09:38 HTML from each page\n10:00 Parse HTML\n12:10 Expanding Discussion\n13:21 Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/lUwZ9rS0SeM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/lUwZ9rS0SeM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/lUwZ9rS0SeM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/lUwZ9rS0SeM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/lUwZ9rS0SeM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "aiohttp",
                        "python async",
                        "aiohttp requests",
                        "async web scraping",
                        "aiohttp tutorial python",
                        "aiohttp with asyncio",
                        "aiohttp python tutorial",
                        "aiohttp webscraper",
                        "web scrapping",
                        "python web scrapping",
                        "web scraping with python",
                        "async requests"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with AIOHTTP and Python",
                        "description": "AIOHttp is a client and server side library for Python 3.6 and above that enables us to create http requests asynchronously. It\u2019s fully featured allowing sessions, cookies, custom headers, and everything else you\u2019d expect to see - so naturally I thought it would be a useful tool to share for creating more advanced web scrapers.\n\n\nWhen we are scraping data from the web the chances are we will need to make multiple requests to the server to extract the information we are after, given that each of these requests takes time we find that our code is effectively sat waiting for the response from the server before making the next. This slows the process right down. In its simplest form AIOHTTP allows us to use the Python asyncio library to send vast numbers of requests in a short amount of time, letting us create faster and more efficient web scrapers.\n\n\nSupport Me:\n\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n#Timestamps\n\n\n00:00 Intro\n01:17 Docs\n02:12 Demo Code\n03:54 Web Scraper\n09:38 HTML from each page\n10:00 Parse HTML\n12:10 Expanding Discussion\n13:21 Outro"
                    }
                },
                "statistics": {
                    "viewCount": "25230",
                    "likeCount": "878",
                    "favoriteCount": "0",
                    "commentCount": "94"
                },
                "contentDetails": {
                    "duration": "PT13M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "5Is-QdbKmEI": {
                "snippet": {
                    "publishedAt": "2021-05-16T15:00:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy From one Script: ProcessCrawler",
                    "description": "In this video I'll show you how to use the Scraper ProcessCrawler to run a scrapy spider without using scrapy crawl command. We can use the export feed by utilizing some basic settings. This is a fast fun project to show you just how quickly and easily we can create a scrapy spider.\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# Timestamps\n00:00 Intro\n00:37 Start Code\n01:30 Scrapy Spider\n03:12 Parse\n07:17 Pagination\n08:41 Crawler Process\n10:37 Run and Fixing errors\n11:47 Output CSV\n12:02 Conclusion and Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/5Is-QdbKmEI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/5Is-QdbKmEI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/5Is-QdbKmEI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/5Is-QdbKmEI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/5Is-QdbKmEI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy from script",
                        "scrapy crawler process",
                        "crawlerprocess",
                        "python web scraping",
                        "learn scrapy",
                        "scrapy",
                        "web scraping",
                        "web scraping with python",
                        "python scrapy",
                        "python scrapy tutorial",
                        "scrapy tutorial",
                        "python scraping",
                        "scrapy for beginners",
                        "scrapy spider",
                        "scrapy python tutorial",
                        "python web scraping tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy From one Script: ProcessCrawler",
                        "description": "In this video I'll show you how to use the Scraper ProcessCrawler to run a scrapy spider without using scrapy crawl command. We can use the export feed by utilizing some basic settings. This is a fast fun project to show you just how quickly and easily we can create a scrapy spider.\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# Timestamps\n00:00 Intro\n00:37 Start Code\n01:30 Scrapy Spider\n03:12 Parse\n07:17 Pagination\n08:41 Crawler Process\n10:37 Run and Fixing errors\n11:47 Output CSV\n12:02 Conclusion and Outro"
                    }
                },
                "statistics": {
                    "viewCount": "15084",
                    "likeCount": "401",
                    "favoriteCount": "0",
                    "commentCount": "62"
                },
                "contentDetails": {
                    "duration": "PT12M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "09pgRsEZyK4": {
                "snippet": {
                    "publishedAt": "2021-05-02T13:30:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Don't Start Web Scraping without Doing These First",
                    "description": "I've put together a short video with 5 tips that I feel could help you some of you that are new to web scraping with python. I hope they benefit you in some way!\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# Timestamps\n00:00 Intro\n00:24 Investigate the site\n01:40 Practice Parsing Locally\n02:32 Write a Plan\n04:17 Don't Over complicate it\n05:12 Pick the right tool",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/09pgRsEZyK4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/09pgRsEZyK4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/09pgRsEZyK4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/09pgRsEZyK4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/09pgRsEZyK4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping tips",
                        "learn web scraping",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Don't Start Web Scraping without Doing These First",
                        "description": "I've put together a short video with 5 tips that I feel could help you some of you that are new to web scraping with python. I hope they benefit you in some way!\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Donations: https://www.paypal.com/donate/?hosted_button_id=7HNSFPRR9N63Y\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# Timestamps\n00:00 Intro\n00:24 Investigate the site\n01:40 Practice Parsing Locally\n02:32 Write a Plan\n04:17 Don't Over complicate it\n05:12 Pick the right tool"
                    }
                },
                "statistics": {
                    "viewCount": "28142",
                    "likeCount": "1081",
                    "favoriteCount": "0",
                    "commentCount": "61"
                },
                "contentDetails": {
                    "duration": "PT7M52S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "hV5k1XbcZXA": {
                "snippet": {
                    "publishedAt": "2021-04-25T17:41:22Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape LIVE scores - No BeautifulSoup or Selenium NEEDED!",
                    "description": "By far the easiest and best way to scrape any website is to find the API endpoint, the place where the server puts up the information for the site to render into what we see. It's JSON data - we can mimick the request made with Python using Insomnia API client and extract the data directly, without having to render any pages or parse any HTML. This is the fastest and easy way to scrape data in 2021.\n\n\nSupport Me:\n\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# Timestamps\n00:00 Intro\n00:25 Finding the Data\n03:10 Copy cURL\n05:15 Generate Code\n06:50 Save the Response\n08:15 Extract from JSON\n13:58 Combine requests and parse\n14:45 Outro and Synopsis",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/hV5k1XbcZXA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/hV5k1XbcZXA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/hV5k1XbcZXA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/hV5k1XbcZXA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/hV5k1XbcZXA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrape live scores",
                        "python tutorial 2021",
                        "python programming projects for beginners",
                        "web scraping",
                        "python web scraping",
                        "web scraping with python",
                        "python tutorial",
                        "web scraping tutorial",
                        "api endpoint",
                        "api endpoint tutorial",
                        "api endpoint python",
                        "api endpoint json"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape LIVE scores - No BeautifulSoup or Selenium NEEDED!",
                        "description": "By far the easiest and best way to scrape any website is to find the API endpoint, the place where the server puts up the information for the site to render into what we see. It's JSON data - we can mimick the request made with Python using Insomnia API client and extract the data directly, without having to render any pages or parse any HTML. This is the fastest and easy way to scrape data in 2021.\n\n\nSupport Me:\n\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n\n# Timestamps\n00:00 Intro\n00:25 Finding the Data\n03:10 Copy cURL\n05:15 Generate Code\n06:50 Save the Response\n08:15 Extract from JSON\n13:58 Combine requests and parse\n14:45 Outro and Synopsis"
                    }
                },
                "statistics": {
                    "viewCount": "52367",
                    "likeCount": "1981",
                    "favoriteCount": "0",
                    "commentCount": "119"
                },
                "contentDetails": {
                    "duration": "PT15M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "yrv9V7ZG5hI": {
                "snippet": {
                    "publishedAt": "2021-04-18T13:00:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Spider Arguments with Scrapy & Python",
                    "description": "Scrapy lets us pass in arguments very easily when running our spiders. One use for this is to change categories or certain parameters of the URL being scraped. In this example I'll show you the most basic used of arguments and pass in different teams and sports to an online shops URL, getting us different data.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 Intro\n00:28 Code Explanation\n01:12 Run Spider\n02:00 Add Args\n04:07 Multiple Args\n05:13 Common uses\n06:27 Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/yrv9V7ZG5hI/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/yrv9V7ZG5hI/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/yrv9V7ZG5hI/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/yrv9V7ZG5hI/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/yrv9V7ZG5hI/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python scrapy",
                        "web scraping",
                        "python web scraping",
                        "scrapy python tutorial",
                        "learn python",
                        "scrapy how to",
                        "python tutorial",
                        "scrapy spider example",
                        "scrapy spider arguments",
                        "Scrappy",
                        "web scrapping",
                        "python scrapy tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Spider Arguments with Scrapy & Python",
                        "description": "Scrapy lets us pass in arguments very easily when running our spiders. One use for this is to change categories or certain parameters of the URL being scraped. In this example I'll show you the most basic used of arguments and pass in different teams and sports to an online shops URL, getting us different data.\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 Intro\n00:28 Code Explanation\n01:12 Run Spider\n02:00 Add Args\n04:07 Multiple Args\n05:13 Common uses\n06:27 Outro"
                    }
                },
                "statistics": {
                    "viewCount": "7300",
                    "likeCount": "212",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT6M52S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "-mkewdn9JdU": {
                "snippet": {
                    "publishedAt": "2021-04-11T17:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Crawl and Follow links with SCRAPY - Web Scraping with Python Project",
                    "description": "Scrapy is a powerful web scrapign framework for Python, we can use it to following links and crawl a website, in this case I am going to scrape product data from an online store following each category link one by one and export the data to a CSV file. \n\nScrapy for Beginners -  https://youtu.be/s4jtkzHhLzY\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 - Intro\n00:30 - Startproject & genspider\n01:30 - Website categories\n02:25 - Scrapy Shell\n\n05:15 - Follow Links\n07:15 - Parse product data\n13:33 - Scrapy Crawl\n14:15 -  Results CSV\n15:05 - Summary & Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/-mkewdn9JdU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/-mkewdn9JdU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/-mkewdn9JdU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/-mkewdn9JdU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/-mkewdn9JdU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python scrapy",
                        "web scraping with python projects",
                        "python projects walkthrough",
                        "scrapy spider tutorial",
                        "scrapy spider example",
                        "scrapy tutorial python 3",
                        "python programming projects for beginners",
                        "python projects for resume",
                        "scrapy crawl spider",
                        "scrapy follow",
                        "scrapy follow links",
                        "python scrapy tutorial",
                        "scrapy shell",
                        "web crawler project",
                        "scrapy tutorial",
                        "scrapy spider"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Crawl and Follow links with SCRAPY - Web Scraping with Python Project",
                        "description": "Scrapy is a powerful web scrapign framework for Python, we can use it to following links and crawl a website, in this case I am going to scrape product data from an online store following each category link one by one and export the data to a CSV file. \n\nScrapy for Beginners -  https://youtu.be/s4jtkzHhLzY\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 - Intro\n00:30 - Startproject & genspider\n01:30 - Website categories\n02:25 - Scrapy Shell\n\n05:15 - Follow Links\n07:15 - Parse product data\n13:33 - Scrapy Crawl\n14:15 -  Results CSV\n15:05 - Summary & Outro"
                    }
                },
                "statistics": {
                    "viewCount": "39440",
                    "likeCount": "789",
                    "favoriteCount": "0",
                    "commentCount": "61"
                },
                "contentDetails": {
                    "duration": "PT15M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8drEB06QjLs": {
                "snippet": {
                    "publishedAt": "2021-04-07T14:00:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Slow Web Scraper? Try this with ASYNC and Requests-html",
                    "description": "Async/Await is a popular way to speed up requests being made to a server, its used both client and server side. This is a basic example of how it can work with Requests-HTML and web scraping.\n\nIt works by gathering tasks and running them at the same time eliminating the time spent waiting for a reponse to our request. It stores up and manages the responses for us enabling us to greatly increase the speed of our web scraping.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 - Intro\n01:04 - No ASYNC\n01:44 - Basic ASYNC explanation\n02:22 - Change the code to ASYNC\n04:35 - Tasks\n06:35 - Asycio.run()\n07:33 - Speed test\n08:26 - Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8drEB06QjLs/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8drEB06QjLs/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8drEB06QjLs/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8drEB06QjLs/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8drEB06QjLs/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "learn python",
                        "python requests-html",
                        "python tutorial",
                        "requests-html tutorial",
                        "python web scraping tutorial",
                        "python projects",
                        "web scrapping",
                        "web scraping tutorial",
                        "requests html async",
                        "async web scraping",
                        "async python",
                        "asyncio python",
                        "async python requests",
                        "async python frameworks"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Slow Web Scraper? Try this with ASYNC and Requests-html",
                        "description": "Async/Await is a popular way to speed up requests being made to a server, its used both client and server side. This is a basic example of how it can work with Requests-HTML and web scraping.\n\nIt works by gathering tasks and running them at the same time eliminating the time spent waiting for a reponse to our request. It stores up and manages the responses for us enabling us to greatly increase the speed of our web scraping.\n\n\nSupport Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\n# Timestamps\n00:00 - Intro\n01:04 - No ASYNC\n01:44 - Basic ASYNC explanation\n02:22 - Change the code to ASYNC\n04:35 - Tasks\n06:35 - Asycio.run()\n07:33 - Speed test\n08:26 - Outro"
                    }
                },
                "statistics": {
                    "viewCount": "17711",
                    "likeCount": "503",
                    "favoriteCount": "0",
                    "commentCount": "62"
                },
                "contentDetails": {
                    "duration": "PT8M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "NZ2seWGQa-A": {
                "snippet": {
                    "publishedAt": "2021-04-01T07:52:59Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping LIVE 4!  QnA - Chat - Hangout",
                    "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/NZ2seWGQa-A/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/NZ2seWGQa-A/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/NZ2seWGQa-A/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/NZ2seWGQa-A/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/NZ2seWGQa-A/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "live web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping LIVE 4!  QnA - Chat - Hangout",
                        "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "2584",
                    "likeCount": "102",
                    "favoriteCount": "0",
                    "commentCount": "19"
                },
                "contentDetails": {
                    "duration": "PT1H4M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "e0ZcQn9epeo": {
                "snippet": {
                    "publishedAt": "2021-03-28T14:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping - Append to CSV, Cleaning Data, Requests HTML",
                    "description": "In this video we create a price tracker for a prodcut over multiple websites. Using Python and Requests-HTML we scrape the price information from 4 sites for one product, clean the data and append to CSV using the DictWriter. The idea is this is a good basic starter point for those of you who want to build your own price tracker and is a good beginner python project. I am going to set this code to run on my Digital Ocean cloud server (link below) and check back on it in a few weeks/months! We will see what happened, and discuss ways to improve the code. \n\n\nWeek4 Code: https://github.com/jhnwr/weeklywebscraper\n\nIf you want to learn more about CSS Selectors, check my video here - https://youtu.be/hkDAW7hhEYU\n\n\n Support Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# Timestamps\n\n\n00:00 - Intro\n01:30 - Testing the Idea\n03:20 - Writing Scraping Funtions\n11:07 - Basic Regex\n15:07 - Date.Today()\n17:25 - Main Function\n20:03 - Append to CSV & DictWriter\n23:58 - \"if name == main\" & Summary\n25:17 - Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/e0ZcQn9epeo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/e0ZcQn9epeo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/e0ZcQn9epeo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/e0ZcQn9epeo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/e0ZcQn9epeo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "learn python",
                        "append to csv",
                        "cleaning data in python",
                        "requests html python",
                        "requests html",
                        "python tutorial",
                        "python web scraping tutorial",
                        "web scraping with python",
                        "python csv",
                        "csv dictwriter python",
                        "web scraping python",
                        "scraping python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping - Append to CSV, Cleaning Data, Requests HTML",
                        "description": "In this video we create a price tracker for a prodcut over multiple websites. Using Python and Requests-HTML we scrape the price information from 4 sites for one product, clean the data and append to CSV using the DictWriter. The idea is this is a good basic starter point for those of you who want to build your own price tracker and is a good beginner python project. I am going to set this code to run on my Digital Ocean cloud server (link below) and check back on it in a few weeks/months! We will see what happened, and discuss ways to improve the code. \n\n\nWeek4 Code: https://github.com/jhnwr/weeklywebscraper\n\nIf you want to learn more about CSS Selectors, check my video here - https://youtu.be/hkDAW7hhEYU\n\n\n Support Me:\n\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n# Timestamps\n\n\n00:00 - Intro\n01:30 - Testing the Idea\n03:20 - Writing Scraping Funtions\n11:07 - Basic Regex\n15:07 - Date.Today()\n17:25 - Main Function\n20:03 - Append to CSV & DictWriter\n23:58 - \"if name == main\" & Summary\n25:17 - Outro"
                    }
                },
                "statistics": {
                    "viewCount": "6567",
                    "likeCount": "194",
                    "favoriteCount": "0",
                    "commentCount": "39"
                },
                "contentDetails": {
                    "duration": "PT26M1S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "UClHOT_7hok": {
                "snippet": {
                    "publishedAt": "2021-03-21T18:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with BeautifulSoup and CSS Selectors",
                    "description": "This week I am revisiting a web scraper that I wrote almost a year ago, and improving and cleaning it up. Using requests, beautifulsoup and some user defined functions we deal with pagination and export products to a csv file using pandas. Itertools helps to flatten out a list of lists and is a handy solution to know.\n\n\nLearning Python with Web Scraping is a good fun and practical way to improve your coding abilities. It was interesting for me to see how much I have improved in the last year going over and rewriting a scraping script.\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/UClHOT_7hok/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/UClHOT_7hok/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/UClHOT_7hok/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/UClHOT_7hok/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/UClHOT_7hok/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "weekly web scraping",
                        "weekly web scraper",
                        "web scraping with python",
                        "python web scraping",
                        "web scrapping",
                        "python web scrapping",
                        "learn to code",
                        "code tutorial",
                        "web scraping pagination"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with BeautifulSoup and CSS Selectors",
                        "description": "This week I am revisiting a web scraper that I wrote almost a year ago, and improving and cleaning it up. Using requests, beautifulsoup and some user defined functions we deal with pagination and export products to a csv file using pandas. Itertools helps to flatten out a list of lists and is a handy solution to know.\n\n\nLearning Python with Web Scraping is a good fun and practical way to improve your coding abilities. It was interesting for me to see how much I have improved in the last year going over and rewriting a scraping script.\n\n\nSupport Me:\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "12688",
                    "likeCount": "398",
                    "favoriteCount": "0",
                    "commentCount": "66"
                },
                "contentDetails": {
                    "duration": "PT25M44S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "0MxLaCES4_8": {
                "snippet": {
                    "publishedAt": "2021-03-17T17:19:40Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Basic ASYNC Web Scraping Part2 - Grequests Example Python Project",
                    "description": "Async can be complicated for beginners, managing coroutines and event loops - but in this video I show you an alternative using grequests - all the benefits of Async with the hard work taken care of. Async works by concurrently creating requests to the server without having to wait for each response in turn, it manages them all at the same time. This greatly speeds up the web scraping process when scraping multiple pages. \n\nWe can't include the parsing part asychronously, but that it a CPU intense task and is very quick.I expand on the last video that was on a sandbox site with this real world Python web scraping project that can be implemented to different sites and scaled to many more pages.\n\n\nPart1: https://youtu.be/UDATm1CwIR8\nCode: https://github.com/jhnwr/grequests-scraping\n\n# Support Me\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n## Timestamps\n\n00:00 - Intro\n00:20 - Code from Part1\n01:03 - The Website\n01:55 - Start Code\n03:36 - Async responses\n04:40 - Checking the HTML\n07:10 - Parsing function\n12:44 - Dictionary for output\n14:56 - Test output & Save to CSV\n16:45 - More pages\n17:42 - Summary & Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/0MxLaCES4_8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/0MxLaCES4_8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/0MxLaCES4_8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/0MxLaCES4_8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/0MxLaCES4_8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "grequests",
                        "async webscraping",
                        "web scraping with python",
                        "python web scraping",
                        "scraping multiple pages",
                        "web scrapping",
                        "webscraping",
                        "web scraping",
                        "python tutorial",
                        "python programming"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Basic ASYNC Web Scraping Part2 - Grequests Example Python Project",
                        "description": "Async can be complicated for beginners, managing coroutines and event loops - but in this video I show you an alternative using grequests - all the benefits of Async with the hard work taken care of. Async works by concurrently creating requests to the server without having to wait for each response in turn, it manages them all at the same time. This greatly speeds up the web scraping process when scraping multiple pages. \n\nWe can't include the parsing part asychronously, but that it a CPU intense task and is very quick.I expand on the last video that was on a sandbox site with this real world Python web scraping project that can be implemented to different sites and scaled to many more pages.\n\n\nPart1: https://youtu.be/UDATm1CwIR8\nCode: https://github.com/jhnwr/grequests-scraping\n\n# Support Me\n\n# Amazon US: https://amzn.to/2OzqL1M\n# Amazon UK: https://amzn.to/2OYuMwo\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n## Timestamps\n\n00:00 - Intro\n00:20 - Code from Part1\n01:03 - The Website\n01:55 - Start Code\n03:36 - Async responses\n04:40 - Checking the HTML\n07:10 - Parsing function\n12:44 - Dictionary for output\n14:56 - Test output & Save to CSV\n16:45 - More pages\n17:42 - Summary & Outro"
                    }
                },
                "statistics": {
                    "viewCount": "4512",
                    "likeCount": "184",
                    "favoriteCount": "0",
                    "commentCount": "43"
                },
                "contentDetails": {
                    "duration": "PT18M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "2O1pOuakEVE": {
                "snippet": {
                    "publishedAt": "2021-03-14T18:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Amazon Review Scraper Full Project in Python",
                    "description": "In this episode of Weekly Web Scraping we look at scraping Amazon product reviews. Using Requests-HTML we can extract and save to CSV the top reivew data for each product. We use CSS selectors, list comprehension, write own on functions and work through how to get the data from the website to a CSV file.\n\n\n# Sessions: https://youtu.be/IDhuUpeF1n0\n\n# Code: https://github.com/jhnwr/weeklywebscraper\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n# Timestamps\n\n\n00:00 - Intro\n01:15 - Data to scrape\n02:10 - Getting the data\n04:25 - CSS Selectors\n07:07 - List Comprehension\n08:14 - Get ASINS function\n09:22 - Product Page\n19:37 - Complete Data\n21:31 - Main() function\n23:28 - Saving to CSV\n24:15 - Overview\n25:02 - Troubleshooting\n26:00 - Running Demo\n27:15 - Another error\n28:00 - Our CSV file & Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/2O1pOuakEVE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/2O1pOuakEVE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/2O1pOuakEVE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/2O1pOuakEVE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/2O1pOuakEVE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "weekly web scraping",
                        "python web scraping",
                        "web scraping",
                        "learn python",
                        "scraping amazon",
                        "scraping amazon product reviews",
                        "how to scrape data",
                        "scrape data to csv",
                        "css selectors",
                        "learn web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Amazon Review Scraper Full Project in Python",
                        "description": "In this episode of Weekly Web Scraping we look at scraping Amazon product reviews. Using Requests-HTML we can extract and save to CSV the top reivew data for each product. We use CSS selectors, list comprehension, write own on functions and work through how to get the data from the website to a CSV file.\n\n\n# Sessions: https://youtu.be/IDhuUpeF1n0\n\n# Code: https://github.com/jhnwr/weeklywebscraper\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n\n# Timestamps\n\n\n00:00 - Intro\n01:15 - Data to scrape\n02:10 - Getting the data\n04:25 - CSS Selectors\n07:07 - List Comprehension\n08:14 - Get ASINS function\n09:22 - Product Page\n19:37 - Complete Data\n21:31 - Main() function\n23:28 - Saving to CSV\n24:15 - Overview\n25:02 - Troubleshooting\n26:00 - Running Demo\n27:15 - Another error\n28:00 - Our CSV file & Outro"
                    }
                },
                "statistics": {
                    "viewCount": "5028",
                    "likeCount": "155",
                    "favoriteCount": "0",
                    "commentCount": "46"
                },
                "contentDetails": {
                    "duration": "PT28M37S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "lf38KO5-GwQ": {
                "snippet": {
                    "publishedAt": "2021-03-10T15:00:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Ignoring These Could Cost You Time and Effort",
                    "description": "A quick tip on using sitemaps to find links from a website quickly and efficiently. Many website use XML sitemaps to allow the search engine bots to crawl and index their sites, and we can use them too! In this video I'll give you a quick run down of what a sitemap is, a few techniques to find it and then use BS4 to parse an XML sitemap and extract 4k+ links\n\n\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Timestamps\n00:00 - Intro\n00:10 - What is a Sitemap\n00:45 - Finding Sitemaps\n02:04 - Using Google\n03:02 - Robots.txt\n03:40 - Extract Links with Python\n05:52 - Conclusion\n06:51 - Outro (subscribe!)",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/lf38KO5-GwQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/lf38KO5-GwQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/lf38KO5-GwQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/lf38KO5-GwQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/lf38KO5-GwQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python webscraping",
                        "web scraping with python",
                        "scraping sitemaps",
                        "sitemaps",
                        "extracting data",
                        "website links",
                        "how to find a sitemap",
                        "what is a sitemap",
                        "scrape data from a sitemap",
                        "python requests",
                        "python beautifulsoup",
                        "scraping XML",
                        "web scraping",
                        "python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Ignoring These Could Cost You Time and Effort",
                        "description": "A quick tip on using sitemaps to find links from a website quickly and efficiently. Many website use XML sitemaps to allow the search engine bots to crawl and index their sites, and we can use them too! In this video I'll give you a quick run down of what a sitemap is, a few techniques to find it and then use BS4 to parse an XML sitemap and extract 4k+ links\n\n\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Timestamps\n00:00 - Intro\n00:10 - What is a Sitemap\n00:45 - Finding Sitemaps\n02:04 - Using Google\n03:02 - Robots.txt\n03:40 - Extract Links with Python\n05:52 - Conclusion\n06:51 - Outro (subscribe!)"
                    }
                },
                "statistics": {
                    "viewCount": "11190",
                    "likeCount": "332",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT7M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "aA4o98Xb8JU": {
                "snippet": {
                    "publishedAt": "2021-03-07T16:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Weekly Web Scraping with Python: Product Pages, Pagination, Save to CSV",
                    "description": "Welcome to my new weekly series! Each week we will scrape a new site, and talk about how we achieved extracting the data. Includes different web scraping tools, techniques and general approach to web scraping.\n\nThis week we show how to work wih multiple pages, lists and functions, taking data in and exporting to CSV and much more.\n\n# CSS Selectors: https://www.youtube.com/watch?v=hkDAW7hhEYU\n# Code: https://github.com/jhnwr/weeklywebscraper\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Timestamps:\n00:00 - Intro\n00:26 - Check the Site\n02:05 - Search the Source\n05:03 - CSS Selectors\n10:32 - Create Functions\n13:07 - Scrape Each Product Page\n19:11 - If __name__ == '__main__'\n21:00 - JSON Normalise\n21:30 - Output to CSV\n22:10 - Completed Output\n22:43 - Summary and Outro",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/aA4o98Xb8JU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/aA4o98Xb8JU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/aA4o98Xb8JU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/aA4o98Xb8JU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/aA4o98Xb8JU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping",
                        "python web scraping",
                        "learn web scraping",
                        "learn python",
                        "code tutorial",
                        "learn to code",
                        "python projects",
                        "requests-html",
                        "web scraping pages",
                        "pagination",
                        "chompjs",
                        "python itertools",
                        "product scraper",
                        "ecommerce scraper",
                        "weekly web scraping",
                        "extracting data",
                        "python",
                        "python tutorial",
                        "save to CSV",
                        "pandas to csv",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Weekly Web Scraping with Python: Product Pages, Pagination, Save to CSV",
                        "description": "Welcome to my new weekly series! Each week we will scrape a new site, and talk about how we achieved extracting the data. Includes different web scraping tools, techniques and general approach to web scraping.\n\nThis week we show how to work wih multiple pages, lists and functions, taking data in and exporting to CSV and much more.\n\n# CSS Selectors: https://www.youtube.com/watch?v=hkDAW7hhEYU\n# Code: https://github.com/jhnwr/weeklywebscraper\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n\n# Timestamps:\n00:00 - Intro\n00:26 - Check the Site\n02:05 - Search the Source\n05:03 - CSS Selectors\n10:32 - Create Functions\n13:07 - Scrape Each Product Page\n19:11 - If __name__ == '__main__'\n21:00 - JSON Normalise\n21:30 - Output to CSV\n22:10 - Completed Output\n22:43 - Summary and Outro"
                    }
                },
                "statistics": {
                    "viewCount": "13386",
                    "likeCount": "375",
                    "favoriteCount": "0",
                    "commentCount": "64"
                },
                "contentDetails": {
                    "duration": "PT24M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "UDATm1CwIR8": {
                "snippet": {
                    "publishedAt": "2021-03-03T14:30:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Async Requests Made Simple - Grequests for Web Scraping with Python",
                    "description": "We're starting to look at Async scraping and how it can speed up our web scraping by eliminating the need to wait for the http response each time before moving on. Grequests is a simple but effective way to create multiple http requests in Python allowing us to scrape faster.\n\n\nPyPI Grequests: https://pypi.org/project/grequests/\n\n\nCode: https://github.com/jhnwr/grequests-scraping\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/UDATm1CwIR8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/UDATm1CwIR8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/UDATm1CwIR8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/UDATm1CwIR8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/UDATm1CwIR8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "async scraping",
                        "web scraping",
                        "python web scraping",
                        "scrape fast",
                        "grequests",
                        "python grequests",
                        "simple async http",
                        "asynchronous",
                        "asynchronous web scraping",
                        "learn web scraping",
                        "intermediate web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Async Requests Made Simple - Grequests for Web Scraping with Python",
                        "description": "We're starting to look at Async scraping and how it can speed up our web scraping by eliminating the need to wait for the http response each time before moving on. Grequests is a simple but effective way to create multiple http requests in Python allowing us to scrape faster.\n\n\nPyPI Grequests: https://pypi.org/project/grequests/\n\n\nCode: https://github.com/jhnwr/grequests-scraping\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "11872",
                    "likeCount": "397",
                    "favoriteCount": "0",
                    "commentCount": "54"
                },
                "contentDetails": {
                    "duration": "PT8M51S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "FbEJN8FsJ9U": {
                "snippet": {
                    "publishedAt": "2021-02-28T16:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Argparse Basics - How I run my scripts via the Command Line",
                    "description": "Argparse lets you pass in user defined arguments to you code before it runs, this is a great way to change specific parts without editing your code or taking in user input. This video covers the very basics, and is aimed at someone who has never used argparse before - there's a lot more to it than just this but I hope that this will give you a good idea of what you can achieve with it and maybe make your life a little easier when running your repeatable web scrapers.\n------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/FbEJN8FsJ9U/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/FbEJN8FsJ9U/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/FbEJN8FsJ9U/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/FbEJN8FsJ9U/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/FbEJN8FsJ9U/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "argparse tutorial python 3",
                        "argparse tutorial",
                        "argparse python",
                        "argparse basics",
                        "argparse explained",
                        "argparse examples python 3",
                        "argparse how to",
                        "argparse in python example",
                        "argparse python tutorial",
                        "argparse quickstart",
                        "using argparse",
                        "what is argparse in python",
                        "argparse for dummies",
                        "how argparse work python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Argparse Basics - How I run my scripts via the Command Line",
                        "description": "Argparse lets you pass in user defined arguments to you code before it runs, this is a great way to change specific parts without editing your code or taking in user input. This video covers the very basics, and is aimed at someone who has never used argparse before - there's a lot more to it than just this but I hope that this will give you a good idea of what you can achieve with it and maybe make your life a little easier when running your repeatable web scrapers.\n------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------"
                    }
                },
                "statistics": {
                    "viewCount": "79734",
                    "likeCount": "1468",
                    "favoriteCount": "0",
                    "commentCount": "47"
                },
                "contentDetails": {
                    "duration": "PT6M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "rQXL9A0ST5k": {
                "snippet": {
                    "publishedAt": "2021-02-24T16:00:18Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping Google News the Easy Way with Python and pygooglenews",
                    "description": "I did a video a while back on scraping google news and wanted to revisit it with a new method and new Python package I have just started using - pygooglenews. This way is simple and easy, and allows searching - returning 100 results. I think this gives a good ability to create a cool project, checking news headlines for various keywords and doing something with the data.\n\n\npygooglenews creator github: https://github.com/kotartemiy/pygooglenews\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/rQXL9A0ST5k/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/rQXL9A0ST5k/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/rQXL9A0ST5k/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/rQXL9A0ST5k/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/rQXL9A0ST5k/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scraping news articles python",
                        "scraping news websites",
                        "scraping news headlines python",
                        "web scraping news articles",
                        "news scraping using python",
                        "google news scraper python",
                        "news scraper python",
                        "how to scrape news articles",
                        "learn python",
                        "python web scraper",
                        "pygooglenews",
                        "scraping google news"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping Google News the Easy Way with Python and pygooglenews",
                        "description": "I did a video a while back on scraping google news and wanted to revisit it with a new method and new Python package I have just started using - pygooglenews. This way is simple and easy, and allows searching - returning 100 results. I think this gives a good ability to create a cool project, checking news headlines for various keywords and doing something with the data.\n\n\npygooglenews creator github: https://github.com/kotartemiy/pygooglenews\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "33515",
                    "likeCount": "726",
                    "favoriteCount": "0",
                    "commentCount": "84"
                },
                "contentDetails": {
                    "duration": "PT12M4S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "VKI69VF8Exk": {
                "snippet": {
                    "publishedAt": "2021-02-17T15:00:28Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Don't Ignore This Scraping Technique",
                    "description": "Chompjs lets us easily and quickly extract the data in the script tags of a website. Lots of Javascript websites have this data here, ready to be loaded into the elements on the page - we can grab them and extract all the data neatly into Python dictionaries and lists without having to mess around! We could do it manually, but Chompjs provides an easy and simple way to do it so this video is about how to use it in its simplest form. Make sure you check the source code of the page that you are scraping to see if this can help you, before you spend time and resources rendering the page.\n\n\nChompjs: https://pypi.org/project/chompjs/\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/VKI69VF8Exk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/VKI69VF8Exk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/VKI69VF8Exk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/VKI69VF8Exk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/VKI69VF8Exk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "chompjs",
                        "data in script tags",
                        "json in script",
                        "scraping dynamic websites",
                        "web scraping",
                        "python",
                        "learn web scraping",
                        "web scrapign techniques",
                        "data extracting from websites"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Don't Ignore This Scraping Technique",
                        "description": "Chompjs lets us easily and quickly extract the data in the script tags of a website. Lots of Javascript websites have this data here, ready to be loaded into the elements on the page - we can grab them and extract all the data neatly into Python dictionaries and lists without having to mess around! We could do it manually, but Chompjs provides an easy and simple way to do it so this video is about how to use it in its simplest form. Make sure you check the source code of the page that you are scraping to see if this can help you, before you spend time and resources rendering the page.\n\n\nChompjs: https://pypi.org/project/chompjs/\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "4543",
                    "likeCount": "207",
                    "favoriteCount": "0",
                    "commentCount": "38"
                },
                "contentDetails": {
                    "duration": "PT8M30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "IDhuUpeF1n0": {
                "snippet": {
                    "publishedAt": "2021-02-10T15:00:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Want Faster HTTP Requests? Use A Session with Python!",
                    "description": "This is why I think you should use a http session when web scraping with python. It comes with many benefits and lets us access more features within the requests library, the most common and used Python library for http requests. In this video we look at the connection pooling that is allows us to access to speed up our code when sending requests to the same server. This is perfect for scraping data or accessing APIs.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/IDhuUpeF1n0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/IDhuUpeF1n0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/IDhuUpeF1n0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/IDhuUpeF1n0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/IDhuUpeF1n0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python requests",
                        "requests session",
                        "python requests session",
                        "session objects",
                        "python session tutorial",
                        "faster requests",
                        "speed up web scraping",
                        "python requests advanced",
                        "http requests python",
                        "python requests library",
                        "python requests package",
                        "python web requests",
                        "python coding tutorial",
                        "learn python",
                        "learn web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Want Faster HTTP Requests? Use A Session with Python!",
                        "description": "This is why I think you should use a http session when web scraping with python. It comes with many benefits and lets us access more features within the requests library, the most common and used Python library for http requests. In this video we look at the connection pooling that is allows us to access to speed up our code when sending requests to the same server. This is perfect for scraping data or accessing APIs."
                    }
                },
                "statistics": {
                    "viewCount": "48950",
                    "likeCount": "1323",
                    "favoriteCount": "0",
                    "commentCount": "94"
                },
                "contentDetails": {
                    "duration": "PT7M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Oz902cJcCUg": {
                "snippet": {
                    "publishedAt": "2021-02-03T15:00:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Request Headers for Web Scraping",
                    "description": "With every HTTP request there are headers that contain information about that request. We can maipulate these with requests or which ever web scraping tool we are using with Python to change how the server reacts to us. In this video i'll show you the basics of how they work and what they look like, and then demo how to change the most important ones in your code.\n\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Oz902cJcCUg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Oz902cJcCUg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Oz902cJcCUg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Oz902cJcCUg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Oz902cJcCUg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "request headers explained",
                        "http request headers explained",
                        "request headers python",
                        "http headers tutorial",
                        "custom http headers",
                        "understanding http headers",
                        "headers for web scraping",
                        "web scraping with python",
                        "how to send custom headers",
                        "user agent python",
                        "user agent spoofing",
                        "user agent browser",
                        "user-agent header",
                        "fake user agent python",
                        "python requests user agent"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Request Headers for Web Scraping",
                        "description": "With every HTTP request there are headers that contain information about that request. We can maipulate these with requests or which ever web scraping tool we are using with Python to change how the server reacts to us. In this video i'll show you the basics of how they work and what they look like, and then demo how to change the most important ones in your code.\n\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "46631",
                    "likeCount": "1205",
                    "favoriteCount": "0",
                    "commentCount": "63"
                },
                "contentDetails": {
                    "duration": "PT10M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ue7-MQRhs1E": {
                "snippet": {
                    "publishedAt": "2021-01-27T16:00:34Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape Amazon for ASINs with Requests-HTML",
                    "description": "Let's scrape some more data, this time its Amazon ASINs. Using requests-html and Python we can extract the individual asins from a search page, and create a list for use elsewhere. This is a relatively simple scraper but has some slightly more complex parts in it. We use a CSS selector to find and extract the asin data from the returned HTML render, and filter out the items with missing data.\n\n\nhttps://github.com/jhnwr/asin-scraper\n\n\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ue7-MQRhs1E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ue7-MQRhs1E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ue7-MQRhs1E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ue7-MQRhs1E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ue7-MQRhs1E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "amazon asin scraper",
                        "amazon asin scraper python",
                        "web scraping",
                        "web scraping with python",
                        "scrape amazon",
                        "web scrapping",
                        "scrapping amazon",
                        "amazon web scraping",
                        "extract asins",
                        "learn python",
                        "python projects",
                        "beginner python projects"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape Amazon for ASINs with Requests-HTML",
                        "description": "Let's scrape some more data, this time its Amazon ASINs. Using requests-html and Python we can extract the individual asins from a search page, and create a list for use elsewhere. This is a relatively simple scraper but has some slightly more complex parts in it. We use a CSS selector to find and extract the asin data from the returned HTML render, and filter out the items with missing data.\n\n\nhttps://github.com/jhnwr/asin-scraper\n\n\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "11852",
                    "likeCount": "277",
                    "favoriteCount": "0",
                    "commentCount": "56"
                },
                "contentDetails": {
                    "duration": "PT10M25S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "w607VRIHtT8": {
                "snippet": {
                    "publishedAt": "2021-01-24T15:00:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How To Scrape Woocommerce products with Python & requests-html",
                    "description": "Lets scrape some more ecommerce sites, this time its getting the product data from a woocommce shop, using Python and requests-html only. No Beautifulsoup or Selenium needed. Using CSS selectors to scrape the links from the first page we loop through those and then grab each individual item page for the product info. Then using the build in CSV library for Python we create and export a new CSV file.\n\n\nhttps://github.com/jhnwr/woocommerce-scraper/\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/w607VRIHtT8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/w607VRIHtT8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/w607VRIHtT8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/w607VRIHtT8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/w607VRIHtT8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "requests-html python",
                        "scrape woocommerce",
                        "web scraping tutorial",
                        "requests-html tutorial",
                        "scrape woocommerce data",
                        "scrape products from website",
                        "how to scrape products from ecommerce",
                        "product scraper for woocommerce",
                        "web scraping ecommerce websites python",
                        "web scraping html",
                        "web scraping html with python",
                        "web scraping in python",
                        "web scraping to excel using python",
                        "products to csv"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How To Scrape Woocommerce products with Python & requests-html",
                        "description": "Lets scrape some more ecommerce sites, this time its getting the product data from a woocommce shop, using Python and requests-html only. No Beautifulsoup or Selenium needed. Using CSS selectors to scrape the links from the first page we loop through those and then grab each individual item page for the product info. Then using the build in CSV library for Python we create and export a new CSV file.\n\n\nhttps://github.com/jhnwr/woocommerce-scraper/\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "14592",
                    "likeCount": "234",
                    "favoriteCount": "0",
                    "commentCount": "42"
                },
                "contentDetails": {
                    "duration": "PT23M56S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "hkDAW7hhEYU": {
                "snippet": {
                    "publishedAt": "2021-01-20T19:00:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "You Should Use CSS Selectors for Web Scraping.",
                    "description": "Lets talk CSS Selectors. I demo the most common, and most useful ones to help you extract data using your web scrapers as easily as possible. I'm using requests_html in Python, which can be pip installed if you do not have it already. It's a great libary and well worth learning\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/hkDAW7hhEYU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/hkDAW7hhEYU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/hkDAW7hhEYU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/hkDAW7hhEYU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/hkDAW7hhEYU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "css selectors tutorial",
                        "css selectors explained",
                        "css selector attribute",
                        "css class selector",
                        "descendant selector css",
                        "python css selector example",
                        "css id selector in html",
                        "css multiple class selector",
                        "css selector python",
                        "css selector tutorial",
                        "css selector tricks",
                        "web scraping css selector",
                        "python web scraping",
                        "requests-html",
                        "web scraping tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "You Should Use CSS Selectors for Web Scraping.",
                        "description": "Lets talk CSS Selectors. I demo the most common, and most useful ones to help you extract data using your web scrapers as easily as possible. I'm using requests_html in Python, which can be pip installed if you do not have it already. It's a great libary and well worth learning\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "16297",
                    "likeCount": "382",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT10M28S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "J82SxHP5SWY": {
                "snippet": {
                    "publishedAt": "2021-01-13T19:00:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Beautifulsoup vs Selenium vs Scrapy - Which Tool for Web Scraping?",
                    "description": "Lets talk about scraping and which tool should you use for your web scraping projects in 2021 - Beautifulsoup, Scrapy or Selenium? When picking the right tool for your web scraping project these are the main 3 options that pop up, so learning when to use each one is an important skill. I go through what I think the top line is for each, and give some insight into the pros and cons and what they are best suited for.\n\n\nBS4 Tips: https://youtu.be/3tUUVenpxbc\nScrapy for beginners: https://youtu.be/s4jtkzHhLzY\nSelenium scraping: https://youtu.be/lTypMlVBFM4\n\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/J82SxHP5SWY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/J82SxHP5SWY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/J82SxHP5SWY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/J82SxHP5SWY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/J82SxHP5SWY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "Beautifulsoup vs Selenium vs Scrapy",
                        "web scraping with python",
                        "python web scraping",
                        "python scraping data",
                        "web scraping python selenium beautifulsoup",
                        "python for web scraping",
                        "best tool for web scraping",
                        "beautifulsoup vs selenium",
                        "beautifulsoup or scrapy"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Beautifulsoup vs Selenium vs Scrapy - Which Tool for Web Scraping?",
                        "description": "Lets talk about scraping and which tool should you use for your web scraping projects in 2021 - Beautifulsoup, Scrapy or Selenium? When picking the right tool for your web scraping project these are the main 3 options that pop up, so learning when to use each one is an important skill. I go through what I think the top line is for each, and give some insight into the pros and cons and what they are best suited for.\n\n\nBS4 Tips: https://youtu.be/3tUUVenpxbc\nScrapy for beginners: https://youtu.be/s4jtkzHhLzY\nSelenium scraping: https://youtu.be/lTypMlVBFM4\n\n\nSupport me:\nAmazon US: https://amzn.to/3cdvjEr\nAmazon UK: https://amzn.to/3iMRtOW\nDigital Ocean: https://m.do.co/c/c7c90f161ff6 \n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases"
                    }
                },
                "statistics": {
                    "viewCount": "77576",
                    "likeCount": "2650",
                    "favoriteCount": "0",
                    "commentCount": "101"
                },
                "contentDetails": {
                    "duration": "PT6M54S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "3tUUVenpxbc": {
                "snippet": {
                    "publishedAt": "2021-01-06T19:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "5 Things You Might Not Be Using in BeautifulSoup",
                    "description": "My 5 top tips for parsing HTML and web scraping using BeautifulSoup! BS4 is the go to library for HTML parsing in Python and for good reason. It's lightweight, fast and simple to use. But I wonder how many people just use the main ways to search the HTML? In this video I have put together a few things that may help you parse better HTML and write more efficient web scrapers using BS4.\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/3tUUVenpxbc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/3tUUVenpxbc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/3tUUVenpxbc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/3tUUVenpxbc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/3tUUVenpxbc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "beautifulsoup tutorial",
                        "beautifulsoup python 3",
                        "beautifulsoup python web scraping",
                        "beautifulsoup python",
                        "beautifulsoup and requests",
                        "beautifulsoup basics",
                        "beautifulsoup css selector",
                        "beautifulsoup code example",
                        "beautifulsoup example",
                        "beautifulsoup extract specific text",
                        "beautifulsoup guide",
                        "beautifulsoup html",
                        "beautifulsoup methods",
                        "beautifulsoup navigate html",
                        "beautifulsoup regex",
                        "beautifulsoup scraping tutorial",
                        "web scraping with python and beautifulsoup"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "5 Things You Might Not Be Using in BeautifulSoup",
                        "description": "My 5 top tips for parsing HTML and web scraping using BeautifulSoup! BS4 is the go to library for HTML parsing in Python and for good reason. It's lightweight, fast and simple to use. But I wonder how many people just use the main ways to search the HTML? In this video I have put together a few things that may help you parse better HTML and write more efficient web scrapers using BS4.\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "11293",
                    "likeCount": "424",
                    "favoriteCount": "0",
                    "commentCount": "36"
                },
                "contentDetails": {
                    "duration": "PT10M32S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WNBhpohY4f0": {
                "snippet": {
                    "publishedAt": "2021-01-01T13:00:22Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How Learning Code Could Change Your Life",
                    "description": "A short take on why I learned to code and how I found focusing on things I wanted to change really helped me get out of a learning rut.\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WNBhpohY4f0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WNBhpohY4f0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WNBhpohY4f0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WNBhpohY4f0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WNBhpohY4f0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "why i learned to code",
                        "python coding",
                        "python motivation",
                        "coding motivation",
                        "reasons to code",
                        "learn python",
                        "learning resource"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How Learning Code Could Change Your Life",
                        "description": "A short take on why I learned to code and how I found focusing on things I wanted to change really helped me get out of a learning rut.\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "3136",
                    "likeCount": "242",
                    "favoriteCount": "0",
                    "commentCount": "33"
                },
                "contentDetails": {
                    "duration": "PT3M43S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "oKk3dplKLVg": {
                "snippet": {
                    "publishedAt": "2020-12-30T19:00:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I found the best Steam Deals this Winter - Web Scraping with Python",
                    "description": "Using Python and web scraping techniques I was able to scrape 6300+ results from the steam top sellers website, finding the best deals for the games I wanted. This video includes some basic and intermediate web scraping techniques including finding a way around infinite scroll websites. Python is a simple and friendly programming language making it ideal for beginners. Following along with my coding videos is a good way to learn the language and get meaningful results at the end.\n\n\ncode: https://github.com/jhnwr/steamdeals\n\n\nYes, the CSV file is there too.\n\n\nBasic Scraper: https://youtu.be/nCuPv3tf2Hg\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n**Buying through these links helps me keep my conent free and available to all**\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/oKk3dplKLVg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/oKk3dplKLVg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/oKk3dplKLVg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/oKk3dplKLVg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/oKk3dplKLVg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping steam",
                        "scraping steam deals",
                        "steam games",
                        "deals on steam",
                        "scraping steam",
                        "web scraping steam data",
                        "steam deals data",
                        "top steam deals",
                        "learn web scraping",
                        "scrape infinite scroll",
                        "infinite scroll",
                        "how to scrape infinite scrolling pages python",
                        "web scrape infinite scroll",
                        "scrape infinite scroll python",
                        "code tutorial",
                        "coding lesson",
                        "learn to code",
                        "learn python",
                        "python functions",
                        "python web scraping",
                        "web scraping with python",
                        "steam deals"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I found the best Steam Deals this Winter - Web Scraping with Python",
                        "description": "Using Python and web scraping techniques I was able to scrape 6300+ results from the steam top sellers website, finding the best deals for the games I wanted. This video includes some basic and intermediate web scraping techniques including finding a way around infinite scroll websites. Python is a simple and friendly programming language making it ideal for beginners. Following along with my coding videos is a good way to learn the language and get meaningful results at the end.\n\n\ncode: https://github.com/jhnwr/steamdeals\n\n\nYes, the CSV file is there too.\n\n\nBasic Scraper: https://youtu.be/nCuPv3tf2Hg\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\n**Buying through these links helps me keep my conent free and available to all**\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "9046",
                    "likeCount": "278",
                    "favoriteCount": "0",
                    "commentCount": "48"
                },
                "contentDetails": {
                    "duration": "PT27M47S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "63PrrrmRj88": {
                "snippet": {
                    "publishedAt": "2020-12-25T04:38:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Live Coding - Web Scraping Project & Chat",
                    "description": "Some Live Coding\nQ&A session and hang out",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/63PrrrmRj88/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/63PrrrmRj88/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/63PrrrmRj88/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/63PrrrmRj88/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/63PrrrmRj88/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Live Coding - Web Scraping Project & Chat",
                        "description": "Some Live Coding\nQ&A session and hang out"
                    }
                },
                "statistics": {
                    "viewCount": "2012",
                    "likeCount": "72",
                    "favoriteCount": "0",
                    "commentCount": "13"
                },
                "contentDetails": {
                    "duration": "PT1H45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "wyE4oDxScfE": {
                "snippet": {
                    "publishedAt": "2020-12-23T19:00:18Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "What I'd Add FIRST To a new Scrapy Project",
                    "description": "In my last Scrapy video we created a basic project from scratch but found some limitations. In this episode we will go through how to use Items and the Itemloader classes in Scrapy to make our project better. The Items class allows us to define fields for our data within our items.py, and utilises the ItemLoader to help us clean the data before loading it ready for use.\n\n\nScrapy p1: https://youtu.be/s4jtkzHhLzY\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/wyE4oDxScfE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/wyE4oDxScfE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/wyE4oDxScfE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/wyE4oDxScfE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/wyE4oDxScfE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy items",
                        "scrapy item example",
                        "scrapy itemloader",
                        "scrapy items.py",
                        "scrapy item class",
                        "scrapy item fields",
                        "scrapy item loader",
                        "scrapy item tutorial",
                        "basic scrapy project",
                        "learn web scraping",
                        "web scraping tutorial",
                        "scrapy web scraping",
                        "scrapy beginner",
                        "scrapy tutorial",
                        "scrapy lessons",
                        "online coding lesson",
                        "learn python",
                        "scrape websites"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "What I'd Add FIRST To a new Scrapy Project",
                        "description": "In my last Scrapy video we created a basic project from scratch but found some limitations. In this episode we will go through how to use Items and the Itemloader classes in Scrapy to make our project better. The Items class allows us to define fields for our data within our items.py, and utilises the ItemLoader to help us clean the data before loading it ready for use.\n\n\nScrapy p1: https://youtu.be/s4jtkzHhLzY\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nstudio lights https://amzn.to/3aBpKik\nsmall lights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "33709",
                    "likeCount": "941",
                    "favoriteCount": "0",
                    "commentCount": "66"
                },
                "contentDetails": {
                    "duration": "PT15M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "mTOXVRao3eA": {
                "snippet": {
                    "publishedAt": "2020-12-16T19:00:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy Splash for Beginners - Example, Settings and Shell Use",
                    "description": "In this video I will show you how to get scrapy working with splash. By sending our requests to the splash API we can render and scrape dynamic and javascript webpages within scrapy. This tutorial will cover the settings, using the shell and a basic example at the end. I have two other videos that will help you if you are a beginner and are looking for some good examples and tutorials using Python and Scrapy:\n\nScrapy: https://youtu.be/s4jtkzHhLzY\n\nSplash: https://youtu.be/8q2K41QC2nQ\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\n\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/mTOXVRao3eA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/mTOXVRao3eA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/mTOXVRao3eA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/mTOXVRao3eA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/mTOXVRao3eA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy splash python",
                        "scrapy splash example",
                        "scrapy splash shell",
                        "scrapy splash tutorial",
                        "scrapy splash javascript",
                        "python scrapy splash tutorial",
                        "scrapy splash settings",
                        "scrapy with splash",
                        "scrapy splash windows",
                        "scrapy-splash tutorial",
                        "scrapy-splash example",
                        "scrapy splash",
                        "scrapy tutorial for beginners",
                        "scrapy and splash",
                        "scrapy dynamic web pages",
                        "scrapy example",
                        "python coding",
                        "web scraping",
                        "python web scraping",
                        "learn web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy Splash for Beginners - Example, Settings and Shell Use",
                        "description": "In this video I will show you how to get scrapy working with splash. By sending our requests to the splash API we can render and scrape dynamic and javascript webpages within scrapy. This tutorial will cover the settings, using the shell and a basic example at the end. I have two other videos that will help you if you are a beginner and are looking for some good examples and tutorials using Python and Scrapy:\n\nScrapy: https://youtu.be/s4jtkzHhLzY\n\nSplash: https://youtu.be/8q2K41QC2nQ\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\n\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "36468",
                    "likeCount": "785",
                    "favoriteCount": "0",
                    "commentCount": "101"
                },
                "contentDetails": {
                    "duration": "PT14M10S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "s4jtkzHhLzY": {
                "snippet": {
                    "publishedAt": "2020-12-09T19:00:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy for Beginners - A Complete How To Example Web Scraping Project",
                    "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nScrapy for Beginners! This python tutorial is aimed at people new to Scrapy. We cover crawling with a basic spider an create a complete tutorial project, including exporting to a JSON file. We scrape products from a online shop and get names and prices. Learn how to use the Scrapy shell to parse the data, and get text and \"href\" attributes from the HTML, as well as scraping multiple pages. This is a full how to from start to finish for your first Scrapy spider project, all in Python 3.\n\ncode: https://github.com/jhnwr/whiskyspider\n\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# The Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Donate: https://www.paypal.com/donate?hosted_button_id=GZCASYK8XYKGE\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/\n\nDISCLAIMER This contains affiliate links. If you use these links to buy something we may earn a commission.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/s4jtkzHhLzY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/s4jtkzHhLzY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/s4jtkzHhLzY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/s4jtkzHhLzY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/s4jtkzHhLzY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrapy python tutorial",
                        "scrapy crawlspider",
                        "scrapy complete tutorial",
                        "scrapy example",
                        "scrapy example project",
                        "scrapy for beginners",
                        "scrapy get attribute value",
                        "scrapy how to",
                        "scrapy json",
                        "scrapy next page python",
                        "scrapy multiple pages",
                        "scrapy pagination",
                        "scrapy python 3",
                        "scrapy shell",
                        "python tutorial",
                        "learn python",
                        "web scraping project",
                        "web scraping with python",
                        "online python course",
                        "python web scraping scrapy",
                        "python scrapy",
                        "python web scraping",
                        "web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy for Beginners - A Complete How To Example Web Scraping Project",
                        "description": "# DISCORD (NEW): https://discord.gg/C4J2uckpbR\n\nScrapy for Beginners! This python tutorial is aimed at people new to Scrapy. We cover crawling with a basic spider an create a complete tutorial project, including exporting to a JSON file. We scrape products from a online shop and get names and prices. Learn how to use the Scrapy shell to parse the data, and get text and \"href\" attributes from the HTML, as well as scraping multiple pages. This is a full how to from start to finish for your first Scrapy spider project, all in Python 3.\n\ncode: https://github.com/jhnwr/whiskyspider\n\n# Proxies: https://proxyscrape.com/?ref=jhnwr\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)\n# The Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Donate: https://www.paypal.com/donate?hosted_button_id=GZCASYK8XYKGE\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/\n\nDISCLAIMER This contains affiliate links. If you use these links to buy something we may earn a commission."
                    }
                },
                "statistics": {
                    "viewCount": "274777",
                    "likeCount": "5189",
                    "favoriteCount": "0",
                    "commentCount": "345"
                },
                "contentDetails": {
                    "duration": "PT23M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "csj1RoLTMIA": {
                "snippet": {
                    "publishedAt": "2020-12-02T15:00:13Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "EBAY Price Tracking with Python, Beautifulsoup and Requests",
                    "description": "This lession I will show you how I scraped ebay for sold item prices, to create an easy way of finding out what things are worth second hand. the saying goes \"its only worth what someone will pay for it!\" so we are going to find out just that! This is a short beginner friendly script that uses only a few packages to complete the scrape, and as always I do my best to keep it concise and to the point. 35 lines of code, output to CSV. an easy and fun Python project for beginners!\n\nCode: https://github.com/jhnwr/ebay-prices\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/csj1RoLTMIA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/csj1RoLTMIA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/csj1RoLTMIA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/csj1RoLTMIA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/csj1RoLTMIA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "scrape ebay",
                        "web scraping tutorial",
                        "learn web scraping",
                        "python lesson",
                        "web scraping lesson",
                        "ebay scraping",
                        "collect ebay data",
                        "download ebay data",
                        "save ebay to csv",
                        "python beginner projects",
                        "basic webscraping",
                        "ebay scraper python",
                        "ebay scraper",
                        "web scraper python",
                        "web scrape with python",
                        "web scraper python beautifulsoup",
                        "web scraper tutorial",
                        "web scrape",
                        "web scrape ebay",
                        "ebay price tracking",
                        "ebay price tracker"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "EBAY Price Tracking with Python, Beautifulsoup and Requests",
                        "description": "This lession I will show you how I scraped ebay for sold item prices, to create an easy way of finding out what things are worth second hand. the saying goes \"its only worth what someone will pay for it!\" so we are going to find out just that! This is a short beginner friendly script that uses only a few packages to complete the scrape, and as always I do my best to keep it concise and to the point. 35 lines of code, output to CSV. an easy and fun Python project for beginners!\n\nCode: https://github.com/jhnwr/ebay-prices\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "34308",
                    "likeCount": "962",
                    "favoriteCount": "0",
                    "commentCount": "127"
                },
                "contentDetails": {
                    "duration": "PT20M33S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "hftDoPXyvFc": {
                "snippet": {
                    "publishedAt": "2020-11-25T19:00:25Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scraping Amazon's best Black Friday DEALS with Python",
                    "description": "Here is my \"how to\" on writing a Python script to collect and determine what is the best Amazon Black Friday deal, based on our search term and the percentage off the items. It returns a CSV with all the data, and involves web scraping multiple pages of Amazon store front.\n\n\nCODE: https://github.com/jhnwr/amazonbf-deals\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/hftDoPXyvFc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/hftDoPXyvFc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/hftDoPXyvFc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/hftDoPXyvFc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/hftDoPXyvFc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python web scraping",
                        "web scraping amazon",
                        "extract amazon data",
                        "amazon deals",
                        "scrape best amazon deals",
                        "python coding tutorial",
                        "web scraping lesson",
                        "web scraping tutorial",
                        "learn web scraping",
                        "how to web scrape",
                        "learn python",
                        "amazon scraping",
                        "scrape to csv",
                        "web scraping projects"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scraping Amazon's best Black Friday DEALS with Python",
                        "description": "Here is my \"how to\" on writing a Python script to collect and determine what is the best Amazon Black Friday deal, based on our search term and the percentage off the items. It returns a CSV with all the data, and involves web scraping multiple pages of Amazon store front.\n\n\nCODE: https://github.com/jhnwr/amazonbf-deals\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean (Cloud Servers, Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "14760",
                    "likeCount": "414",
                    "favoriteCount": "0",
                    "commentCount": "45"
                },
                "contentDetails": {
                    "duration": "PT41M50S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "4VfqVpTz4Q4": {
                "snippet": {
                    "publishedAt": "2020-11-22T17:03:56Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape multiple pages on Amazon with Python, Requests & BeautifulSoup",
                    "description": "In this video I will demonstrate one of the ways to deal with the pagination when scraping the amazon website. We check to see if the next button is availabe then collect the url from it, and using our functions, move to scrape the next page. this works well as we can let it run and collect all the pages without having to add a number to the url each time. This method would also work for other websites that have a similar style of pagination\n\ncode: https://github.com/jhnwr/amazon-pagination\n\nDigital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\n\naudio interface https://amzn.to/2FlnfU0\n\n-------------------------------------\n\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/4VfqVpTz4Q4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/4VfqVpTz4Q4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/4VfqVpTz4Q4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/4VfqVpTz4Q4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/4VfqVpTz4Q4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrape multiple pages python beautifulsoup",
                        "scrape multiple pages",
                        "python web scraping",
                        "web scraping",
                        "python tutorial",
                        "learn python",
                        "scraping pages",
                        "how to deal with pagination",
                        "scraping amazon",
                        "web scrape amazon",
                        "amazon pagination",
                        "web scraping with python",
                        "scrape amazon data",
                        "scrape data from amazon",
                        "how to scrape amazon using python",
                        "how to scrape amazon using beautifulsoup"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape multiple pages on Amazon with Python, Requests & BeautifulSoup",
                        "description": "In this video I will demonstrate one of the ways to deal with the pagination when scraping the amazon website. We check to see if the next button is availabe then collect the url from it, and using our functions, move to scrape the next page. this works well as we can let it run and collect all the pages without having to add a number to the url each time. This method would also work for other websites that have a similar style of pagination\n\ncode: https://github.com/jhnwr/amazon-pagination\n\nDigital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\n\naudio interface https://amzn.to/2FlnfU0\n\n-------------------------------------\n\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "96266",
                    "likeCount": "1773",
                    "favoriteCount": "0",
                    "commentCount": "127"
                },
                "contentDetails": {
                    "duration": "PT11M24S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "VztRqRXeyn0": {
                "snippet": {
                    "publishedAt": "2020-11-18T19:00:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Run Your Web Scraper Automatically Once a DAY",
                    "description": "In this video i'll show you one way of running your web scrapers automatically in the cloud, using cronjobs. we utilise a linux vm from Digital Ocean and download and run our code at a set interval. I cover creating a droplet, downloading code from git and isntalling requirements.\n\n\nCode & Commands: https://github.com/jhnwr/whiskey-cronjob\n\n\nDigital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \nCrontab Guru - https://crontab.guru/\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/VztRqRXeyn0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/VztRqRXeyn0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/VztRqRXeyn0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/VztRqRXeyn0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/VztRqRXeyn0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "cronjobs",
                        "run web scraper online",
                        "cronjob python",
                        "cron job linux",
                        "cron job basics",
                        "crontab example",
                        "crontab examples in linux",
                        "crontab how to",
                        "crontab in linux",
                        "crontab not running",
                        "crontab on ubuntu",
                        "cron jobs python",
                        "cron job tutorial for beginners",
                        "cron job to run python script",
                        "cron job tutorial for beginners python",
                        "crontab python script",
                        "python cron job",
                        "cronjob web scraper",
                        "python web scraping",
                        "python tutorial",
                        "code tutorial",
                        "scrape daily"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Run Your Web Scraper Automatically Once a DAY",
                        "description": "In this video i'll show you one way of running your web scrapers automatically in the cloud, using cronjobs. we utilise a linux vm from Digital Ocean and download and run our code at a set interval. I cover creating a droplet, downloading code from git and isntalling requirements.\n\n\nCode & Commands: https://github.com/jhnwr/whiskey-cronjob\n\n\nDigital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6 \nCrontab Guru - https://crontab.guru/\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "30199",
                    "likeCount": "886",
                    "favoriteCount": "0",
                    "commentCount": "67"
                },
                "contentDetails": {
                    "duration": "PT16M13S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "z2ntS7_CNpk": {
                "snippet": {
                    "publishedAt": "2020-11-15T19:19:49Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Sentiment Analysis With Python: Movie Quotes & TEXTBLOB",
                    "description": "In this video we use an API to scrape movie quotes and then start some initial sentiment analysis with textblob. This is part 1 of a fun project aimed at getting started with sentiment analysis in Python, next part we collect more data and use the notebooks in VS Code to create some graphs and more anaylsis. \n\n\ncode: https://github.com/jhnwr/imdbpy-textblob/\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\n\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\n\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/z2ntS7_CNpk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/z2ntS7_CNpk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/z2ntS7_CNpk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/z2ntS7_CNpk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/z2ntS7_CNpk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "sentiment analysis python",
                        "sentiment analysis basics",
                        "sentiment analysis code in python",
                        "sentiment analysis example",
                        "sentiment analysis for beginners",
                        "sentiment analysis in python",
                        "sentiment analysis introduction",
                        "sentiment analysis movie quotes",
                        "sentiment analysis of text using python",
                        "sentiment analysis python textblob",
                        "sentiment analysis using python",
                        "scraping movie quotes",
                        "analyse movie quotes",
                        "python web scraping",
                        "sentiment analysis"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Sentiment Analysis With Python: Movie Quotes & TEXTBLOB",
                        "description": "In this video we use an API to scrape movie quotes and then start some initial sentiment analysis with textblob. This is part 1 of a fun project aimed at getting started with sentiment analysis in Python, next part we collect more data and use the notebooks in VS Code to create some graphs and more anaylsis. \n\n\ncode: https://github.com/jhnwr/imdbpy-textblob/\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nDigital Ocean https://m.do.co/c/c7c90f161ff6\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\n\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\n\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "3113",
                    "likeCount": "127",
                    "favoriteCount": "0",
                    "commentCount": "23"
                },
                "contentDetails": {
                    "duration": "PT14M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "EJUdFB5iu7Y": {
                "snippet": {
                    "publishedAt": "2020-11-14T18:00:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python & VS Code on Windows - My Method QUICK + EASY",
                    "description": "In this video I will show you the simplest way to get started with Python on Windows 10. We are going to run through the basic install of the main things you need to get started coding on Win 10 with Python, starting from scratch. Once done you will be able to follow along with any of mine, or others code along tutorials on YT. \n\nCovering installing:\n\n*Python\n*Windows Terminal\n*PIP\n*Some useful Python Packages\n*VS Code\n*Python Extension\n\nBonus:\n*VS Code theme\n\n\nLINKS:\n\nPython: https://www.python.org/downloads/\n\nPIP: https://pip.pypa.io/en/stable/installing/ or https://bootstrap.pypa.io/get-pip.py\n\nVS Code: https://code.visualstudio.com/download\n\nThe theme I use: https://marketplace.visualstudio.com/items?itemName=zhuangtongfa.Material-theme\n\n(install via extensions button in VS Code)\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/EJUdFB5iu7Y/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/EJUdFB5iu7Y/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/EJUdFB5iu7Y/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/EJUdFB5iu7Y/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/EJUdFB5iu7Y/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python install",
                        "install python windows",
                        "python windows 10",
                        "install pip on windows",
                        "vs code",
                        "install vs code",
                        "vs code themes",
                        "get started with python",
                        "basic dev setup windows",
                        "beginner dev setup for windows",
                        "windows python setup",
                        "learn to code on windows",
                        "can you code on windows",
                        "python installation in windows 10",
                        "python installation",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python & VS Code on Windows - My Method QUICK + EASY",
                        "description": "In this video I will show you the simplest way to get started with Python on Windows 10. We are going to run through the basic install of the main things you need to get started coding on Win 10 with Python, starting from scratch. Once done you will be able to follow along with any of mine, or others code along tutorials on YT. \n\nCovering installing:\n\n*Python\n*Windows Terminal\n*PIP\n*Some useful Python Packages\n*VS Code\n*Python Extension\n\nBonus:\n*VS Code theme\n\n\nLINKS:\n\nPython: https://www.python.org/downloads/\n\nPIP: https://pip.pypa.io/en/stable/installing/ or https://bootstrap.pypa.io/get-pip.py\n\nVS Code: https://code.visualstudio.com/download\n\nThe theme I use: https://marketplace.visualstudio.com/items?itemName=zhuangtongfa.Material-theme\n\n(install via extensions button in VS Code)\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "1756",
                    "likeCount": "96",
                    "favoriteCount": "0",
                    "commentCount": "14"
                },
                "contentDetails": {
                    "duration": "PT13M2S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "GqICHBfeAWk": {
                "snippet": {
                    "publishedAt": "2020-11-11T18:30:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape Walmart product data with Python",
                    "description": "Another fun project, showing a way to scrape walmart prices and product data. we access the API endpoint and using postman replicate the request before transferring it to Python, including all header data. Keep the cookie means we dont get blocked so easily. This is a basic way of learning how to extract data from websites that aren't accessible using the traditional methods\n\n\nPostman: https://www.postman.com/downloads/\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/GqICHBfeAWk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/GqICHBfeAWk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/GqICHBfeAWk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/GqICHBfeAWk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/GqICHBfeAWk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scrape walmart",
                        "scrape walmart",
                        "scraping deals",
                        "walmart scraper",
                        "postman api",
                        "postman to python code",
                        "python web scraping tutorial",
                        "how to scrape with the hidden api",
                        "api enpoints",
                        "learn python",
                        "python coding tutorial",
                        "walmart inventory scraper",
                        "walmart price scraper",
                        "walmart product scraper"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape Walmart product data with Python",
                        "description": "Another fun project, showing a way to scrape walmart prices and product data. we access the API endpoint and using postman replicate the request before transferring it to Python, including all header data. Keep the cookie means we dont get blocked so easily. This is a basic way of learning how to extract data from websites that aren't accessible using the traditional methods\n\n\nPostman: https://www.postman.com/downloads/\n\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "20262",
                    "likeCount": "497",
                    "favoriteCount": "0",
                    "commentCount": "78"
                },
                "contentDetails": {
                    "duration": "PT20M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "6Li6Y1_DRJ8": {
                "snippet": {
                    "publishedAt": "2020-11-08T17:30:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Amazon Price Tracker using Python - Web Scrape from ASINs CSV and save results to Database",
                    "description": "Lets' build a quick and simple price tracker using python. We take a CSV of ASINs and scrape the data from the site and save it into a database for easy analysis later. This is a fun short project that hopefully demonstrates some new techniques that you might not have seen before.\n\ncode: https://github.com/jhnwr/amazon-price-tracker\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/6Li6Y1_DRJ8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/6Li6Y1_DRJ8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/6Li6Y1_DRJ8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/6Li6Y1_DRJ8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/6Li6Y1_DRJ8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "price tracker",
                        "amazon scraper",
                        "price scraper",
                        "amazon prices",
                        "amazon price scraper",
                        "amazon price scraper python",
                        "price tracker python",
                        "price tracker for amazon",
                        "price tracker amazon",
                        "amazon price tracker with python",
                        "python tutorial",
                        "learn python",
                        "web scraping",
                        "web scraping lesson",
                        "python database",
                        "amazon prices to sql database"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Amazon Price Tracker using Python - Web Scrape from ASINs CSV and save results to Database",
                        "description": "Lets' build a quick and simple price tracker using python. We take a CSV of ASINs and scrape the data from the site and save it into a database for easy analysis later. This is a fun short project that hopefully demonstrates some new techniques that you might not have seen before.\n\ncode: https://github.com/jhnwr/amazon-price-tracker\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    },
                    "defaultAudioLanguage": "en"
                },
                "statistics": {
                    "viewCount": "16561",
                    "likeCount": "414",
                    "favoriteCount": "0",
                    "commentCount": "67"
                },
                "contentDetails": {
                    "duration": "PT23M4S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8q2K41QC2nQ": {
                "snippet": {
                    "publishedAt": "2020-10-31T20:11:21Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape Javascript with SPLASH  - how to install and get started with Splash",
                    "description": "Get started with Splash! Splash is a lightweight browser with an API designed spcifically for web scraping and rendering javascript and dynamic websites. We can quickly and easily send requests to Splash instance and have it render the JS for us, and return the HTML to parse. I cover install Splash and Docker Desktop, the simplist and easiest way to manage it on windows. You guys should definitely try this out. let me know what you think down below.\n\n\nSplash - https://splash.readthedocs.io/en/stable/\nDocker Desktop - https://www.docker.com/products/docker-desktop\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\nUsing these links helps me keep my channel going\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8q2K41QC2nQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8q2K41QC2nQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8q2K41QC2nQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8q2K41QC2nQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8q2K41QC2nQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "splash python tutorial",
                        "web scrape javascript",
                        "python web scraping",
                        "scrape amazon",
                        "python tutorial",
                        "web scraping",
                        "scraping api",
                        "splash",
                        "scraping with splash",
                        "what is splash",
                        "render js",
                        "render javascript",
                        "learn python",
                        "python coding",
                        "programming tutorial",
                        "web scraping lesson",
                        "how to scrape dynamic sites",
                        "learn splash"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape Javascript with SPLASH  - how to install and get started with Splash",
                        "description": "Get started with Splash! Splash is a lightweight browser with an API designed spcifically for web scraping and rendering javascript and dynamic websites. We can quickly and easily send requests to Splash instance and have it render the JS for us, and return the HTML to parse. I cover install Splash and Docker Desktop, the simplist and easiest way to manage it on windows. You guys should definitely try this out. let me know what you think down below.\n\n\nSplash - https://splash.readthedocs.io/en/stable/\nDocker Desktop - https://www.docker.com/products/docker-desktop\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n\nUsing these links helps me keep my channel going\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "26554",
                    "likeCount": "717",
                    "favoriteCount": "0",
                    "commentCount": "84"
                },
                "contentDetails": {
                    "duration": "PT10M28S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "stIxEKR7o-c": {
                "snippet": {
                    "publishedAt": "2020-10-28T18:00:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape and Download ALL images from a webpage with Python",
                    "description": "Today we are going to create an image downloader / scraper using Python. Using web scraping we can extract all the image links from a page and then save them to our PC in bulk. This is a basic python programming tutorial for beginners to help show what can be achieved by learning Python! Saving all the images from a website is a real world project that you could well be asked to do at a job, or freelancing. It combines some basic scraping skills with learning the basics of creating directories and writing to files.\n\n\nhttps://github.com/jhnwr/image-downloader\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/stIxEKR7o-c/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/stIxEKR7o-c/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/stIxEKR7o-c/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/stIxEKR7o-c/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/stIxEKR7o-c/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "image scraper python 3",
                        "python image downloader",
                        "web scrape images",
                        "bulk image downloader",
                        "image downloader python",
                        "web image downloader",
                        "website image downloader",
                        "python download all images from url",
                        "python download image url requests",
                        "image scraper",
                        "web scraping image",
                        "scraping images python beautifulsoup",
                        "image crawler",
                        "web scraping",
                        "python scraping",
                        "python tutorial",
                        "python programming",
                        "beautifulsoup web scraping",
                        "python scraping tutorial",
                        "coding tutorial",
                        "beautifulsoup4"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape and Download ALL images from a webpage with Python",
                        "description": "Today we are going to create an image downloader / scraper using Python. Using web scraping we can extract all the image links from a page and then save them to our PC in bulk. This is a basic python programming tutorial for beginners to help show what can be achieved by learning Python! Saving all the images from a website is a real world project that you could well be asked to do at a job, or freelancing. It combines some basic scraping skills with learning the basics of creating directories and writing to files.\n\n\nhttps://github.com/jhnwr/image-downloader\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "84024",
                    "likeCount": "1705",
                    "favoriteCount": "0",
                    "commentCount": "160"
                },
                "contentDetails": {
                    "duration": "PT15M",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "7sFCOunKL_Y": {
                "snippet": {
                    "publishedAt": "2020-10-25T17:00:01Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Scrape Stock Prices from Yahoo Finance with Python",
                    "description": "Lets web scrape some financial data from yahoo - stock prices to be exact - using python. It's HTML data so we will use requests and beautifulsoup to get and parse the info. We will write a function that we can loop through to enable us to select a few stocks to track and output the data to a json file for easy reviewing.\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/7sFCOunKL_Y/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/7sFCOunKL_Y/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/7sFCOunKL_Y/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/7sFCOunKL_Y/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/7sFCOunKL_Y/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrape stock prices python",
                        "web scraping financial data",
                        "scrape stock data",
                        "scrape stock data python",
                        "scrape stock market data",
                        "how to scrape stock market data",
                        "web scraping yahoo finance",
                        "yahoo finance python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Scrape Stock Prices from Yahoo Finance with Python",
                        "description": "Lets web scrape some financial data from yahoo - stock prices to be exact - using python. It's HTML data so we will use requests and beautifulsoup to get and parse the info. We will write a function that we can loop through to enable us to select a few stocks to track and output the data to a json file for easy reviewing.\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    },
                    "defaultAudioLanguage": "en"
                },
                "statistics": {
                    "viewCount": "53151",
                    "likeCount": "1273",
                    "favoriteCount": "0",
                    "commentCount": "120"
                },
                "contentDetails": {
                    "duration": "PT20M6S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "onlQ7fL4ey8": {
                "snippet": {
                    "publishedAt": "2020-10-21T17:00:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Easiest SELENIUM Web Scraping for JavaScript Pages",
                    "description": "Modern web scraping is all JavaScript! Learn another method of extracting data from a JS website by using Selenium to load the page and grabbing the rendered source HTML. its really easy and can work very well in certain situations. It's all about knowing the tools available and using the right one for the job at hand\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/onlQ7fL4ey8/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/onlQ7fL4ey8/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/onlQ7fL4ey8/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/onlQ7fL4ey8/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/onlQ7fL4ey8/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "scraping js websites",
                        "scrape javascript",
                        "selenium web scraping",
                        "python helium",
                        "web scraping with helium",
                        "render javascript",
                        "scrape dynamic sites"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Easiest SELENIUM Web Scraping for JavaScript Pages",
                        "description": "Modern web scraping is all JavaScript! Learn another method of extracting data from a JS website by using Selenium to load the page and grabbing the rendered source HTML. its really easy and can work very well in certain situations. It's all about knowing the tools available and using the right one for the job at hand\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "28257",
                    "likeCount": "634",
                    "favoriteCount": "0",
                    "commentCount": "63"
                },
                "contentDetails": {
                    "duration": "PT5M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "m-koIYWCaIo": {
                "snippet": {
                    "publishedAt": "2020-10-18T18:30:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How Web Scrape Multiple Pages with ONE Function with Python",
                    "description": "Many websites use the same template for multiple pages of data, and this video shows you can create a single function to scrape that data easily. I've included pagination and another variable - in this case tags. \n\n\nThis project web scrapes questions data from stack overflow, and outputs to an excel file the title, data, main tag and up votes. \n\n------------------------------------\nCode: https://github.com/jhnwr/stackoverflow\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\n\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/m-koIYWCaIo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/m-koIYWCaIo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/m-koIYWCaIo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/m-koIYWCaIo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/m-koIYWCaIo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraper python",
                        "web scraper pagination",
                        "web scraping function",
                        "python web scraping",
                        "web scrape to excel",
                        "scraping stackoverflow",
                        "scrape stackoverflow questions",
                        "how to web scrape with python",
                        "how to web scrape using python",
                        "web scrape multiple pages python",
                        "web scrape multiple pages python beautifulsoup",
                        "web scraper project",
                        "web scraper python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How Web Scrape Multiple Pages with ONE Function with Python",
                        "description": "Many websites use the same template for multiple pages of data, and this video shows you can create a single function to scrape that data easily. I've included pagination and another variable - in this case tags. \n\n\nThis project web scrapes questions data from stack overflow, and outputs to an excel file the title, data, main tag and up votes. \n\n------------------------------------\nCode: https://github.com/jhnwr/stackoverflow\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\n\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "45295",
                    "likeCount": "875",
                    "favoriteCount": "0",
                    "commentCount": "70"
                },
                "contentDetails": {
                    "duration": "PT21M4S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "NlapIIe4mEA": {
                "snippet": {
                    "publishedAt": "2020-10-16T07:41:45Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping LIVE 3!  QnA - Chat - Live Code Examples",
                    "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/NlapIIe4mEA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/NlapIIe4mEA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/NlapIIe4mEA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/NlapIIe4mEA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/NlapIIe4mEA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "live web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping LIVE 3!  QnA - Chat - Live Code Examples",
                        "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "1722",
                    "likeCount": "56",
                    "favoriteCount": "0",
                    "commentCount": "12"
                },
                "contentDetails": {
                    "duration": "PT1H34M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "xBbK2kvHXwE": {
                "snippet": {
                    "publishedAt": "2020-10-11T18:00:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I save my Scraped Data to a Database with Python! Beginners sqlite3 tutorial",
                    "description": "We've focused on how to scrape content but not on how to save it persistently - I'll show you how I save my scraped data to a database in its most basic form, from setting up and connecting to an sqlite3 database, to creating a table and inserting data. \n\nThis Python tutorial is aimed at beginners who haven't tried using a database yet in their own projects, and has some examples of how it can be put into existing code with just a few extra lines.\n------------------------------------\nCode: https://github.com/jhnwr/scrapetodb\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\n\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/xBbK2kvHXwE/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/xBbK2kvHXwE/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/xBbK2kvHXwE/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/xBbK2kvHXwE/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/xBbK2kvHXwE/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python database basics",
                        "python database table",
                        "python database for beginners",
                        "python database connectivity mysql",
                        "python database sqlite",
                        "sqlite3 python",
                        "sqlite3 tutorial",
                        "sqlite3 basics",
                        "sqlite3 connect to database python",
                        "sqlite3 datetime python",
                        "sqlite3 for beginners",
                        "using databases with python",
                        "database with python 3",
                        "scraping to db",
                        "web scrape to a database",
                        "save scraped data to database",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I save my Scraped Data to a Database with Python! Beginners sqlite3 tutorial",
                        "description": "We've focused on how to scrape content but not on how to save it persistently - I'll show you how I save my scraped data to a database in its most basic form, from setting up and connecting to an sqlite3 database, to creating a table and inserting data. \n\nThis Python tutorial is aimed at beginners who haven't tried using a database yet in their own projects, and has some examples of how it can be put into existing code with just a few extra lines.\n------------------------------------\nCode: https://github.com/jhnwr/scrapetodb\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\n\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\n\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "54425",
                    "likeCount": "1373",
                    "favoriteCount": "0",
                    "commentCount": "76"
                },
                "contentDetails": {
                    "duration": "PT17M40S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "WcPNlnsNZyY": {
                "snippet": {
                    "publishedAt": "2020-10-05T21:09:31Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape Amazon NEW METHOD with Python 2020",
                    "description": "Whilst working ona new personal project i noticed that scraping amazon with requests and bs4 no longer worked, so I am sharing a new method of how to get prices and titles from any amazon product page.\n\nCode: https://github.com/jhnwr/scrapeamazon\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/WcPNlnsNZyY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/WcPNlnsNZyY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/WcPNlnsNZyY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/WcPNlnsNZyY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/WcPNlnsNZyY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scrape amazon",
                        "web scraping with python",
                        "scrape amazon price python",
                        "scrape amazon using python",
                        "scrape data from amazon",
                        "web scrape amazon",
                        "how to scrape amazon using python",
                        "scrape amazon data",
                        "scrape amazon products"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape Amazon NEW METHOD with Python 2020",
                        "description": "Whilst working ona new personal project i noticed that scraping amazon with requests and bs4 no longer worked, so I am sharing a new method of how to get prices and titles from any amazon product page.\n\nCode: https://github.com/jhnwr/scrapeamazon\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n\n-------------------------------------\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "43651",
                    "likeCount": "828",
                    "favoriteCount": "0",
                    "commentCount": "102"
                },
                "contentDetails": {
                    "duration": "PT8M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "hCARQVJy_mk": {
                "snippet": {
                    "publishedAt": "2020-10-04T06:30:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrapy Basics - How to Get Started with Python's Web Scraping Framework",
                    "description": "Scrapy is a Python framework for web scraping and in this video I will show you the basics of how to start:\n\n* Create a scrapy project\n* Use the scrapy shell to find elements\n* How css selectors work with scrapy\n* Create a simple spider to crawl a website for product information\n\nCode: https://github.com/jhnwr/scrapy-spider\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/hCARQVJy_mk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/hCARQVJy_mk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/hCARQVJy_mk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/hCARQVJy_mk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/hCARQVJy_mk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "scarpy python",
                        "scrapy basics",
                        "scrapy crawler",
                        "scrapy example",
                        "scrapy crawlspider",
                        "scrapy how to",
                        "scrapy guide",
                        "scrapy beginners",
                        "scrapy python tutorial",
                        "scrapy python 3",
                        "scrapy shell",
                        "scrapy web scraping",
                        "scrapy web scraping tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrapy Basics - How to Get Started with Python's Web Scraping Framework",
                        "description": "Scrapy is a Python framework for web scraping and in this video I will show you the basics of how to start:\n\n* Create a scrapy project\n* Use the scrapy shell to find elements\n* How css selectors work with scrapy\n* Create a simple spider to crawl a website for product information\n\nCode: https://github.com/jhnwr/scrapy-spider\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "34246",
                    "likeCount": "860",
                    "favoriteCount": "0",
                    "commentCount": "88"
                },
                "contentDetails": {
                    "duration": "PT20M30S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "vJwcW2gCCE4": {
                "snippet": {
                    "publishedAt": "2020-09-27T17:45:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Rotate Proxies with Python",
                    "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIn this video I go through how to implement rotating proxies using requests with Python. We look at scraping some free proxies and writing a script to see if they work. Although free proxies aren't any use for actual web scraping projects the principles are the same.\n\nCode here: https://github.com/jhnwr/rotatingproxies\nProxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I use https://nodemaven.com/?a_aid=JohnWatsonRooney\nScraper API I use https://www.scrapingbee.com/?fpr=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items.",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/vJwcW2gCCE4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/vJwcW2gCCE4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/vJwcW2gCCE4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/vJwcW2gCCE4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/vJwcW2gCCE4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "proxy python requests",
                        "proxy python script",
                        "rotating proxy python",
                        "proxy checker python",
                        "python http proxy server",
                        "python proxy scraper",
                        "proxy with python",
                        "python web scraping proxy",
                        "python proxy server tutorial",
                        "proxy server using python",
                        "random proxy python",
                        "how to rotate proxies with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Rotate Proxies with Python",
                        "description": "Join the Discord to discuss all things Python and Web with our growing community! https://discord.gg/C4J2uckpbR\n\nIn this video I go through how to implement rotating proxies using requests with Python. We look at scraping some free proxies and writing a script to see if they work. Although free proxies aren't any use for actual web scraping projects the principles are the same.\n\nCode here: https://github.com/jhnwr/rotatingproxies\nProxies: https://nodemaven.com/?a_aid=JohnWatsonRooney\n\nIf you are new, welcome! I am John, a self taught Python (and Go, kinda..) developer working in the web and data space. I specialize in data extraction and JSON web API's both server and client. If you like programming and web content as much as I do, you can subscribe for weekly content.\n\n:: Links ::\nMy Patrons Really keep the channel alive, and get extra content https://www.patreon.com/johnwatsonrooney (NEW free tier)\nI Host almost all my stuff on Digital Ocean https://m.do.co/c/c7c90f161ff6\nI rundown of the gear I use to create videos https://www.amazon.co.uk/shop/johnwatsonrooney\nProxies I use https://nodemaven.com/?a_aid=JohnWatsonRooney\nScraper API I use https://www.scrapingbee.com/?fpr=jhnwr\n\n:: Disclaimer ::\nSome/all of the links above are affiliate links. By clicking on these links I receive a small commission should you chose to purchase any services or items."
                    }
                },
                "statistics": {
                    "viewCount": "122053",
                    "likeCount": "3146",
                    "favoriteCount": "0",
                    "commentCount": "199"
                },
                "contentDetails": {
                    "duration": "PT13M5S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ODNMNwgtehk": {
                "snippet": {
                    "publishedAt": "2020-09-23T18:00:04Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape HTML tables easily with Pandas and Python",
                    "description": "In this video I will show you how you can scrape html tables direct from the web using pandas. this works surprisingly well! i'll show a few examples of where it could be useful for quick and simple scraping.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ODNMNwgtehk/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ODNMNwgtehk/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ODNMNwgtehk/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ODNMNwgtehk/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ODNMNwgtehk/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scrape with pandas",
                        "python web scraping",
                        "extract html table data",
                        "pandas read html",
                        "simple web scraping",
                        "simple html table scraping",
                        "scrape wikipedia tables"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape HTML tables easily with Pandas and Python",
                        "description": "In this video I will show you how you can scrape html tables direct from the web using pandas. this works surprisingly well! i'll show a few examples of where it could be useful for quick and simple scraping.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "35077",
                    "likeCount": "831",
                    "favoriteCount": "0",
                    "commentCount": "76"
                },
                "contentDetails": {
                    "duration": "PT6M45S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "PPcgtx0sI2E": {
                "snippet": {
                    "publishedAt": "2020-09-20T18:00:04Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Indeed Jobs Web Scraping Save to CSV",
                    "description": "Let's scrape some job postings from indeed.com using Python. I will show you how to work with pagination, extract job titles, salary, company and summaries from the site and save as a csv file for excel.\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/PPcgtx0sI2E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/PPcgtx0sI2E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/PPcgtx0sI2E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/PPcgtx0sI2E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/PPcgtx0sI2E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scrape indeed",
                        "web scrape jobs",
                        "scrape job posts",
                        "scrape job listings",
                        "python web scraping",
                        "web scraping with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Indeed Jobs Web Scraping Save to CSV",
                        "description": "Let's scrape some job postings from indeed.com using Python. I will show you how to work with pagination, extract job titles, salary, company and summaries from the site and save as a csv file for excel.\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "92429",
                    "likeCount": "2492",
                    "favoriteCount": "0",
                    "commentCount": "238"
                },
                "contentDetails": {
                    "duration": "PT20M55S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "aA6-ezS5dyY": {
                "snippet": {
                    "publishedAt": "2020-09-16T18:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "PARALLEL and CONCURRENCY in Python for FAST Web Scraping",
                    "description": "In this video I demo how using concurrent futures could help you speed up your web scraping scripts. I will show you how long it takes to scrape 1000 urls with and without concurrent futures and compare the times taken, with just a few lines of code.\n\ncode: https://github.com/jhnwr/speedupscraping\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/aA6-ezS5dyY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/aA6-ezS5dyY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/aA6-ezS5dyY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/aA6-ezS5dyY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/aA6-ezS5dyY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "concurrent futures",
                        "web scrape faster",
                        "faster web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "PARALLEL and CONCURRENCY in Python for FAST Web Scraping",
                        "description": "In this video I demo how using concurrent futures could help you speed up your web scraping scripts. I will show you how long it takes to scrape 1000 urls with and without concurrent futures and compare the times taken, with just a few lines of code.\n\ncode: https://github.com/jhnwr/speedupscraping\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "29785",
                    "likeCount": "1029",
                    "favoriteCount": "0",
                    "commentCount": "94"
                },
                "contentDetails": {
                    "duration": "PT6M20S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "PhJFg1THF9E": {
                "snippet": {
                    "publishedAt": "2020-09-13T18:00:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Build your own Yellow Pages web scraper with Python",
                    "description": "In this video I will show you how to build your own web scraper for Yellow Pages or Yell. We can easily extract a lot of useful leads and business data by using a simple web scraper. We use requests and BeautifulSoup to download and parse the data and export it to CSV for Excel\n\nCode is on github - https://github.com/jhnwr/yellowpages-scraper\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/PhJFg1THF9E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/PhJFg1THF9E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/PhJFg1THF9E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python web scraper",
                        "yellow pages web scraper",
                        "yellow pages extractor",
                        "yellow pages download excel",
                        "yellow pages data scraping",
                        "yellow pages data",
                        "yellow pages data extractor"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Build your own Yellow Pages web scraper with Python",
                        "description": "In this video I will show you how to build your own web scraper for Yellow Pages or Yell. We can easily extract a lot of useful leads and business data by using a simple web scraper. We use requests and BeautifulSoup to download and parse the data and export it to CSV for Excel\n\nCode is on github - https://github.com/jhnwr/yellowpages-scraper\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "10232",
                    "likeCount": "288",
                    "favoriteCount": "0",
                    "commentCount": "47"
                },
                "contentDetails": {
                    "duration": "PT25M10S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8eddCc1LuYA": {
                "snippet": {
                    "publishedAt": "2020-09-11T07:36:05Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping Q&A 2! + Live Coding",
                    "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8eddCc1LuYA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8eddCc1LuYA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8eddCc1LuYA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8eddCc1LuYA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8eddCc1LuYA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "live web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping Q&A 2! + Live Coding",
                        "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n\n\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "802",
                    "likeCount": "30",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT1H28M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ct0xvw_Z0tU": {
                "snippet": {
                    "publishedAt": "2020-09-09T18:30:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Google Sheets Database with Python Web Scraping",
                    "description": "We can use Google Sheets as a database for our Python Web Scrapers. In this video tutorial I will show you how to add new rows under each other to a Google Sheet from your Python script.\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ct0xvw_Z0tU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ct0xvw_Z0tU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ct0xvw_Z0tU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ct0xvw_Z0tU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ct0xvw_Z0tU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "google sheets database",
                        "python google sheets",
                        "google sheets python",
                        "google sheets script",
                        "google sheets web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Google Sheets Database with Python Web Scraping",
                        "description": "We can use Google Sheets as a database for our Python Web Scrapers. In this video tutorial I will show you how to add new rows under each other to a Google Sheet from your Python script.\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "33477",
                    "likeCount": "983",
                    "favoriteCount": "0",
                    "commentCount": "63"
                },
                "contentDetails": {
                    "duration": "PT12M57S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "CMM7tK3GR1Q": {
                "snippet": {
                    "publishedAt": "2020-09-04T07:42:20Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping Q&A + Live Coding",
                    "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/CMM7tK3GR1Q/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/CMM7tK3GR1Q/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/CMM7tK3GR1Q/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/CMM7tK3GR1Q/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/CMM7tK3GR1Q/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping Q&A + Live Coding",
                        "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "910",
                    "likeCount": "35",
                    "favoriteCount": "0",
                    "commentCount": "9"
                },
                "contentDetails": {
                    "duration": "PT1H33M3S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "THRd7b5PbuU": {
                "snippet": {
                    "publishedAt": "2020-09-03T19:44:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping Q&A + Live Coding",
                    "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/THRd7b5PbuU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/THRd7b5PbuU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/THRd7b5PbuU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/THRd7b5PbuU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/THRd7b5PbuU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping Q&A + Live Coding",
                        "description": "Come and talk Python and web scraping with me, discussing technologies, best practices, how to and live coding examples\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "610",
                    "likeCount": "25",
                    "favoriteCount": "0",
                    "commentCount": "16"
                },
                "contentDetails": {
                    "duration": "PT1H31M31S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uKb9fA4gyWQ": {
                "snippet": {
                    "publishedAt": "2020-08-30T18:00:12Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping NEWS Articles with Python",
                    "description": "How I go about web scraping new articles, in this case from Google news. The page is of course dynamically loaded but we can use requests_html to render the page for us and allow us access to the elements and their data. I run through a short example of how this works and point out some pitfalls along the way.\n\nCode: https://github.com/jhnwr/webscrapenewsarticles\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uKb9fA4gyWQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uKb9fA4gyWQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uKb9fA4gyWQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uKb9fA4gyWQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uKb9fA4gyWQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping news articles with python",
                        "learn python",
                        "python web scraping",
                        "scrapign dynamic websites",
                        "scraping javascript pages",
                        "google news python",
                        "learn webscraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping NEWS Articles with Python",
                        "description": "How I go about web scraping new articles, in this case from Google news. The page is of course dynamically loaded but we can use requests_html to render the page for us and allow us access to the elements and their data. I run through a short example of how this works and point out some pitfalls along the way.\n\nCode: https://github.com/jhnwr/webscrapenewsarticles\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "70934",
                    "likeCount": "953",
                    "favoriteCount": "0",
                    "commentCount": "59"
                },
                "contentDetails": {
                    "duration": "PT12M22S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "SEQjNEawceo": {
                "snippet": {
                    "publishedAt": "2020-08-20T18:40:34Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to scrape SPORTS STATS websites with Python",
                    "description": "In this video we scrape a sports stats website by accessing the api endpoint. utilising Postman we can replicate the request that the browser makes and download all of the data into Python and VSCODE. Using Pandas we can create a dataframe with all the player stats ready to be analysed, or exported to a csv file.\n\nhttps://www.postman.com/\n\nThank you to Daniel for sending this over, and if you've never watched any AFL before search for AFL biggest hits on YouTube..!!\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/SEQjNEawceo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/SEQjNEawceo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/SEQjNEawceo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/SEQjNEawceo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/SEQjNEawceo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "How to scrape SPORTS STATS websites with Python",
                        "web scraping with python",
                        "python web scraping",
                        "learn python",
                        "python json",
                        "python api endpoints",
                        "python apis",
                        "scraping stats",
                        "web scrape sports data"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to scrape SPORTS STATS websites with Python",
                        "description": "In this video we scrape a sports stats website by accessing the api endpoint. utilising Postman we can replicate the request that the browser makes and download all of the data into Python and VSCODE. Using Pandas we can create a dataframe with all the player stats ready to be analysed, or exported to a csv file.\n\nhttps://www.postman.com/\n\nThank you to Daniel for sending this over, and if you've never watched any AFL before search for AFL biggest hits on YouTube..!!\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "60772",
                    "likeCount": "1524",
                    "favoriteCount": "0",
                    "commentCount": "96"
                },
                "contentDetails": {
                    "duration": "PT12M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "c6BO3j2rHhU": {
                "snippet": {
                    "publishedAt": "2020-08-17T19:03:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I always get the right table when web scraping with Python",
                    "description": "In this video I show you how to scrape the information from HTML with Python, when the tags don't have an ID or Class to call on. Many sites use table identifiers but some do not - but we can use find_all and indexing to make sure we are able to always get the data we are after\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/c6BO3j2rHhU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/c6BO3j2rHhU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/c6BO3j2rHhU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/c6BO3j2rHhU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/c6BO3j2rHhU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "How I always get the right table when web scraping with Python",
                        "web scraping with Python",
                        "html tables with python",
                        "web scraping html tables",
                        "scrape tables with no id or class",
                        "beginner web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I always get the right table when web scraping with Python",
                        "description": "In this video I show you how to scrape the information from HTML with Python, when the tags don't have an ID or Class to call on. Many sites use table identifiers but some do not - but we can use find_all and indexing to make sure we are able to always get the data we are after\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "5775",
                    "likeCount": "126",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT8M26S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "JcfQthzH4lQ": {
                "snippet": {
                    "publishedAt": "2020-08-16T17:30:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "IMPROVING this BeautifulSoup Blog Scraper",
                    "description": "Scrape WordPress blogs with Python and BeautifulSoup. This video works through a way to deal with multiple pages on a WordPress blog and we scrape the title and link of over 1000 articles and save to an xlsx Excel file.\n\n\nCode: https://github.com/jhnwr/wordpress-scraper\n\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/JcfQthzH4lQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/JcfQthzH4lQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/JcfQthzH4lQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/JcfQthzH4lQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/JcfQthzH4lQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python web scraping",
                        "beautifulsoup",
                        "wordpress scraper",
                        "scrape wordpress blogs",
                        "blog web scraper"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "IMPROVING this BeautifulSoup Blog Scraper",
                        "description": "Scrape WordPress blogs with Python and BeautifulSoup. This video works through a way to deal with multiple pages on a WordPress blog and we scrape the title and link of over 1000 articles and save to an xlsx Excel file.\n\n\nCode: https://github.com/jhnwr/wordpress-scraper\n\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "2337",
                    "likeCount": "51",
                    "favoriteCount": "0",
                    "commentCount": "7"
                },
                "contentDetails": {
                    "duration": "PT11M40S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "U90vK84bq4s": {
                "snippet": {
                    "publishedAt": "2020-08-09T19:50:33Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Scrape blog posts with Python",
                    "description": "In this video we will create a simple WordPress web scraper using Python. We get the title, date and author of the posts plus a link to the full article and save all to an Excel file. This is part 1, in part 2 we will expand on it to get all the posts, as opposed to just those on the front page.\n\nThis is a beginner level scraper and covers basic usage of Requests and BeautifulSoup4 - a staple of the the Python scraping toolkit.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/U90vK84bq4s/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/U90vK84bq4s/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/U90vK84bq4s/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/U90vK84bq4s/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/U90vK84bq4s/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "WordPress scraper",
                        "blog scraper",
                        "python web scraping",
                        "beautifulsoup",
                        "scrape blog posts"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Scrape blog posts with Python",
                        "description": "In this video we will create a simple WordPress web scraper using Python. We get the title, date and author of the posts plus a link to the full article and save all to an Excel file. This is part 1, in part 2 we will expand on it to get all the posts, as opposed to just those on the front page.\n\nThis is a beginner level scraper and covers basic usage of Requests and BeautifulSoup4 - a staple of the the Python scraping toolkit.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "7217",
                    "likeCount": "134",
                    "favoriteCount": "0",
                    "commentCount": "10"
                },
                "contentDetails": {
                    "duration": "PT15M18S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "B14mtXA7Tyw": {
                "snippet": {
                    "publishedAt": "2020-08-02T18:00:02Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Rendering Dynamic Pages 2! - Web Scraping ALL products with Python",
                    "description": "Part 2! \n\nPart 1 is here: https://www.youtube.com/watch?v=MeBU-4Xs2RU \n\nCode: https://github.com/jhnwr/beerwulf\n\nIn this video we clean up the script from part 1 by adding functions, and learn a way to deal with pagination. I run the completed script at the end and scrape all 796 products with info from the site.\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/B14mtXA7Tyw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/B14mtXA7Tyw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/B14mtXA7Tyw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/B14mtXA7Tyw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/B14mtXA7Tyw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python web scraping",
                        "learn python",
                        "render javascript",
                        "scrape js",
                        "scraping dynamic content"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Rendering Dynamic Pages 2! - Web Scraping ALL products with Python",
                        "description": "Part 2! \n\nPart 1 is here: https://www.youtube.com/watch?v=MeBU-4Xs2RU \n\nCode: https://github.com/jhnwr/beerwulf\n\nIn this video we clean up the script from part 1 by adding functions, and learn a way to deal with pagination. I run the completed script at the end and scrape all 796 products with info from the site.\n\n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "9994",
                    "likeCount": "278",
                    "favoriteCount": "0",
                    "commentCount": "35"
                },
                "contentDetails": {
                    "duration": "PT15M35S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "MeBU-4Xs2RU": {
                "snippet": {
                    "publishedAt": "2020-07-27T21:43:29Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Render Dynamic Pages - Web Scraping Product Links with Python",
                    "description": "Thanks to Stuart for sending this site in! I enjoyed this scraping challenge.\n\nThis video will show a simple method that can help with dynamically loaded content. I use the requestes-html library to render the page in the background quickly and efficiently, and scrape all the product links from the html DIV using the XPATH selector. I loop through each link to get all the product information.\n\nComing in part 2 - pagination and functions to tidy up the code.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/MeBU-4Xs2RU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/MeBU-4Xs2RU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/MeBU-4Xs2RU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/MeBU-4Xs2RU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/MeBU-4Xs2RU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "python web scraping",
                        "web scraping",
                        "scraping dynamic content",
                        "render js",
                        "scrape javascript"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Render Dynamic Pages - Web Scraping Product Links with Python",
                        "description": "Thanks to Stuart for sending this site in! I enjoyed this scraping challenge.\n\nThis video will show a simple method that can help with dynamically loaded content. I use the requestes-html library to render the page in the background quickly and efficiently, and scrape all the product links from the html DIV using the XPATH selector. I loop through each link to get all the product information.\n\nComing in part 2 - pagination and functions to tidy up the code.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "68011",
                    "likeCount": "1344",
                    "favoriteCount": "0",
                    "commentCount": "166"
                },
                "contentDetails": {
                    "duration": "PT13M41S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8980WHjsC6E": {
                "snippet": {
                    "publishedAt": "2020-07-12T18:30:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "A Better Web Scraper - 3 Steps Demo Python Web Scraping",
                    "description": "In this video we run thorugh a demo of the 3 steps to scraping sucess from my previous video. I break down each part and show you how to use functions to build a better web scraper with Python. We scrape products from a woocommerce site and work through some pagination to get all the products and prices.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8980WHjsC6E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8980WHjsC6E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8980WHjsC6E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8980WHjsC6E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8980WHjsC6E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "3 steps for scraping",
                        "learn to web scrape",
                        "learn python",
                        "build a better web scraper"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "A Better Web Scraper - 3 Steps Demo Python Web Scraping",
                        "description": "In this video we run thorugh a demo of the 3 steps to scraping sucess from my previous video. I break down each part and show you how to use functions to build a better web scraper with Python. We scrape products from a woocommerce site and work through some pagination to get all the products and prices.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "7112",
                    "likeCount": "179",
                    "favoriteCount": "0",
                    "commentCount": "32"
                },
                "contentDetails": {
                    "duration": "PT13M29S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "yjH0YpeQuy0": {
                "snippet": {
                    "publishedAt": "2020-07-05T18:00:08Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "The 3 Principles to Web Scraping Success",
                    "description": "Web Scraping with Python can be simple and easy, these are the 3 main steps for web scraping success. In this video I talk about what I consider the 3 main steps for web scraping, how I approach web scraping jobs following this basic framework. Once you understand each step you can take the knowledge you have an apply it to your own projects.\n\nPython Web Scraping Playlist: https://www.youtube.com/playlist?list=PLRzwgpycm-FgQ9lP_JTfrCa9O573XiJph\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (Linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/yjH0YpeQuy0/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/yjH0YpeQuy0/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/yjH0YpeQuy0/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/yjH0YpeQuy0/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/yjH0YpeQuy0/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping",
                        "learn python",
                        "python projects",
                        "beginner scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "The 3 Principles to Web Scraping Success",
                        "description": "Web Scraping with Python can be simple and easy, these are the 3 main steps for web scraping success. In this video I talk about what I consider the 3 main steps for web scraping, how I approach web scraping jobs following this basic framework. Once you understand each step you can take the knowledge you have an apply it to your own projects.\n\nPython Web Scraping Playlist: https://www.youtube.com/playlist?list=PLRzwgpycm-FgQ9lP_JTfrCa9O573XiJph\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (Linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    },
                    "defaultAudioLanguage": "en-GB"
                },
                "statistics": {
                    "viewCount": "4153",
                    "likeCount": "185",
                    "favoriteCount": "0",
                    "commentCount": "18"
                },
                "contentDetails": {
                    "duration": "PT7M59S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "90t9WkQbQ2E": {
                "snippet": {
                    "publishedAt": "2020-06-28T16:29:42Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "User Agent Switching - Python Web Scraping",
                    "description": "Lets have a look at User Agents and web scraping with Python, to see how we can bypass some basic scraping protection. This video will show you what a user agent string looks like, how to find ones and how to send it along with your request, enabling you to convince the web server you are coming from a user controlled browser.\n\nUser-Agent list: https://developers.whatismybrowser.com/useragents/explore/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/90t9WkQbQ2E/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/90t9WkQbQ2E/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/90t9WkQbQ2E/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/90t9WkQbQ2E/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/90t9WkQbQ2E/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "user agents",
                        "python requests",
                        "user agent spoofing",
                        "user agent switcher",
                        "python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "User Agent Switching - Python Web Scraping",
                        "description": "Lets have a look at User Agents and web scraping with Python, to see how we can bypass some basic scraping protection. This video will show you what a user agent string looks like, how to find ones and how to send it along with your request, enabling you to convince the web server you are coming from a user controlled browser.\n\nUser-Agent list: https://developers.whatismybrowser.com/useragents/explore/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "45275",
                    "likeCount": "1105",
                    "favoriteCount": "0",
                    "commentCount": "84"
                },
                "contentDetails": {
                    "duration": "PT6M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "jdhjdiccASA": {
                "snippet": {
                    "publishedAt": "2020-06-11T19:24:14Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Why Would Anyone Use This?! All In One Web Scraper",
                    "description": "Lets have a look at a super basic web scraper using a different Python Library - Gazpacho. It claims to be simple and lightweight so lets have a little look at see what's what.\n\nGazpacho - https://pypi.org/project/gazpacho/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/jdhjdiccASA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/jdhjdiccASA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/jdhjdiccASA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "web scraping",
                        "webscraping",
                        "scrape data",
                        "get data from the web",
                        "gazpacho web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Why Would Anyone Use This?! All In One Web Scraper",
                        "description": "Lets have a look at a super basic web scraper using a different Python Library - Gazpacho. It claims to be simple and lightweight so lets have a little look at see what's what.\n\nGazpacho - https://pypi.org/project/gazpacho/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "2288",
                    "likeCount": "79",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT7M19S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "jPjxWC7zV2s": {
                "snippet": {
                    "publishedAt": "2020-06-09T21:31:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web scraping Shopify - easily download all products",
                    "description": "In this video we run through the simplest way to get Shopify store data, using the products.json URL. It's easy and fast and requires only basic Python web scraping knowledge. \n\nMore on scripts to CSV: https://www.youtube.com/watch?v=PeTagmeYKjw&t=33s\nNot Shopify?:  https://www.youtube.com/watch?v=nCuPv3tf2Hg&t=374s\nHTML Tables: https://www.youtube.com/watch?v=15f4JhJ8SiQ\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/jPjxWC7zV2s/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/jPjxWC7zV2s/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/jPjxWC7zV2s/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/jPjxWC7zV2s/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/jPjxWC7zV2s/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "web scraping",
                        "python web scraping",
                        "python shopify",
                        "shopify products python",
                        "python shopify json",
                        "products json shopify"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web scraping Shopify - easily download all products",
                        "description": "In this video we run through the simplest way to get Shopify store data, using the products.json URL. It's easy and fast and requires only basic Python web scraping knowledge. \n\nMore on scripts to CSV: https://www.youtube.com/watch?v=PeTagmeYKjw&t=33s\nNot Shopify?:  https://www.youtube.com/watch?v=nCuPv3tf2Hg&t=374s\nHTML Tables: https://www.youtube.com/watch?v=15f4JhJ8SiQ\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "23041",
                    "likeCount": "425",
                    "favoriteCount": "0",
                    "commentCount": "104"
                },
                "contentDetails": {
                    "duration": "PT14M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "QNLBBGWEQ3Q": {
                "snippet": {
                    "publishedAt": "2020-05-28T20:55:10Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web Scraping: JSON in SCRIPT tags",
                    "description": "This video covers a simple and easy way to web scrape with python by getting the data out in JSON format from the HTML script tags. This inline JSON is common place on lots of websites and can be used to our advantage in just a few lines of code!\n\nJSON Formatter: https://jsonformatter.org/\n\nPython Web Scraping Guide: https://youtu.be/J91bHusPatc\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/QNLBBGWEQ3Q/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/QNLBBGWEQ3Q/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/QNLBBGWEQ3Q/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/QNLBBGWEQ3Q/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/QNLBBGWEQ3Q/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python web scraping",
                        "web scraping with python",
                        "json in script tags",
                        "web scraping",
                        "learn python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web Scraping: JSON in SCRIPT tags",
                        "description": "This video covers a simple and easy way to web scrape with python by getting the data out in JSON format from the HTML script tags. This inline JSON is common place on lots of websites and can be used to our advantage in just a few lines of code!\n\nJSON Formatter: https://jsonformatter.org/\n\nPython Web Scraping Guide: https://youtu.be/J91bHusPatc\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "41303",
                    "likeCount": "767",
                    "favoriteCount": "0",
                    "commentCount": "87"
                },
                "contentDetails": {
                    "duration": "PT10M14S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "nCuPv3tf2Hg": {
                "snippet": {
                    "publishedAt": "2020-05-21T20:55:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with Python: Ecommerce Product Pages. In Depth including troubleshooting",
                    "description": "Follow along with me as I scrape data from an online store. I loop loop through pages to get product links, then each of those links to get information from each product page, scraping data only available there.\n\nUser Agents: \nhttps://developers.whatismybrowser.com/useragents/explore/software_type_specific/web-browser/\n\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/nCuPv3tf2Hg/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/nCuPv3tf2Hg/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/nCuPv3tf2Hg/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/nCuPv3tf2Hg/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/nCuPv3tf2Hg/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "web scraping",
                        "web scraping with python",
                        "web scraping with python multiple pages",
                        "python requests",
                        "python beautifulsoup",
                        "web scraping products",
                        "web scrape online shops",
                        "web scraping with python and beautifulsoup",
                        "web scraping python beautifulsoup",
                        "beautifulsoup"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with Python: Ecommerce Product Pages. In Depth including troubleshooting",
                        "description": "Follow along with me as I scrape data from an online store. I loop loop through pages to get product links, then each of those links to get information from each product page, scraping data only available there.\n\nUser Agents: \nhttps://developers.whatismybrowser.com/useragents/explore/software_type_specific/web-browser/\n\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)"
                    }
                },
                "statistics": {
                    "viewCount": "172400",
                    "likeCount": "3359",
                    "favoriteCount": "0",
                    "commentCount": "276"
                },
                "contentDetails": {
                    "duration": "PT21M53S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "sIOMDu6MXJQ": {
                "snippet": {
                    "publishedAt": "2020-05-19T18:32:28Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Webscraping With Python: Pagination and HTML",
                    "description": "For this video I run through line by line code of how I approached a webscraping task using python. I cover some basics of HTML scraping and pagination using a simple loop. Webscraping with Python is extremely effective and simple and can be used to create your own datasets very easily.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/sIOMDu6MXJQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/sIOMDu6MXJQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/sIOMDu6MXJQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/sIOMDu6MXJQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/sIOMDu6MXJQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "web scraping with python",
                        "python webscraping",
                        "learn python",
                        "python projects",
                        "webscraping pages",
                        "html webscraping",
                        "webscraping pagination",
                        "webscraping for beginners",
                        "basic python webscraper"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Webscraping With Python: Pagination and HTML",
                        "description": "For this video I run through line by line code of how I approached a webscraping task using python. I cover some basics of HTML scraping and pagination using a simple loop. Webscraping with Python is extremely effective and simple and can be used to create your own datasets very easily.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "26959",
                    "likeCount": "492",
                    "favoriteCount": "0",
                    "commentCount": "57"
                },
                "contentDetails": {
                    "duration": "PT20M21S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ukVjagiXJzw": {
                "snippet": {
                    "publishedAt": "2020-05-11T21:28:54Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Turn your web scraper into a web app with Python and Flask",
                    "description": "How to make a simple flask app that takes data from an API feed and displays it as a webpage. The idea of this video was to show how we can take simple and short Python scripts and make them into web apps very simply with very little learning required. This should be used as a building block to get you off the ground and creating your own apps.\n\ncode here: https://github.com/jhnwr/yt-beer-app\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ukVjagiXJzw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ukVjagiXJzw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ukVjagiXJzw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ukVjagiXJzw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ukVjagiXJzw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "basic flask app",
                        "simple flask app",
                        "python flask example",
                        "flask tutorial",
                        "what is flask python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Turn your web scraper into a web app with Python and Flask",
                        "description": "How to make a simple flask app that takes data from an API feed and displays it as a webpage. The idea of this video was to show how we can take simple and short Python scripts and make them into web apps very simply with very little learning required. This should be used as a building block to get you off the ground and creating your own apps.\n\ncode here: https://github.com/jhnwr/yt-beer-app\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "20485",
                    "likeCount": "484",
                    "favoriteCount": "0",
                    "commentCount": "35"
                },
                "contentDetails": {
                    "duration": "PT9M2S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "J91bHusPatc": {
                "snippet": {
                    "publishedAt": "2020-05-06T07:55:38Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scraping with Python Guide",
                    "description": "5 Common ways to web scrape with Python! In this video I give and overview of some methods of extracting data from websites and take a bit about the legality of it.\n\nScraping with:\nHTML Tables: https://youtu.be/15f4JhJ8SiQ\nDealing with Logins: https://youtu.be/cV21EOf5bbA\nRender JS: https://youtu.be/lTypMlVBFM4\nAPI Endpoints: https://youtu.be/uRlik_-puEw\nSelenium: https://youtu.be/lTypMlVBFM4\n\nBonus:\nWorking with JSON and APIs: https://youtu.be/YgO5ff9sp7A\n\nCourt Case: https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/J91bHusPatc/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/J91bHusPatc/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/J91bHusPatc/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/J91bHusPatc/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/J91bHusPatc/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn python",
                        "python web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scraping with Python Guide",
                        "description": "5 Common ways to web scrape with Python! In this video I give and overview of some methods of extracting data from websites and take a bit about the legality of it.\n\nScraping with:\nHTML Tables: https://youtu.be/15f4JhJ8SiQ\nDealing with Logins: https://youtu.be/cV21EOf5bbA\nRender JS: https://youtu.be/lTypMlVBFM4\nAPI Endpoints: https://youtu.be/uRlik_-puEw\nSelenium: https://youtu.be/lTypMlVBFM4\n\nBonus:\nWorking with JSON and APIs: https://youtu.be/YgO5ff9sp7A\n\nCourt Case: https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "7189",
                    "likeCount": "146",
                    "favoriteCount": "0",
                    "commentCount": "9"
                },
                "contentDetails": {
                    "duration": "PT7M37S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "brJR5Qjp4SM": {
                "snippet": {
                    "publishedAt": "2020-04-20T21:50:35Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Always start your web scrapers with this- VENV And Python",
                    "description": "A demo of how to use the VENV virtual environments command in Python 3.8.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/brJR5Qjp4SM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/brJR5Qjp4SM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/brJR5Qjp4SM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/brJR5Qjp4SM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/brJR5Qjp4SM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "python virtual environments",
                        "VENV",
                        "venv python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Always start your web scrapers with this- VENV And Python",
                        "description": "A demo of how to use the VENV virtual environments command in Python 3.8.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "3166",
                    "likeCount": "95",
                    "favoriteCount": "0",
                    "commentCount": "11"
                },
                "contentDetails": {
                    "duration": "PT8M5S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "Texh_xJfzEM": {
                "snippet": {
                    "publishedAt": "2020-04-15T20:58:17Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "HELIUM for simple DYNAMIC web scraping with Python",
                    "description": "After using Selenium a lot to scrape dynamic sites i thought i would give Helium a go - its built on Selenium but is said to be lighter and easier. it comes with some handy features out of the box and is installed with pip.\n\ngithub: https://github.com/mherrmann/selenium-python-helium\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/Texh_xJfzEM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/Texh_xJfzEM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/Texh_xJfzEM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/Texh_xJfzEM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/Texh_xJfzEM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "web scraping",
                        "python web scraping",
                        "selenium",
                        "scrape dynamic sites"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "HELIUM for simple DYNAMIC web scraping with Python",
                        "description": "After using Selenium a lot to scrape dynamic sites i thought i would give Helium a go - its built on Selenium but is said to be lighter and easier. it comes with some handy features out of the box and is installed with pip.\n\ngithub: https://github.com/mherrmann/selenium-python-helium\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "19752",
                    "likeCount": "495",
                    "favoriteCount": "0",
                    "commentCount": "75"
                },
                "contentDetails": {
                    "duration": "PT7M42S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "uRlik_-puEw": {
                "snippet": {
                    "publishedAt": "2020-03-26T20:16:34Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "API Endpoints? Get data from the web easily with PYTHON",
                    "description": "This is another way to web scrape with Python. Find where the website gets its data from and then mimic this request programmatically.\n\nPostman: https://www.postman.com/\nInsomnia REST Client: https://insomnia.rest/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/uRlik_-puEw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/uRlik_-puEw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/uRlik_-puEw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/uRlik_-puEw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/uRlik_-puEw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn python",
                        "api endpoint",
                        "web scraping with python",
                        "web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "API Endpoints? Get data from the web easily with PYTHON",
                        "description": "This is another way to web scrape with Python. Find where the website gets its data from and then mimic this request programmatically.\n\nPostman: https://www.postman.com/\nInsomnia REST Client: https://insomnia.rest/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "69172",
                    "likeCount": "1375",
                    "favoriteCount": "0",
                    "commentCount": "69"
                },
                "contentDetails": {
                    "duration": "PT5M38S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "0hiGp3lF6ig": {
                "snippet": {
                    "publishedAt": "2020-03-22T17:36:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I Scrape JAVASCRIPT websites with Python",
                    "description": "Demo of the Render() function\n\nHow we can use requests-html to render webpages for us quickly and easily enabling us to scrape the data from javascript dynamic websites. this example demos scraping video titles and links from my YouTube channel\n\nCode at my GitHub: https://github.com/jhnwr/requests-html-render-yt/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/0hiGp3lF6ig/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/0hiGp3lF6ig/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/0hiGp3lF6ig/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/0hiGp3lF6ig/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/0hiGp3lF6ig/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "web scraping",
                        "webscraping with python",
                        "scraping javascript"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I Scrape JAVASCRIPT websites with Python",
                        "description": "Demo of the Render() function\n\nHow we can use requests-html to render webpages for us quickly and easily enabling us to scrape the data from javascript dynamic websites. this example demos scraping video titles and links from my YouTube channel\n\nCode at my GitHub: https://github.com/jhnwr/requests-html-render-yt/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n-------------------------------------\n\nSound like me:\n\nmicrophone https://amzn.to/36TbaAW\n\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\n-------------------------------------\n\nVideo like me:\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\nlights https://amzn.to/2GN7INg\n-------------------------------------\n\nPC Stuff:\ncase: https://amzn.to/3dEz6Jw\npsu: https://amzn.to/3kc7SfB\ncpu: https://amzn.to/2ILxGSh\nmobo: https://amzn.to/3lWmxw4\nram: https://amzn.to/31muxPc\ngfx card https://amzn.to/2SKYraW\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmouse https://amzn.to/2SH1ssK\nkeyboard https://amzn.to/2SKrjQA"
                    }
                },
                "statistics": {
                    "viewCount": "71423",
                    "likeCount": "1291",
                    "favoriteCount": "0",
                    "commentCount": "124"
                },
                "contentDetails": {
                    "duration": "PT4M33S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "eGsJR_7ipiw": {
                "snippet": {
                    "publishedAt": "2020-03-11T21:00:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "JMESPATH in PYTHON - JSON query language",
                    "description": "In this video we discuss how to use the basics of JMESPATH and hoe we could use it in our own projects. We cover looking through some order JSON data and use some search queries to extract the information we need\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/eGsJR_7ipiw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/eGsJR_7ipiw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/eGsJR_7ipiw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/eGsJR_7ipiw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/eGsJR_7ipiw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "jmespath",
                        "jmespath python",
                        "jmespath json"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "JMESPATH in PYTHON - JSON query language",
                        "description": "In this video we discuss how to use the basics of JMESPATH and hoe we could use it in our own projects. We cover looking through some order JSON data and use some search queries to extract the information we need\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "7190",
                    "likeCount": "154",
                    "favoriteCount": "0",
                    "commentCount": "14"
                },
                "contentDetails": {
                    "duration": "PT11M35S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "8gg7vStycHY": {
                "snippet": {
                    "publishedAt": "2020-03-05T20:30:00Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Easy SOCIAL IMAGES with Python PIL",
                    "description": "Use Python to create simple social images ready for upload by adding your text to a background image easily without using Photoshop or GIMP\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/8gg7vStycHY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/8gg7vStycHY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/8gg7vStycHY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/8gg7vStycHY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/8gg7vStycHY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "text over image",
                        "easily social images with python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Easy SOCIAL IMAGES with Python PIL",
                        "description": "Use Python to create simple social images ready for upload by adding your text to a background image easily without using Photoshop or GIMP\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "1711",
                    "likeCount": "54",
                    "favoriteCount": "0",
                    "commentCount": "2"
                },
                "contentDetails": {
                    "duration": "PT6M16S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "vRcRplls6qM": {
                "snippet": {
                    "publishedAt": "2020-03-04T22:05:18Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "QUICK PYTHON for Beginners - My MOST used",
                    "description": "A quickfire look at some aspects of beginner level Python. I cover a lot of the things I use regularly in my coding. With these basic things nailed you will have a good foundation to start your own projects.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/vRcRplls6qM/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/vRcRplls6qM/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/vRcRplls6qM/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/vRcRplls6qM/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/vRcRplls6qM/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "python basics",
                        "quick python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "QUICK PYTHON for Beginners - My MOST used",
                        "description": "A quickfire look at some aspects of beginner level Python. I cover a lot of the things I use regularly in my coding. With these basic things nailed you will have a good foundation to start your own projects.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "711",
                    "likeCount": "32",
                    "favoriteCount": "0",
                    "commentCount": "5"
                },
                "contentDetails": {
                    "duration": "PT14M28S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "lUAEMLqhlFQ": {
                "snippet": {
                    "publishedAt": "2020-02-28T10:00:08Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Easy Databases in PYTON - Web Scraping Example",
                    "description": "Second supplementary part to a quick look into using Dataset in Python to control our databases for us. I use a simple web scraping script to demonstrate some ways we can easily add our data to a database without any SQL commands.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/lUAEMLqhlFQ/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/lUAEMLqhlFQ/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/lUAEMLqhlFQ/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/lUAEMLqhlFQ/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/lUAEMLqhlFQ/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "learn python",
                        "python",
                        "python databases",
                        "web scraping python"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Easy Databases in PYTON - Web Scraping Example",
                        "description": "Second supplementary part to a quick look into using Dataset in Python to control our databases for us. I use a simple web scraping script to demonstrate some ways we can easily add our data to a database without any SQL commands.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "812",
                    "likeCount": "35",
                    "favoriteCount": "0",
                    "commentCount": "7"
                },
                "contentDetails": {
                    "duration": "PT7M37S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "ndtjygWQpX4": {
                "snippet": {
                    "publishedAt": "2020-02-25T22:48:33Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Easy Databases in PYTHON with Dataset",
                    "description": "Avoid having to learn SQL commands right now by using DATASET as a wrapper to do it for you. Simple quick and easy way of utilizing a database in your Python programs. In this video we explore the basic and how to use it by creating a database, adding a table and some data.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/ndtjygWQpX4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/ndtjygWQpX4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/ndtjygWQpX4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/ndtjygWQpX4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/ndtjygWQpX4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "python databases"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Easy Databases in PYTHON with Dataset",
                        "description": "Avoid having to learn SQL commands right now by using DATASET as a wrapper to do it for you. Simple quick and easy way of utilizing a database in your Python programs. In this video we explore the basic and how to use it by creating a database, adding a table and some data.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "2349",
                    "likeCount": "57",
                    "favoriteCount": "0",
                    "commentCount": "10"
                },
                "contentDetails": {
                    "duration": "PT13M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "lTypMlVBFM4": {
                "snippet": {
                    "publishedAt": "2020-02-12T22:45:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to SCRAPE DYNAMIC websites with Selenium",
                    "description": "How I use Selenium and Python to automate a browser to scrape data from dynamic websites. These sites load the content through JS or similar meaning we cannot use requests to get the html information. This is a way to get to that info.\n\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/lTypMlVBFM4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/lTypMlVBFM4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/lTypMlVBFM4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/lTypMlVBFM4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/lTypMlVBFM4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "selenium",
                        "dynamic websites",
                        "web scraping",
                        "webscraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to SCRAPE DYNAMIC websites with Selenium",
                        "description": "How I use Selenium and Python to automate a browser to scrape data from dynamic websites. These sites load the content through JS or similar meaning we cannot use requests to get the html information. This is a way to get to that info.\n\n# Scraper API: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies I use: https://proxyscrape.com/?ref=jhnwr\n# Hosting: Digital Ocean (Affiliate Link) - https://m.do.co/c/c7c90f161ff6\n# Gear Used: https://jhnwr.com/gear/ (NEW)\n# Patreon: https://www.patreon.com/johnwatsonrooney (NEW)"
                    }
                },
                "statistics": {
                    "viewCount": "172734",
                    "likeCount": "3798",
                    "favoriteCount": "0",
                    "commentCount": "321"
                },
                "contentDetails": {
                    "duration": "PT11M4S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "pUUhvJvs-R4": {
                "snippet": {
                    "publishedAt": "2020-02-05T21:47:30Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How I use SELENIUM to AUTOMATE the Web with PYTHON. Pt1",
                    "description": "First part in my Selenium mini-series. This first video shows how to install selenium and use the webdriver to open pages, input text into forms and submit, along with a quick look at the wait function to hold for dynamic content.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/pUUhvJvs-R4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/pUUhvJvs-R4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/pUUhvJvs-R4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/pUUhvJvs-R4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/pUUhvJvs-R4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learnpython",
                        "selenium",
                        "python selenium",
                        "browser automation",
                        "chrome webdriver"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How I use SELENIUM to AUTOMATE the Web with PYTHON. Pt1",
                        "description": "First part in my Selenium mini-series. This first video shows how to install selenium and use the webdriver to open pages, input text into forms and submit, along with a quick look at the wait function to hold for dynamic content.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "71885",
                    "likeCount": "1344",
                    "favoriteCount": "0",
                    "commentCount": "97"
                },
                "contentDetails": {
                    "duration": "PT13M58S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "YgO5ff9sp7A": {
                "snippet": {
                    "publishedAt": "2020-01-29T21:53:38Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "HOW TO: JSON and APIs in PYTHON - A Beginners Look",
                    "description": "Let's talk about working with JSON data in Python. \nUsing fake data stored in a JSON file we talk about accessing specific parts using indexing, and store them in a new dictionary. \n\nThen we make some API requests to create a fun little script for suggesting what beers go with our dinner choice. We begin to see how JSON and API requests work together and how we can manipulate this in Python for us to use in our own apps and webapps.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/YgO5ff9sp7A/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/YgO5ff9sp7A/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/YgO5ff9sp7A/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/YgO5ff9sp7A/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/YgO5ff9sp7A/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learnpython",
                        "json data",
                        "python json",
                        "python apis",
                        "python api requests",
                        "python requests"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "HOW TO: JSON and APIs in PYTHON - A Beginners Look",
                        "description": "Let's talk about working with JSON data in Python. \nUsing fake data stored in a JSON file we talk about accessing specific parts using indexing, and store them in a new dictionary. \n\nThen we make some API requests to create a fun little script for suggesting what beers go with our dinner choice. We begin to see how JSON and API requests work together and how we can manipulate this in Python for us to use in our own apps and webapps.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "44560",
                    "likeCount": "943",
                    "favoriteCount": "0",
                    "commentCount": "45"
                },
                "contentDetails": {
                    "duration": "PT25M40S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "cV21EOf5bbA": {
                "snippet": {
                    "publishedAt": "2020-01-22T21:38:03Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Web Scrape Websites with a LOGIN - Python Basic Auth",
                    "description": "Here we go through how to use requests to POST the login information and session to make it persistent, allowing us to scrape information behind a login wall.\nDummy site: https://the-internet.herokuapp.com/login\n\n-------------------------------------\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/cV21EOf5bbA/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/cV21EOf5bbA/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/cV21EOf5bbA/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/cV21EOf5bbA/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/cV21EOf5bbA/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "webscraping",
                        "webscraping with python",
                        "webscraping logins",
                        "learn python",
                        "python tutorial"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Web Scrape Websites with a LOGIN - Python Basic Auth",
                        "description": "Here we go through how to use requests to POST the login information and session to make it persistent, allowing us to scrape information behind a login wall.\nDummy site: https://the-internet.herokuapp.com/login\n\n-------------------------------------\n\n# Patreon: https://www.patreon.com/johnwatsonrooney\n# Scraper API I use: https://www.scrapingbee.com/?fpr=jhnwr\n# Proxies: https://iproyal.club/JWR50\n# Hosting: Digital Ocean: https://m.do.co/c/c7c90f161ff6\n# Gear I use: https://www.amazon.co.uk/shop/johnwatsonrooney\n# Twitter https://twitter.com/jhnwr"
                    }
                },
                "statistics": {
                    "viewCount": "138443",
                    "likeCount": "2540",
                    "favoriteCount": "0",
                    "commentCount": "136"
                },
                "contentDetails": {
                    "duration": "PT13M55S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "RWL_ubFht3Y": {
                "snippet": {
                    "publishedAt": "2020-01-12T17:03:20Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Functions: Basics - how to add user defined functions to you code",
                    "description": "A look at how to use functions in your code to make it cleaner, shorter and easier to test or add to.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/RWL_ubFht3Y/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/RWL_ubFht3Y/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/RWL_ubFht3Y/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/RWL_ubFht3Y/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/RWL_ubFht3Y/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "user defined functions",
                        "functions",
                        "python for beginners"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Functions: Basics - how to add user defined functions to you code",
                        "description": "A look at how to use functions in your code to make it cleaner, shorter and easier to test or add to.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "4705",
                    "likeCount": "61",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT7M24S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "mLi-na5IF4o": {
                "snippet": {
                    "publishedAt": "2020-01-08T21:34:15Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Automate Sales Reports with Pandas and Python",
                    "description": "Use Pandas and Python to automate composing of sales data from multiple csv files. We look a little at list comprehension to make our code neater and tidier, and export our results back to csv.\n\nLearn to use \"pd.concat\" to combine data frames, and how to check datatypes and remove blank lines from our data.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/mLi-na5IF4o/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/mLi-na5IF4o/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/mLi-na5IF4o/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/mLi-na5IF4o/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/mLi-na5IF4o/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Automate Sales Reports with Pandas and Python",
                        "description": "Use Pandas and Python to automate composing of sales data from multiple csv files. We look a little at list comprehension to make our code neater and tidier, and export our results back to csv.\n\nLearn to use \"pd.concat\" to combine data frames, and how to check datatypes and remove blank lines from our data.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "2692",
                    "likeCount": "86",
                    "favoriteCount": "0",
                    "commentCount": "9"
                },
                "contentDetails": {
                    "duration": "PT15M7S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "6x8oN6FtpLo": {
                "snippet": {
                    "publishedAt": "2019-12-09T21:44:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "How to Use Python Dictionaries + Lists of Dicts",
                    "description": "Here i cover the basics of working with dictionaries in Python. I go into creating, understanding keys and values and the interaction of lists in dictionaries and lists of dictionaries\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/6x8oN6FtpLo/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/6x8oN6FtpLo/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/6x8oN6FtpLo/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/6x8oN6FtpLo/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/6x8oN6FtpLo/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "python dictionaries",
                        "lists of dictionaries"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "How to Use Python Dictionaries + Lists of Dicts",
                        "description": "Here i cover the basics of working with dictionaries in Python. I go into creating, understanding keys and values and the interaction of lists in dictionaries and lists of dictionaries\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "60954",
                    "likeCount": "984",
                    "favoriteCount": "0",
                    "commentCount": "53"
                },
                "contentDetails": {
                    "duration": "PT8M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "1KHIFs8v7jY": {
                "snippet": {
                    "publishedAt": "2019-12-01T16:42:16Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Find the best prices for stuff with Python web scraping",
                    "description": "Learn how to web scrape using functions and email yourself the data. Using Python we can easily create simple scripts to perform basic tasks, like get prices for a PC upgrade.\n\ncode: https://github.com/jhnwr/scrape-deals\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/1KHIFs8v7jY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/1KHIFs8v7jY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/1KHIFs8v7jY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/1KHIFs8v7jY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/1KHIFs8v7jY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learn python",
                        "python functions",
                        "web scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Find the best prices for stuff with Python web scraping",
                        "description": "Learn how to web scrape using functions and email yourself the data. Using Python we can easily create simple scripts to perform basic tasks, like get prices for a PC upgrade.\n\ncode: https://github.com/jhnwr/scrape-deals\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "7778",
                    "likeCount": "173",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT16M27S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "PeTagmeYKjw": {
                "snippet": {
                    "publishedAt": "2019-12-01T14:13:11Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Python Web scraping - Script to CSV or Excel",
                    "description": "How to export the output of your web scraper to CSV or Excel using Pandas\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/PeTagmeYKjw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/PeTagmeYKjw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/PeTagmeYKjw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/PeTagmeYKjw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/PeTagmeYKjw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "pythonprogramming",
                        "python pandas",
                        "web scraping",
                        "script to csv",
                        "script to excel"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Python Web scraping - Script to CSV or Excel",
                        "description": "How to export the output of your web scraper to CSV or Excel using Pandas\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "17654",
                    "likeCount": "255",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT4M57S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "s7u4AkLS2Bw": {
                "snippet": {
                    "publishedAt": "2019-11-22T09:00:09Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "5 Tips for Learning PYTHON",
                    "description": "5 quick tips for beginners looking to learn Python. \n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/s7u4AkLS2Bw/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/s7u4AkLS2Bw/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/s7u4AkLS2Bw/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/s7u4AkLS2Bw/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/s7u4AkLS2Bw/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "learnpython",
                        "tipsforlearning"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "5 Tips for Learning PYTHON",
                        "description": "5 quick tips for beginners looking to learn Python. \n\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "1165",
                    "likeCount": "63",
                    "favoriteCount": "0",
                    "commentCount": "2"
                },
                "contentDetails": {
                    "duration": "PT7M14S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "XwaEo4f17LU": {
                "snippet": {
                    "publishedAt": "2019-11-20T20:57:19Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Indexing and Slicing Python Lists for Beginners",
                    "description": "Learn how to use indexes and slicing on your data in Python.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/XwaEo4f17LU/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/XwaEo4f17LU/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/XwaEo4f17LU/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/XwaEo4f17LU/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/XwaEo4f17LU/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "python",
                        "indexing",
                        "learnpython",
                        "python tutorial",
                        "learn python",
                        "python programming",
                        "python list",
                        "python list index",
                        "python index",
                        "python index list"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Indexing and Slicing Python Lists for Beginners",
                        "description": "Learn how to use indexes and slicing on your data in Python.\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "25594",
                    "likeCount": "438",
                    "favoriteCount": "0",
                    "commentCount": "15"
                },
                "contentDetails": {
                    "duration": "PT7M28S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "APukTnnwQEY": {
                "snippet": {
                    "publishedAt": "2019-11-18T20:48:07Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Basic Webscraper : Get info from the web with Python",
                    "description": "A beginners tutorial for learning to scrape websites with Python.\n\nTest website: http://toscrape.com/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/APukTnnwQEY/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/APukTnnwQEY/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/APukTnnwQEY/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/APukTnnwQEY/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/APukTnnwQEY/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "tags": [
                        "Python",
                        "Web Scraping"
                    ],
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Basic Webscraper : Get info from the web with Python",
                        "description": "A beginners tutorial for learning to scrape websites with Python.\n\nTest website: http://toscrape.com/\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    }
                },
                "statistics": {
                    "viewCount": "8934",
                    "likeCount": "227",
                    "favoriteCount": "0",
                    "commentCount": "27"
                },
                "contentDetails": {
                    "duration": "PT19M15S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            },
            "BdnHeQlYwR4": {
                "snippet": {
                    "publishedAt": "2019-10-31T20:58:06Z",
                    "channelId": "UC8tgRQ7DOzAbn9L7zDL8mLg",
                    "title": "Simple Python Projects | short projects for beginners",
                    "description": "Short and simple python projects for beginners to work on. Customize and learn as you code, there is no better way to learn than by doing.\n\n1 - Basic Web Scraper\n2 - Image Downloader\n3 - Bulk Image Resizer/manipulator\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy",
                    "thumbnails": {
                        "default": {
                            "url": "https://i.ytimg.com/vi/BdnHeQlYwR4/default.jpg",
                            "width": 120,
                            "height": 90
                        },
                        "medium": {
                            "url": "https://i.ytimg.com/vi/BdnHeQlYwR4/mqdefault.jpg",
                            "width": 320,
                            "height": 180
                        },
                        "high": {
                            "url": "https://i.ytimg.com/vi/BdnHeQlYwR4/hqdefault.jpg",
                            "width": 480,
                            "height": 360
                        },
                        "standard": {
                            "url": "https://i.ytimg.com/vi/BdnHeQlYwR4/sddefault.jpg",
                            "width": 640,
                            "height": 480
                        },
                        "maxres": {
                            "url": "https://i.ytimg.com/vi/BdnHeQlYwR4/maxresdefault.jpg",
                            "width": 1280,
                            "height": 720
                        }
                    },
                    "channelTitle": "John Watson Rooney",
                    "categoryId": "28",
                    "liveBroadcastContent": "none",
                    "localized": {
                        "title": "Simple Python Projects | short projects for beginners",
                        "description": "Short and simple python projects for beginners to work on. Customize and learn as you code, there is no better way to learn than by doing.\n\n1 - Basic Web Scraper\n2 - Image Downloader\n3 - Bulk Image Resizer/manipulator\n-------------------------------------\ntwitter https://twitter.com/jhnwr\ncode editor https://code.visualstudio.com/\nWSL2 (linux on windows) https://docs.microsoft.com/en-us/windows/wsl/install-win10\n-------------------------------------\nDisclaimer: These are affiliate links and as an Amazon Associate I earn from qualifying purchases\n\nmouse https://amzn.to/2SH1ssK\n27\" monitor https://amzn.to/2GAH4r9\n24\" monitor (vertical) https://amzn.to/3jIFamt\ndual monitor arm https://amzn.to/3lyFS6s\nmicrophone https://amzn.to/36TbaAW\nmic arm https://amzn.to/33NJI5v\naudio interface https://amzn.to/2FlnfU0\nkeyboard https://amzn.to/2SKrjQA\nlights https://amzn.to/2GN7INg\nwebcam https://amzn.to/2SJHopS\ncamera https://amzn.to/3iVIJol\ngfx card https://amzn.to/2SKYraW\nssd https://amzn.to/3lAjMAy"
                    },
                    "defaultAudioLanguage": "en-GB"
                },
                "statistics": {
                    "viewCount": "3214",
                    "likeCount": "111",
                    "favoriteCount": "0",
                    "commentCount": "3"
                },
                "contentDetails": {
                    "duration": "PT9M10S",
                    "dimension": "2d",
                    "definition": "hd",
                    "caption": "false",
                    "licensedContent": true,
                    "contentRating": {},
                    "projection": "rectangular"
                }
            }
        }
    }
}